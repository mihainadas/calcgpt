{
  "best_global_step": 6500,
  "best_metric": 0.7532694935798645,
  "best_model_checkpoint": "models/calcgpt_emb128_lay6_head8_ep20_bs8_lr1e03_dsm100/checkpoint-6500",
  "epoch": 8.463541666666666,
  "eval_steps": 100,
  "global_step": 6500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.013020833333333334,
      "grad_norm": 2.499931812286377,
      "learning_rate": 0.00017999999999999998,
      "loss": 2.0723,
      "step": 10
    },
    {
      "epoch": 0.026041666666666668,
      "grad_norm": 1.798388123512268,
      "learning_rate": 0.00038,
      "loss": 1.5988,
      "step": 20
    },
    {
      "epoch": 0.0390625,
      "grad_norm": 2.0532233715057373,
      "learning_rate": 0.00058,
      "loss": 1.4348,
      "step": 30
    },
    {
      "epoch": 0.052083333333333336,
      "grad_norm": 1.2272289991378784,
      "learning_rate": 0.0007800000000000001,
      "loss": 1.3259,
      "step": 40
    },
    {
      "epoch": 0.06510416666666667,
      "grad_norm": 1.3862024545669556,
      "learning_rate": 0.00098,
      "loss": 1.2577,
      "step": 50
    },
    {
      "epoch": 0.078125,
      "grad_norm": 2.2232749462127686,
      "learning_rate": 0.000999999147343184,
      "loss": 1.1924,
      "step": 60
    },
    {
      "epoch": 0.09114583333333333,
      "grad_norm": 1.4860501289367676,
      "learning_rate": 0.0009999961998912572,
      "loss": 1.1645,
      "step": 70
    },
    {
      "epoch": 0.10416666666666667,
      "grad_norm": 1.6602798700332642,
      "learning_rate": 0.0009999911471299998,
      "loss": 1.1511,
      "step": 80
    },
    {
      "epoch": 0.1171875,
      "grad_norm": 0.8558229804039001,
      "learning_rate": 0.0009999839890806877,
      "loss": 1.1204,
      "step": 90
    },
    {
      "epoch": 0.13020833333333334,
      "grad_norm": 1.1552633047103882,
      "learning_rate": 0.0009999747257734605,
      "loss": 1.1168,
      "step": 100
    },
    {
      "epoch": 0.13020833333333334,
      "eval_loss": 1.196810245513916,
      "eval_runtime": 2.9594,
      "eval_samples_per_second": 1037.696,
      "eval_steps_per_second": 64.877,
      "step": 100
    },
    {
      "epoch": 0.14322916666666666,
      "grad_norm": 1.0159436464309692,
      "learning_rate": 0.0009999633572473229,
      "loss": 1.0894,
      "step": 110
    },
    {
      "epoch": 0.15625,
      "grad_norm": 1.2207509279251099,
      "learning_rate": 0.0009999498835501436,
      "loss": 1.1032,
      "step": 120
    },
    {
      "epoch": 0.16927083333333334,
      "grad_norm": 1.0494612455368042,
      "learning_rate": 0.000999934304738656,
      "loss": 1.0884,
      "step": 130
    },
    {
      "epoch": 0.18229166666666666,
      "grad_norm": 0.9575875401496887,
      "learning_rate": 0.000999916620878457,
      "loss": 1.0828,
      "step": 140
    },
    {
      "epoch": 0.1953125,
      "grad_norm": 1.0766199827194214,
      "learning_rate": 0.0009998968320440067,
      "loss": 1.0917,
      "step": 150
    },
    {
      "epoch": 0.20833333333333334,
      "grad_norm": 0.8817653059959412,
      "learning_rate": 0.0009998749383186296,
      "loss": 1.0941,
      "step": 160
    },
    {
      "epoch": 0.22135416666666666,
      "grad_norm": 1.5443583726882935,
      "learning_rate": 0.000999850939794512,
      "loss": 1.0782,
      "step": 170
    },
    {
      "epoch": 0.234375,
      "grad_norm": 0.6320395469665527,
      "learning_rate": 0.0009998248365727035,
      "loss": 1.0607,
      "step": 180
    },
    {
      "epoch": 0.24739583333333334,
      "grad_norm": 1.3411633968353271,
      "learning_rate": 0.0009997966287631156,
      "loss": 1.0728,
      "step": 190
    },
    {
      "epoch": 0.2604166666666667,
      "grad_norm": 0.6761427521705627,
      "learning_rate": 0.0009997663164845218,
      "loss": 1.0484,
      "step": 200
    },
    {
      "epoch": 0.2604166666666667,
      "eval_loss": 1.158355474472046,
      "eval_runtime": 2.3291,
      "eval_samples_per_second": 1318.562,
      "eval_steps_per_second": 82.437,
      "step": 200
    },
    {
      "epoch": 0.2734375,
      "grad_norm": 0.7497255206108093,
      "learning_rate": 0.0009997338998645562,
      "loss": 1.0673,
      "step": 210
    },
    {
      "epoch": 0.2864583333333333,
      "grad_norm": 1.2504007816314697,
      "learning_rate": 0.000999699379039714,
      "loss": 1.0555,
      "step": 220
    },
    {
      "epoch": 0.2994791666666667,
      "grad_norm": 0.6909586787223816,
      "learning_rate": 0.0009996627541553503,
      "loss": 1.0647,
      "step": 230
    },
    {
      "epoch": 0.3125,
      "grad_norm": 1.8944178819656372,
      "learning_rate": 0.0009996240253656796,
      "loss": 1.0539,
      "step": 240
    },
    {
      "epoch": 0.3255208333333333,
      "grad_norm": 1.9205564260482788,
      "learning_rate": 0.0009995831928337755,
      "loss": 1.0936,
      "step": 250
    },
    {
      "epoch": 0.3385416666666667,
      "grad_norm": 1.0287151336669922,
      "learning_rate": 0.0009995402567315695,
      "loss": 1.0462,
      "step": 260
    },
    {
      "epoch": 0.3515625,
      "grad_norm": 0.9391170144081116,
      "learning_rate": 0.0009994952172398502,
      "loss": 1.0429,
      "step": 270
    },
    {
      "epoch": 0.3645833333333333,
      "grad_norm": 2.0246365070343018,
      "learning_rate": 0.0009994480745482636,
      "loss": 1.0569,
      "step": 280
    },
    {
      "epoch": 0.3776041666666667,
      "grad_norm": 0.8101407289505005,
      "learning_rate": 0.0009993988288553109,
      "loss": 1.0401,
      "step": 290
    },
    {
      "epoch": 0.390625,
      "grad_norm": 1.4204919338226318,
      "learning_rate": 0.0009993474803683484,
      "loss": 1.0538,
      "step": 300
    },
    {
      "epoch": 0.390625,
      "eval_loss": 1.122793436050415,
      "eval_runtime": 2.1384,
      "eval_samples_per_second": 1436.114,
      "eval_steps_per_second": 89.786,
      "step": 300
    },
    {
      "epoch": 0.4036458333333333,
      "grad_norm": 0.7219247221946716,
      "learning_rate": 0.000999294029303587,
      "loss": 1.0389,
      "step": 310
    },
    {
      "epoch": 0.4166666666666667,
      "grad_norm": 0.8614612221717834,
      "learning_rate": 0.0009992384758860902,
      "loss": 1.0305,
      "step": 320
    },
    {
      "epoch": 0.4296875,
      "grad_norm": 0.8684917092323303,
      "learning_rate": 0.000999180820349774,
      "loss": 1.0433,
      "step": 330
    },
    {
      "epoch": 0.4427083333333333,
      "grad_norm": 1.0427924394607544,
      "learning_rate": 0.0009991210629374057,
      "loss": 1.0318,
      "step": 340
    },
    {
      "epoch": 0.4557291666666667,
      "grad_norm": 0.7431294322013855,
      "learning_rate": 0.000999059203900603,
      "loss": 1.0452,
      "step": 350
    },
    {
      "epoch": 0.46875,
      "grad_norm": 1.2334614992141724,
      "learning_rate": 0.0009989952434998328,
      "loss": 1.0367,
      "step": 360
    },
    {
      "epoch": 0.4817708333333333,
      "grad_norm": 0.7304384708404541,
      "learning_rate": 0.0009989291820044098,
      "loss": 1.0442,
      "step": 370
    },
    {
      "epoch": 0.4947916666666667,
      "grad_norm": 1.6951324939727783,
      "learning_rate": 0.000998861019692496,
      "loss": 1.0312,
      "step": 380
    },
    {
      "epoch": 0.5078125,
      "grad_norm": 0.8239961862564087,
      "learning_rate": 0.000998790756851099,
      "loss": 1.0255,
      "step": 390
    },
    {
      "epoch": 0.5208333333333334,
      "grad_norm": 0.7974883317947388,
      "learning_rate": 0.0009987183937760712,
      "loss": 1.0267,
      "step": 400
    },
    {
      "epoch": 0.5208333333333334,
      "eval_loss": 1.110863208770752,
      "eval_runtime": 2.3724,
      "eval_samples_per_second": 1294.49,
      "eval_steps_per_second": 80.932,
      "step": 400
    },
    {
      "epoch": 0.5338541666666666,
      "grad_norm": 0.7215186953544617,
      "learning_rate": 0.000998643930772108,
      "loss": 1.0322,
      "step": 410
    },
    {
      "epoch": 0.546875,
      "grad_norm": 0.6602383852005005,
      "learning_rate": 0.0009985673681527473,
      "loss": 1.0304,
      "step": 420
    },
    {
      "epoch": 0.5598958333333334,
      "grad_norm": 0.8809551000595093,
      "learning_rate": 0.0009984887062403677,
      "loss": 1.0207,
      "step": 430
    },
    {
      "epoch": 0.5729166666666666,
      "grad_norm": 0.8293929696083069,
      "learning_rate": 0.0009984079453661868,
      "loss": 1.0195,
      "step": 440
    },
    {
      "epoch": 0.5859375,
      "grad_norm": 0.9820918440818787,
      "learning_rate": 0.0009983250858702601,
      "loss": 1.0077,
      "step": 450
    },
    {
      "epoch": 0.5989583333333334,
      "grad_norm": 2.433850049972534,
      "learning_rate": 0.0009982401281014807,
      "loss": 1.0365,
      "step": 460
    },
    {
      "epoch": 0.6119791666666666,
      "grad_norm": 1.1875053644180298,
      "learning_rate": 0.0009981530724175755,
      "loss": 1.036,
      "step": 470
    },
    {
      "epoch": 0.625,
      "grad_norm": 0.7992544174194336,
      "learning_rate": 0.000998063919185106,
      "loss": 1.0189,
      "step": 480
    },
    {
      "epoch": 0.6380208333333334,
      "grad_norm": 0.963571310043335,
      "learning_rate": 0.000997972668779465,
      "loss": 1.0177,
      "step": 490
    },
    {
      "epoch": 0.6510416666666666,
      "grad_norm": 1.0703667402267456,
      "learning_rate": 0.0009978793215848763,
      "loss": 1.0288,
      "step": 500
    },
    {
      "epoch": 0.6510416666666666,
      "eval_loss": 1.0991663932800293,
      "eval_runtime": 2.8714,
      "eval_samples_per_second": 1069.527,
      "eval_steps_per_second": 66.867,
      "step": 500
    },
    {
      "epoch": 0.6640625,
      "grad_norm": 0.8133019804954529,
      "learning_rate": 0.0009977838779943922,
      "loss": 1.0132,
      "step": 510
    },
    {
      "epoch": 0.6770833333333334,
      "grad_norm": 1.2656387090682983,
      "learning_rate": 0.0009976863384098921,
      "loss": 1.0216,
      "step": 520
    },
    {
      "epoch": 0.6901041666666666,
      "grad_norm": 0.8675236701965332,
      "learning_rate": 0.0009975867032420815,
      "loss": 1.0229,
      "step": 530
    },
    {
      "epoch": 0.703125,
      "grad_norm": 0.6654026508331299,
      "learning_rate": 0.0009974849729104892,
      "loss": 1.0072,
      "step": 540
    },
    {
      "epoch": 0.7161458333333334,
      "grad_norm": 0.8352308869361877,
      "learning_rate": 0.0009973811478434663,
      "loss": 1.0102,
      "step": 550
    },
    {
      "epoch": 0.7291666666666666,
      "grad_norm": 0.928264856338501,
      "learning_rate": 0.0009972752284781831,
      "loss": 1.0008,
      "step": 560
    },
    {
      "epoch": 0.7421875,
      "grad_norm": 1.5741796493530273,
      "learning_rate": 0.00099716721526063,
      "loss": 1.0081,
      "step": 570
    },
    {
      "epoch": 0.7552083333333334,
      "grad_norm": 0.8090035915374756,
      "learning_rate": 0.0009970571086456124,
      "loss": 1.0139,
      "step": 580
    },
    {
      "epoch": 0.7682291666666666,
      "grad_norm": 0.7030411958694458,
      "learning_rate": 0.0009969449090967508,
      "loss": 1.0163,
      "step": 590
    },
    {
      "epoch": 0.78125,
      "grad_norm": 1.5201892852783203,
      "learning_rate": 0.0009968306170864785,
      "loss": 1.0029,
      "step": 600
    },
    {
      "epoch": 0.78125,
      "eval_loss": 1.0818830728530884,
      "eval_runtime": 2.1789,
      "eval_samples_per_second": 1409.44,
      "eval_steps_per_second": 88.119,
      "step": 600
    },
    {
      "epoch": 0.7942708333333334,
      "grad_norm": 1.1800755262374878,
      "learning_rate": 0.0009967142330960389,
      "loss": 0.9951,
      "step": 610
    },
    {
      "epoch": 0.8072916666666666,
      "grad_norm": 0.7212767004966736,
      "learning_rate": 0.0009965957576154847,
      "loss": 1.0073,
      "step": 620
    },
    {
      "epoch": 0.8203125,
      "grad_norm": 0.9177600741386414,
      "learning_rate": 0.0009964751911436746,
      "loss": 0.9956,
      "step": 630
    },
    {
      "epoch": 0.8333333333333334,
      "grad_norm": 0.6939943432807922,
      "learning_rate": 0.000996352534188272,
      "loss": 1.0084,
      "step": 640
    },
    {
      "epoch": 0.8463541666666666,
      "grad_norm": 0.8186669945716858,
      "learning_rate": 0.000996227787265742,
      "loss": 1.01,
      "step": 650
    },
    {
      "epoch": 0.859375,
      "grad_norm": 0.8308948874473572,
      "learning_rate": 0.0009961009509013511,
      "loss": 1.0027,
      "step": 660
    },
    {
      "epoch": 0.8723958333333334,
      "grad_norm": 0.910146176815033,
      "learning_rate": 0.0009959720256291626,
      "loss": 0.9915,
      "step": 670
    },
    {
      "epoch": 0.8854166666666666,
      "grad_norm": 1.1591596603393555,
      "learning_rate": 0.0009958410119920355,
      "loss": 1.0043,
      "step": 680
    },
    {
      "epoch": 0.8984375,
      "grad_norm": 1.5518451929092407,
      "learning_rate": 0.0009957079105416228,
      "loss": 0.9923,
      "step": 690
    },
    {
      "epoch": 0.9114583333333334,
      "grad_norm": 0.9788129925727844,
      "learning_rate": 0.0009955727218383678,
      "loss": 0.9901,
      "step": 700
    },
    {
      "epoch": 0.9114583333333334,
      "eval_loss": 1.0558850765228271,
      "eval_runtime": 2.0183,
      "eval_samples_per_second": 1521.58,
      "eval_steps_per_second": 95.13,
      "step": 700
    },
    {
      "epoch": 0.9244791666666666,
      "grad_norm": 1.2177057266235352,
      "learning_rate": 0.0009954354464515034,
      "loss": 0.9907,
      "step": 710
    },
    {
      "epoch": 0.9375,
      "grad_norm": 0.8455919623374939,
      "learning_rate": 0.000995296084959048,
      "loss": 1.0054,
      "step": 720
    },
    {
      "epoch": 0.9505208333333334,
      "grad_norm": 1.3224629163742065,
      "learning_rate": 0.0009951546379478042,
      "loss": 1.0021,
      "step": 730
    },
    {
      "epoch": 0.9635416666666666,
      "grad_norm": 0.9872110486030579,
      "learning_rate": 0.0009950111060133562,
      "loss": 0.9825,
      "step": 740
    },
    {
      "epoch": 0.9765625,
      "grad_norm": 0.8842948079109192,
      "learning_rate": 0.0009948654897600664,
      "loss": 0.9718,
      "step": 750
    },
    {
      "epoch": 0.9895833333333334,
      "grad_norm": 0.8647941946983337,
      "learning_rate": 0.0009947177898010744,
      "loss": 0.9779,
      "step": 760
    },
    {
      "epoch": 1.0026041666666667,
      "grad_norm": 0.8492551445960999,
      "learning_rate": 0.0009945680067582926,
      "loss": 0.9795,
      "step": 770
    },
    {
      "epoch": 1.015625,
      "grad_norm": 1.1158668994903564,
      "learning_rate": 0.0009944161412624058,
      "loss": 0.9784,
      "step": 780
    },
    {
      "epoch": 1.0286458333333333,
      "grad_norm": 1.039377212524414,
      "learning_rate": 0.000994262193952866,
      "loss": 0.981,
      "step": 790
    },
    {
      "epoch": 1.0416666666666667,
      "grad_norm": 0.7435840368270874,
      "learning_rate": 0.0009941061654778916,
      "loss": 0.9684,
      "step": 800
    },
    {
      "epoch": 1.0416666666666667,
      "eval_loss": 1.052314043045044,
      "eval_runtime": 2.2239,
      "eval_samples_per_second": 1380.887,
      "eval_steps_per_second": 86.334,
      "step": 800
    },
    {
      "epoch": 1.0546875,
      "grad_norm": 1.2022504806518555,
      "learning_rate": 0.0009939480564944642,
      "loss": 0.9737,
      "step": 810
    },
    {
      "epoch": 1.0677083333333333,
      "grad_norm": 0.7170414328575134,
      "learning_rate": 0.0009937878676683253,
      "loss": 0.9716,
      "step": 820
    },
    {
      "epoch": 1.0807291666666667,
      "grad_norm": 1.2198954820632935,
      "learning_rate": 0.0009936255996739743,
      "loss": 0.9716,
      "step": 830
    },
    {
      "epoch": 1.09375,
      "grad_norm": 0.8580887913703918,
      "learning_rate": 0.0009934612531946648,
      "loss": 0.9622,
      "step": 840
    },
    {
      "epoch": 1.1067708333333333,
      "grad_norm": 0.8606069684028625,
      "learning_rate": 0.0009932948289224025,
      "loss": 0.9713,
      "step": 850
    },
    {
      "epoch": 1.1197916666666667,
      "grad_norm": 0.6324271559715271,
      "learning_rate": 0.000993126327557942,
      "loss": 0.9695,
      "step": 860
    },
    {
      "epoch": 1.1328125,
      "grad_norm": 0.7814024090766907,
      "learning_rate": 0.0009929557498107836,
      "loss": 0.992,
      "step": 870
    },
    {
      "epoch": 1.1458333333333333,
      "grad_norm": 0.734380304813385,
      "learning_rate": 0.0009927830963991705,
      "loss": 0.9648,
      "step": 880
    },
    {
      "epoch": 1.1588541666666667,
      "grad_norm": 1.1752095222473145,
      "learning_rate": 0.000992608368050086,
      "loss": 0.9556,
      "step": 890
    },
    {
      "epoch": 1.171875,
      "grad_norm": 0.9765871167182922,
      "learning_rate": 0.0009924315654992499,
      "loss": 0.9652,
      "step": 900
    },
    {
      "epoch": 1.171875,
      "eval_loss": 1.0302835702896118,
      "eval_runtime": 2.3167,
      "eval_samples_per_second": 1325.618,
      "eval_steps_per_second": 82.878,
      "step": 900
    },
    {
      "epoch": 1.1848958333333333,
      "grad_norm": 0.7334101796150208,
      "learning_rate": 0.0009922526894911167,
      "loss": 0.9882,
      "step": 910
    },
    {
      "epoch": 1.1979166666666667,
      "grad_norm": 0.7298495173454285,
      "learning_rate": 0.0009920717407788699,
      "loss": 0.9812,
      "step": 920
    },
    {
      "epoch": 1.2109375,
      "grad_norm": 1.41301429271698,
      "learning_rate": 0.0009918887201244217,
      "loss": 0.9673,
      "step": 930
    },
    {
      "epoch": 1.2239583333333333,
      "grad_norm": 0.9919083714485168,
      "learning_rate": 0.0009917036282984083,
      "loss": 0.9664,
      "step": 940
    },
    {
      "epoch": 1.2369791666666667,
      "grad_norm": 0.9790655374526978,
      "learning_rate": 0.0009915164660801866,
      "loss": 0.9657,
      "step": 950
    },
    {
      "epoch": 1.25,
      "grad_norm": 1.319536566734314,
      "learning_rate": 0.0009913272342578312,
      "loss": 0.9747,
      "step": 960
    },
    {
      "epoch": 1.2630208333333333,
      "grad_norm": 1.039781093597412,
      "learning_rate": 0.0009911359336281312,
      "loss": 0.9768,
      "step": 970
    },
    {
      "epoch": 1.2760416666666667,
      "grad_norm": 0.7338558435440063,
      "learning_rate": 0.000990942564996587,
      "loss": 0.9833,
      "step": 980
    },
    {
      "epoch": 1.2890625,
      "grad_norm": 1.2822951078414917,
      "learning_rate": 0.0009907471291774057,
      "loss": 0.9615,
      "step": 990
    },
    {
      "epoch": 1.3020833333333333,
      "grad_norm": 0.6864981055259705,
      "learning_rate": 0.0009905496269935002,
      "loss": 0.9716,
      "step": 1000
    },
    {
      "epoch": 1.3020833333333333,
      "eval_loss": 1.0355041027069092,
      "eval_runtime": 2.1138,
      "eval_samples_per_second": 1452.828,
      "eval_steps_per_second": 90.831,
      "step": 1000
    },
    {
      "epoch": 1.3151041666666667,
      "grad_norm": 0.7888725996017456,
      "learning_rate": 0.0009903500592764825,
      "loss": 0.9661,
      "step": 1010
    },
    {
      "epoch": 1.328125,
      "grad_norm": 0.8011967539787292,
      "learning_rate": 0.0009901484268666628,
      "loss": 0.9656,
      "step": 1020
    },
    {
      "epoch": 1.3411458333333333,
      "grad_norm": 0.9975444078445435,
      "learning_rate": 0.0009899447306130447,
      "loss": 0.9689,
      "step": 1030
    },
    {
      "epoch": 1.3541666666666667,
      "grad_norm": 0.8019043207168579,
      "learning_rate": 0.0009897389713733218,
      "loss": 0.9623,
      "step": 1040
    },
    {
      "epoch": 1.3671875,
      "grad_norm": 0.7928854823112488,
      "learning_rate": 0.000989531150013875,
      "loss": 0.9463,
      "step": 1050
    },
    {
      "epoch": 1.3802083333333333,
      "grad_norm": 1.0263601541519165,
      "learning_rate": 0.0009893212674097665,
      "loss": 0.9615,
      "step": 1060
    },
    {
      "epoch": 1.3932291666666667,
      "grad_norm": 0.9784836769104004,
      "learning_rate": 0.0009891093244447393,
      "loss": 0.9562,
      "step": 1070
    },
    {
      "epoch": 1.40625,
      "grad_norm": 0.6441085338592529,
      "learning_rate": 0.000988895322011211,
      "loss": 0.9494,
      "step": 1080
    },
    {
      "epoch": 1.4192708333333333,
      "grad_norm": 1.0800938606262207,
      "learning_rate": 0.000988679261010271,
      "loss": 0.9638,
      "step": 1090
    },
    {
      "epoch": 1.4322916666666667,
      "grad_norm": 1.4084528684616089,
      "learning_rate": 0.000988461142351677,
      "loss": 0.9564,
      "step": 1100
    },
    {
      "epoch": 1.4322916666666667,
      "eval_loss": 1.0223181247711182,
      "eval_runtime": 2.0001,
      "eval_samples_per_second": 1535.44,
      "eval_steps_per_second": 95.996,
      "step": 1100
    },
    {
      "epoch": 1.4453125,
      "grad_norm": 0.8806980848312378,
      "learning_rate": 0.0009882409669538501,
      "loss": 0.9644,
      "step": 1110
    },
    {
      "epoch": 1.4583333333333333,
      "grad_norm": 0.9082779288291931,
      "learning_rate": 0.000988018735743872,
      "loss": 0.9577,
      "step": 1120
    },
    {
      "epoch": 1.4713541666666667,
      "grad_norm": 0.6190146207809448,
      "learning_rate": 0.0009877944496574811,
      "loss": 0.9577,
      "step": 1130
    },
    {
      "epoch": 1.484375,
      "grad_norm": 0.8654364943504333,
      "learning_rate": 0.0009875681096390674,
      "loss": 0.9456,
      "step": 1140
    },
    {
      "epoch": 1.4973958333333333,
      "grad_norm": 1.1689670085906982,
      "learning_rate": 0.0009873397166416697,
      "loss": 0.9494,
      "step": 1150
    },
    {
      "epoch": 1.5104166666666665,
      "grad_norm": 1.2337278127670288,
      "learning_rate": 0.0009871092716269715,
      "loss": 0.9546,
      "step": 1160
    },
    {
      "epoch": 1.5234375,
      "grad_norm": 0.8921563029289246,
      "learning_rate": 0.0009868767755652956,
      "loss": 0.9552,
      "step": 1170
    },
    {
      "epoch": 1.5364583333333335,
      "grad_norm": 0.8004721999168396,
      "learning_rate": 0.0009866422294356018,
      "loss": 0.9508,
      "step": 1180
    },
    {
      "epoch": 1.5494791666666665,
      "grad_norm": 0.7598027586936951,
      "learning_rate": 0.0009864056342254826,
      "loss": 0.9361,
      "step": 1190
    },
    {
      "epoch": 1.5625,
      "grad_norm": 1.0183345079421997,
      "learning_rate": 0.0009861669909311571,
      "loss": 0.9493,
      "step": 1200
    },
    {
      "epoch": 1.5625,
      "eval_loss": 1.0181130170822144,
      "eval_runtime": 2.1223,
      "eval_samples_per_second": 1447.045,
      "eval_steps_per_second": 90.47,
      "step": 1200
    },
    {
      "epoch": 1.5755208333333335,
      "grad_norm": 1.4012069702148438,
      "learning_rate": 0.000985926300557469,
      "loss": 0.9576,
      "step": 1210
    },
    {
      "epoch": 1.5885416666666665,
      "grad_norm": 0.8896031379699707,
      "learning_rate": 0.0009856835641178815,
      "loss": 0.9474,
      "step": 1220
    },
    {
      "epoch": 1.6015625,
      "grad_norm": 0.8001646399497986,
      "learning_rate": 0.0009854387826344728,
      "loss": 0.9528,
      "step": 1230
    },
    {
      "epoch": 1.6145833333333335,
      "grad_norm": 0.6722118854522705,
      "learning_rate": 0.0009851919571379326,
      "loss": 0.9583,
      "step": 1240
    },
    {
      "epoch": 1.6276041666666665,
      "grad_norm": 0.865106463432312,
      "learning_rate": 0.0009849430886675564,
      "loss": 0.957,
      "step": 1250
    },
    {
      "epoch": 1.640625,
      "grad_norm": 0.7352889180183411,
      "learning_rate": 0.0009846921782712423,
      "loss": 0.9518,
      "step": 1260
    },
    {
      "epoch": 1.6536458333333335,
      "grad_norm": 0.650165319442749,
      "learning_rate": 0.0009844392270054868,
      "loss": 0.9539,
      "step": 1270
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 1.0156986713409424,
      "learning_rate": 0.000984184235935379,
      "loss": 0.9415,
      "step": 1280
    },
    {
      "epoch": 1.6796875,
      "grad_norm": 1.09251868724823,
      "learning_rate": 0.0009839272061345973,
      "loss": 0.9461,
      "step": 1290
    },
    {
      "epoch": 1.6927083333333335,
      "grad_norm": 0.6593221426010132,
      "learning_rate": 0.0009836681386854043,
      "loss": 0.9313,
      "step": 1300
    },
    {
      "epoch": 1.6927083333333335,
      "eval_loss": 1.0059233903884888,
      "eval_runtime": 2.3103,
      "eval_samples_per_second": 1329.258,
      "eval_steps_per_second": 83.106,
      "step": 1300
    },
    {
      "epoch": 1.7057291666666665,
      "grad_norm": 0.6809172034263611,
      "learning_rate": 0.0009834070346786427,
      "loss": 0.9427,
      "step": 1310
    },
    {
      "epoch": 1.71875,
      "grad_norm": 0.8635002374649048,
      "learning_rate": 0.0009831438952137303,
      "loss": 0.9522,
      "step": 1320
    },
    {
      "epoch": 1.7317708333333335,
      "grad_norm": 2.383527994155884,
      "learning_rate": 0.0009828787213986554,
      "loss": 0.9399,
      "step": 1330
    },
    {
      "epoch": 1.7447916666666665,
      "grad_norm": 1.3215667009353638,
      "learning_rate": 0.000982611514349972,
      "loss": 0.9531,
      "step": 1340
    },
    {
      "epoch": 1.7578125,
      "grad_norm": 0.7014426589012146,
      "learning_rate": 0.000982342275192796,
      "loss": 0.9489,
      "step": 1350
    },
    {
      "epoch": 1.7708333333333335,
      "grad_norm": 0.6915684342384338,
      "learning_rate": 0.0009820710050607994,
      "loss": 0.9532,
      "step": 1360
    },
    {
      "epoch": 1.7838541666666665,
      "grad_norm": 0.8454422950744629,
      "learning_rate": 0.0009817977050962058,
      "loss": 0.9202,
      "step": 1370
    },
    {
      "epoch": 1.796875,
      "grad_norm": 0.8935896754264832,
      "learning_rate": 0.000981522376449786,
      "loss": 0.9429,
      "step": 1380
    },
    {
      "epoch": 1.8098958333333335,
      "grad_norm": 1.0579984188079834,
      "learning_rate": 0.0009812450202808525,
      "loss": 0.958,
      "step": 1390
    },
    {
      "epoch": 1.8229166666666665,
      "grad_norm": 0.771094799041748,
      "learning_rate": 0.0009809656377572555,
      "loss": 0.9537,
      "step": 1400
    },
    {
      "epoch": 1.8229166666666665,
      "eval_loss": 1.0047342777252197,
      "eval_runtime": 2.3712,
      "eval_samples_per_second": 1295.104,
      "eval_steps_per_second": 80.97,
      "step": 1400
    },
    {
      "epoch": 1.8359375,
      "grad_norm": 0.7875704169273376,
      "learning_rate": 0.0009806842300553772,
      "loss": 0.9501,
      "step": 1410
    },
    {
      "epoch": 1.8489583333333335,
      "grad_norm": 0.7328592538833618,
      "learning_rate": 0.0009804007983601271,
      "loss": 0.9374,
      "step": 1420
    },
    {
      "epoch": 1.8619791666666665,
      "grad_norm": 0.9614570140838623,
      "learning_rate": 0.0009801153438649371,
      "loss": 0.947,
      "step": 1430
    },
    {
      "epoch": 1.875,
      "grad_norm": 1.0509589910507202,
      "learning_rate": 0.000979827867771756,
      "loss": 0.9568,
      "step": 1440
    },
    {
      "epoch": 1.8880208333333335,
      "grad_norm": 0.9407303929328918,
      "learning_rate": 0.000979538371291046,
      "loss": 0.9458,
      "step": 1450
    },
    {
      "epoch": 1.9010416666666665,
      "grad_norm": 1.5824888944625854,
      "learning_rate": 0.0009792468556417747,
      "loss": 0.9498,
      "step": 1460
    },
    {
      "epoch": 1.9140625,
      "grad_norm": 0.6395705938339233,
      "learning_rate": 0.0009789533220514132,
      "loss": 0.9305,
      "step": 1470
    },
    {
      "epoch": 1.9270833333333335,
      "grad_norm": 1.0554094314575195,
      "learning_rate": 0.0009786577717559289,
      "loss": 0.9293,
      "step": 1480
    },
    {
      "epoch": 1.9401041666666665,
      "grad_norm": 0.7489562630653381,
      "learning_rate": 0.0009783602059997808,
      "loss": 0.952,
      "step": 1490
    },
    {
      "epoch": 1.953125,
      "grad_norm": 0.8826549053192139,
      "learning_rate": 0.000978060626035914,
      "loss": 0.9399,
      "step": 1500
    },
    {
      "epoch": 1.953125,
      "eval_loss": 1.0067138671875,
      "eval_runtime": 2.0863,
      "eval_samples_per_second": 1471.975,
      "eval_steps_per_second": 92.028,
      "step": 1500
    },
    {
      "epoch": 1.9661458333333335,
      "grad_norm": 0.8528324961662292,
      "learning_rate": 0.0009777590331257557,
      "loss": 0.9366,
      "step": 1510
    },
    {
      "epoch": 1.9791666666666665,
      "grad_norm": 0.7934684753417969,
      "learning_rate": 0.0009774554285392077,
      "loss": 0.931,
      "step": 1520
    },
    {
      "epoch": 1.9921875,
      "grad_norm": 1.2910408973693848,
      "learning_rate": 0.0009771498135546432,
      "loss": 0.9445,
      "step": 1530
    },
    {
      "epoch": 2.0052083333333335,
      "grad_norm": 0.7937708497047424,
      "learning_rate": 0.0009768421894589003,
      "loss": 0.9539,
      "step": 1540
    },
    {
      "epoch": 2.0182291666666665,
      "grad_norm": 0.9113337993621826,
      "learning_rate": 0.0009765325575472762,
      "loss": 0.9349,
      "step": 1550
    },
    {
      "epoch": 2.03125,
      "grad_norm": 2.3691892623901367,
      "learning_rate": 0.0009762209191235227,
      "loss": 0.9433,
      "step": 1560
    },
    {
      "epoch": 2.0442708333333335,
      "grad_norm": 0.9422128200531006,
      "learning_rate": 0.0009759072754998407,
      "loss": 0.9241,
      "step": 1570
    },
    {
      "epoch": 2.0572916666666665,
      "grad_norm": 1.0010513067245483,
      "learning_rate": 0.0009755916279968737,
      "loss": 0.9298,
      "step": 1580
    },
    {
      "epoch": 2.0703125,
      "grad_norm": 0.6371631622314453,
      "learning_rate": 0.0009752739779437031,
      "loss": 0.939,
      "step": 1590
    },
    {
      "epoch": 2.0833333333333335,
      "grad_norm": 1.273356556892395,
      "learning_rate": 0.0009749543266778422,
      "loss": 0.9423,
      "step": 1600
    },
    {
      "epoch": 2.0833333333333335,
      "eval_loss": 1.0081866979599,
      "eval_runtime": 2.1448,
      "eval_samples_per_second": 1431.842,
      "eval_steps_per_second": 89.519,
      "step": 1600
    },
    {
      "epoch": 2.0963541666666665,
      "grad_norm": 0.5311087369918823,
      "learning_rate": 0.0009746326755452311,
      "loss": 0.9417,
      "step": 1610
    },
    {
      "epoch": 2.109375,
      "grad_norm": 0.8017789125442505,
      "learning_rate": 0.0009743090259002301,
      "loss": 0.9388,
      "step": 1620
    },
    {
      "epoch": 2.1223958333333335,
      "grad_norm": 0.7101368308067322,
      "learning_rate": 0.0009739833791056149,
      "loss": 0.9332,
      "step": 1630
    },
    {
      "epoch": 2.1354166666666665,
      "grad_norm": 0.9687156081199646,
      "learning_rate": 0.0009736557365325703,
      "loss": 0.9288,
      "step": 1640
    },
    {
      "epoch": 2.1484375,
      "grad_norm": 1.051536202430725,
      "learning_rate": 0.0009733260995606849,
      "loss": 0.9366,
      "step": 1650
    },
    {
      "epoch": 2.1614583333333335,
      "grad_norm": 1.185655117034912,
      "learning_rate": 0.0009729944695779447,
      "loss": 0.9449,
      "step": 1660
    },
    {
      "epoch": 2.1744791666666665,
      "grad_norm": 0.7531276941299438,
      "learning_rate": 0.0009726608479807276,
      "loss": 0.9424,
      "step": 1670
    },
    {
      "epoch": 2.1875,
      "grad_norm": 0.70262211561203,
      "learning_rate": 0.0009723252361737978,
      "loss": 0.929,
      "step": 1680
    },
    {
      "epoch": 2.2005208333333335,
      "grad_norm": 0.5626025199890137,
      "learning_rate": 0.0009719876355702992,
      "loss": 0.9281,
      "step": 1690
    },
    {
      "epoch": 2.2135416666666665,
      "grad_norm": 0.9529790282249451,
      "learning_rate": 0.0009716480475917503,
      "loss": 0.9255,
      "step": 1700
    },
    {
      "epoch": 2.2135416666666665,
      "eval_loss": 0.9881882071495056,
      "eval_runtime": 2.1545,
      "eval_samples_per_second": 1425.359,
      "eval_steps_per_second": 89.114,
      "step": 1700
    },
    {
      "epoch": 2.2265625,
      "grad_norm": 0.9395204186439514,
      "learning_rate": 0.0009713064736680371,
      "loss": 0.9216,
      "step": 1710
    },
    {
      "epoch": 2.2395833333333335,
      "grad_norm": 0.7961413264274597,
      "learning_rate": 0.0009709629152374083,
      "loss": 0.9193,
      "step": 1720
    },
    {
      "epoch": 2.2526041666666665,
      "grad_norm": 0.8322834372520447,
      "learning_rate": 0.0009706173737464684,
      "loss": 0.9224,
      "step": 1730
    },
    {
      "epoch": 2.265625,
      "grad_norm": 0.8280519843101501,
      "learning_rate": 0.0009702698506501717,
      "loss": 0.9354,
      "step": 1740
    },
    {
      "epoch": 2.2786458333333335,
      "grad_norm": 1.0326688289642334,
      "learning_rate": 0.0009699203474118167,
      "loss": 0.9487,
      "step": 1750
    },
    {
      "epoch": 2.2916666666666665,
      "grad_norm": 0.767361581325531,
      "learning_rate": 0.0009695688655030397,
      "loss": 0.9414,
      "step": 1760
    },
    {
      "epoch": 2.3046875,
      "grad_norm": 1.0132896900177002,
      "learning_rate": 0.0009692154064038079,
      "loss": 0.941,
      "step": 1770
    },
    {
      "epoch": 2.3177083333333335,
      "grad_norm": 0.7142376899719238,
      "learning_rate": 0.0009688599716024141,
      "loss": 0.9291,
      "step": 1780
    },
    {
      "epoch": 2.3307291666666665,
      "grad_norm": 0.7048730254173279,
      "learning_rate": 0.0009685025625954702,
      "loss": 0.9167,
      "step": 1790
    },
    {
      "epoch": 2.34375,
      "grad_norm": 0.8066487312316895,
      "learning_rate": 0.0009681431808879007,
      "loss": 0.9354,
      "step": 1800
    },
    {
      "epoch": 2.34375,
      "eval_loss": 0.9889347553253174,
      "eval_runtime": 2.0246,
      "eval_samples_per_second": 1516.805,
      "eval_steps_per_second": 94.831,
      "step": 1800
    },
    {
      "epoch": 2.3567708333333335,
      "grad_norm": 0.8510262966156006,
      "learning_rate": 0.0009677818279929363,
      "loss": 0.9348,
      "step": 1810
    },
    {
      "epoch": 2.3697916666666665,
      "grad_norm": 0.6431695818901062,
      "learning_rate": 0.0009674185054321079,
      "loss": 0.9219,
      "step": 1820
    },
    {
      "epoch": 2.3828125,
      "grad_norm": 0.6874697208404541,
      "learning_rate": 0.0009670532147352397,
      "loss": 0.9349,
      "step": 1830
    },
    {
      "epoch": 2.3958333333333335,
      "grad_norm": 0.6217290163040161,
      "learning_rate": 0.0009666859574404434,
      "loss": 0.9156,
      "step": 1840
    },
    {
      "epoch": 2.4088541666666665,
      "grad_norm": 0.7447871565818787,
      "learning_rate": 0.0009663167350941113,
      "loss": 0.9319,
      "step": 1850
    },
    {
      "epoch": 2.421875,
      "grad_norm": 0.8931940197944641,
      "learning_rate": 0.0009659455492509095,
      "loss": 0.9179,
      "step": 1860
    },
    {
      "epoch": 2.4348958333333335,
      "grad_norm": 0.9476786255836487,
      "learning_rate": 0.0009655724014737719,
      "loss": 0.9219,
      "step": 1870
    },
    {
      "epoch": 2.4479166666666665,
      "grad_norm": 1.0998402833938599,
      "learning_rate": 0.0009651972933338935,
      "loss": 0.9286,
      "step": 1880
    },
    {
      "epoch": 2.4609375,
      "grad_norm": 1.1104989051818848,
      "learning_rate": 0.0009648202264107237,
      "loss": 0.9392,
      "step": 1890
    },
    {
      "epoch": 2.4739583333333335,
      "grad_norm": 1.0408531427383423,
      "learning_rate": 0.0009644412022919596,
      "loss": 0.9287,
      "step": 1900
    },
    {
      "epoch": 2.4739583333333335,
      "eval_loss": 0.9946876764297485,
      "eval_runtime": 2.1984,
      "eval_samples_per_second": 1396.95,
      "eval_steps_per_second": 87.338,
      "step": 1900
    },
    {
      "epoch": 2.4869791666666665,
      "grad_norm": 0.8782169222831726,
      "learning_rate": 0.0009640602225735391,
      "loss": 0.9368,
      "step": 1910
    },
    {
      "epoch": 2.5,
      "grad_norm": 1.0772722959518433,
      "learning_rate": 0.000963677288859635,
      "loss": 0.9286,
      "step": 1920
    },
    {
      "epoch": 2.5130208333333335,
      "grad_norm": 0.8548166155815125,
      "learning_rate": 0.0009632924027626473,
      "loss": 0.9192,
      "step": 1930
    },
    {
      "epoch": 2.5260416666666665,
      "grad_norm": 0.8070386648178101,
      "learning_rate": 0.0009629055659031969,
      "loss": 0.9274,
      "step": 1940
    },
    {
      "epoch": 2.5390625,
      "grad_norm": 0.6048424243927002,
      "learning_rate": 0.0009625167799101186,
      "loss": 0.9259,
      "step": 1950
    },
    {
      "epoch": 2.5520833333333335,
      "grad_norm": 0.8418717384338379,
      "learning_rate": 0.0009621260464204546,
      "loss": 0.9283,
      "step": 1960
    },
    {
      "epoch": 2.5651041666666665,
      "grad_norm": 0.6977070569992065,
      "learning_rate": 0.0009617333670794468,
      "loss": 0.9236,
      "step": 1970
    },
    {
      "epoch": 2.578125,
      "grad_norm": 0.8638871312141418,
      "learning_rate": 0.0009613387435405312,
      "loss": 0.9273,
      "step": 1980
    },
    {
      "epoch": 2.5911458333333335,
      "grad_norm": 0.7681301236152649,
      "learning_rate": 0.0009609421774653291,
      "loss": 0.9383,
      "step": 1990
    },
    {
      "epoch": 2.6041666666666665,
      "grad_norm": 1.097541093826294,
      "learning_rate": 0.0009605436705236422,
      "loss": 0.916,
      "step": 2000
    },
    {
      "epoch": 2.6041666666666665,
      "eval_loss": 0.9892765879631042,
      "eval_runtime": 2.3488,
      "eval_samples_per_second": 1307.501,
      "eval_steps_per_second": 81.745,
      "step": 2000
    },
    {
      "epoch": 2.6171875,
      "grad_norm": 1.1108404397964478,
      "learning_rate": 0.0009601432243934436,
      "loss": 0.9247,
      "step": 2010
    },
    {
      "epoch": 2.6302083333333335,
      "grad_norm": 0.5949715971946716,
      "learning_rate": 0.0009597408407608724,
      "loss": 0.926,
      "step": 2020
    },
    {
      "epoch": 2.6432291666666665,
      "grad_norm": 1.0842934846878052,
      "learning_rate": 0.0009593365213202255,
      "loss": 0.9245,
      "step": 2030
    },
    {
      "epoch": 2.65625,
      "grad_norm": 1.060417890548706,
      "learning_rate": 0.0009589302677739506,
      "loss": 0.9249,
      "step": 2040
    },
    {
      "epoch": 2.6692708333333335,
      "grad_norm": 0.5248439311981201,
      "learning_rate": 0.0009585220818326395,
      "loss": 0.9156,
      "step": 2050
    },
    {
      "epoch": 2.6822916666666665,
      "grad_norm": 1.0670167207717896,
      "learning_rate": 0.0009581119652150207,
      "loss": 0.9354,
      "step": 2060
    },
    {
      "epoch": 2.6953125,
      "grad_norm": 0.7717132568359375,
      "learning_rate": 0.000957699919647952,
      "loss": 0.9276,
      "step": 2070
    },
    {
      "epoch": 2.7083333333333335,
      "grad_norm": 0.7176546454429626,
      "learning_rate": 0.0009572859468664134,
      "loss": 0.9389,
      "step": 2080
    },
    {
      "epoch": 2.7213541666666665,
      "grad_norm": 0.7172672748565674,
      "learning_rate": 0.0009568700486134995,
      "loss": 0.9326,
      "step": 2090
    },
    {
      "epoch": 2.734375,
      "grad_norm": 0.9887889623641968,
      "learning_rate": 0.0009564522266404126,
      "loss": 0.9119,
      "step": 2100
    },
    {
      "epoch": 2.734375,
      "eval_loss": 0.9826837182044983,
      "eval_runtime": 2.4385,
      "eval_samples_per_second": 1259.405,
      "eval_steps_per_second": 78.738,
      "step": 2100
    },
    {
      "epoch": 2.7473958333333335,
      "grad_norm": 0.6292335391044617,
      "learning_rate": 0.0009560324827064553,
      "loss": 0.9158,
      "step": 2110
    },
    {
      "epoch": 2.7604166666666665,
      "grad_norm": 0.655960202217102,
      "learning_rate": 0.0009556108185790222,
      "loss": 0.9317,
      "step": 2120
    },
    {
      "epoch": 2.7734375,
      "grad_norm": 0.7689936757087708,
      "learning_rate": 0.0009551872360335942,
      "loss": 0.9211,
      "step": 2130
    },
    {
      "epoch": 2.7864583333333335,
      "grad_norm": 0.5619646906852722,
      "learning_rate": 0.0009547617368537289,
      "loss": 0.9174,
      "step": 2140
    },
    {
      "epoch": 2.7994791666666665,
      "grad_norm": 1.2475835084915161,
      "learning_rate": 0.0009543343228310551,
      "loss": 0.9358,
      "step": 2150
    },
    {
      "epoch": 2.8125,
      "grad_norm": 0.7841667532920837,
      "learning_rate": 0.0009539049957652639,
      "loss": 0.9195,
      "step": 2160
    },
    {
      "epoch": 2.8255208333333335,
      "grad_norm": 0.6549028158187866,
      "learning_rate": 0.0009534737574641012,
      "loss": 0.9158,
      "step": 2170
    },
    {
      "epoch": 2.8385416666666665,
      "grad_norm": 0.6807146072387695,
      "learning_rate": 0.0009530406097433614,
      "loss": 0.9224,
      "step": 2180
    },
    {
      "epoch": 2.8515625,
      "grad_norm": 0.7121636271476746,
      "learning_rate": 0.0009526055544268778,
      "loss": 0.9087,
      "step": 2190
    },
    {
      "epoch": 2.8645833333333335,
      "grad_norm": 1.4744749069213867,
      "learning_rate": 0.0009521685933465165,
      "loss": 0.9252,
      "step": 2200
    },
    {
      "epoch": 2.8645833333333335,
      "eval_loss": 0.9722771048545837,
      "eval_runtime": 2.8592,
      "eval_samples_per_second": 1074.088,
      "eval_steps_per_second": 67.152,
      "step": 2200
    },
    {
      "epoch": 2.8776041666666665,
      "grad_norm": 0.7370389699935913,
      "learning_rate": 0.0009517297283421679,
      "loss": 0.9193,
      "step": 2210
    },
    {
      "epoch": 2.890625,
      "grad_norm": 1.0035876035690308,
      "learning_rate": 0.0009512889612617396,
      "loss": 0.9168,
      "step": 2220
    },
    {
      "epoch": 2.9036458333333335,
      "grad_norm": 1.3520660400390625,
      "learning_rate": 0.0009508462939611473,
      "loss": 0.9197,
      "step": 2230
    },
    {
      "epoch": 2.9166666666666665,
      "grad_norm": 0.9831650853157043,
      "learning_rate": 0.0009504017283043086,
      "loss": 0.9311,
      "step": 2240
    },
    {
      "epoch": 2.9296875,
      "grad_norm": 0.7520572543144226,
      "learning_rate": 0.0009499552661631341,
      "loss": 0.917,
      "step": 2250
    },
    {
      "epoch": 2.9427083333333335,
      "grad_norm": 0.7823874950408936,
      "learning_rate": 0.0009495069094175199,
      "loss": 0.9043,
      "step": 2260
    },
    {
      "epoch": 2.9557291666666665,
      "grad_norm": 0.6871271133422852,
      "learning_rate": 0.0009490566599553398,
      "loss": 0.9039,
      "step": 2270
    },
    {
      "epoch": 2.96875,
      "grad_norm": 0.7657281160354614,
      "learning_rate": 0.0009486045196724368,
      "loss": 0.918,
      "step": 2280
    },
    {
      "epoch": 2.9817708333333335,
      "grad_norm": 0.5751971006393433,
      "learning_rate": 0.0009481504904726159,
      "loss": 0.9134,
      "step": 2290
    },
    {
      "epoch": 2.9947916666666665,
      "grad_norm": 0.6374853253364563,
      "learning_rate": 0.0009476945742676352,
      "loss": 0.9457,
      "step": 2300
    },
    {
      "epoch": 2.9947916666666665,
      "eval_loss": 0.9770150184631348,
      "eval_runtime": 2.0741,
      "eval_samples_per_second": 1480.621,
      "eval_steps_per_second": 92.569,
      "step": 2300
    },
    {
      "epoch": 3.0078125,
      "grad_norm": 0.7233908176422119,
      "learning_rate": 0.0009472367729771987,
      "loss": 0.9283,
      "step": 2310
    },
    {
      "epoch": 3.0208333333333335,
      "grad_norm": 0.8862678408622742,
      "learning_rate": 0.0009467770885289476,
      "loss": 0.9141,
      "step": 2320
    },
    {
      "epoch": 3.0338541666666665,
      "grad_norm": 0.8523941040039062,
      "learning_rate": 0.0009463155228584526,
      "loss": 0.9196,
      "step": 2330
    },
    {
      "epoch": 3.046875,
      "grad_norm": 1.529420018196106,
      "learning_rate": 0.0009458520779092057,
      "loss": 0.9173,
      "step": 2340
    },
    {
      "epoch": 3.0598958333333335,
      "grad_norm": 1.383867621421814,
      "learning_rate": 0.0009453867556326113,
      "loss": 0.9231,
      "step": 2350
    },
    {
      "epoch": 3.0729166666666665,
      "grad_norm": 0.8170729279518127,
      "learning_rate": 0.0009449195579879793,
      "loss": 0.9126,
      "step": 2360
    },
    {
      "epoch": 3.0859375,
      "grad_norm": 0.7793170809745789,
      "learning_rate": 0.0009444504869425155,
      "loss": 0.908,
      "step": 2370
    },
    {
      "epoch": 3.0989583333333335,
      "grad_norm": 0.6842008829116821,
      "learning_rate": 0.0009439795444713141,
      "loss": 0.9197,
      "step": 2380
    },
    {
      "epoch": 3.1119791666666665,
      "grad_norm": 0.6462126970291138,
      "learning_rate": 0.0009435067325573498,
      "loss": 0.9227,
      "step": 2390
    },
    {
      "epoch": 3.125,
      "grad_norm": 0.888971745967865,
      "learning_rate": 0.0009430320531914683,
      "loss": 0.905,
      "step": 2400
    },
    {
      "epoch": 3.125,
      "eval_loss": 0.971813976764679,
      "eval_runtime": 2.0361,
      "eval_samples_per_second": 1508.283,
      "eval_steps_per_second": 94.298,
      "step": 2400
    },
    {
      "epoch": 3.1380208333333335,
      "grad_norm": 1.2372405529022217,
      "learning_rate": 0.0009425555083723782,
      "loss": 0.9112,
      "step": 2410
    },
    {
      "epoch": 3.1510416666666665,
      "grad_norm": 0.7175512909889221,
      "learning_rate": 0.0009420771001066437,
      "loss": 0.9145,
      "step": 2420
    },
    {
      "epoch": 3.1640625,
      "grad_norm": 1.046318531036377,
      "learning_rate": 0.0009415968304086745,
      "loss": 0.9297,
      "step": 2430
    },
    {
      "epoch": 3.1770833333333335,
      "grad_norm": 0.8610039353370667,
      "learning_rate": 0.0009411147013007187,
      "loss": 0.9347,
      "step": 2440
    },
    {
      "epoch": 3.1901041666666665,
      "grad_norm": 0.863828718662262,
      "learning_rate": 0.0009406307148128537,
      "loss": 0.9192,
      "step": 2450
    },
    {
      "epoch": 3.203125,
      "grad_norm": 0.8031206727027893,
      "learning_rate": 0.0009401448729829772,
      "loss": 0.9119,
      "step": 2460
    },
    {
      "epoch": 3.2161458333333335,
      "grad_norm": 1.1585103273391724,
      "learning_rate": 0.0009396571778567997,
      "loss": 0.9242,
      "step": 2470
    },
    {
      "epoch": 3.2291666666666665,
      "grad_norm": 1.2583904266357422,
      "learning_rate": 0.0009391676314878348,
      "loss": 0.9247,
      "step": 2480
    },
    {
      "epoch": 3.2421875,
      "grad_norm": 0.8051342964172363,
      "learning_rate": 0.0009386762359373915,
      "loss": 0.9262,
      "step": 2490
    },
    {
      "epoch": 3.2552083333333335,
      "grad_norm": 0.5707066655158997,
      "learning_rate": 0.0009381829932745645,
      "loss": 0.9063,
      "step": 2500
    },
    {
      "epoch": 3.2552083333333335,
      "eval_loss": 0.9755721092224121,
      "eval_runtime": 2.0712,
      "eval_samples_per_second": 1482.71,
      "eval_steps_per_second": 92.7,
      "step": 2500
    },
    {
      "epoch": 3.2682291666666665,
      "grad_norm": 0.893156886100769,
      "learning_rate": 0.0009376879055762266,
      "loss": 0.9166,
      "step": 2510
    },
    {
      "epoch": 3.28125,
      "grad_norm": 0.6406066417694092,
      "learning_rate": 0.0009371909749270189,
      "loss": 0.9073,
      "step": 2520
    },
    {
      "epoch": 3.2942708333333335,
      "grad_norm": 0.7622990012168884,
      "learning_rate": 0.000936692203419343,
      "loss": 0.9074,
      "step": 2530
    },
    {
      "epoch": 3.3072916666666665,
      "grad_norm": 0.7503463625907898,
      "learning_rate": 0.0009361915931533514,
      "loss": 0.9087,
      "step": 2540
    },
    {
      "epoch": 3.3203125,
      "grad_norm": 0.591529130935669,
      "learning_rate": 0.000935689146236939,
      "loss": 0.9205,
      "step": 2550
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 0.759699285030365,
      "learning_rate": 0.0009351848647857343,
      "loss": 0.9253,
      "step": 2560
    },
    {
      "epoch": 3.3463541666666665,
      "grad_norm": 0.7281885147094727,
      "learning_rate": 0.0009346787509230902,
      "loss": 0.9143,
      "step": 2570
    },
    {
      "epoch": 3.359375,
      "grad_norm": 0.9397158622741699,
      "learning_rate": 0.0009341708067800756,
      "loss": 0.929,
      "step": 2580
    },
    {
      "epoch": 3.3723958333333335,
      "grad_norm": 0.7669069766998291,
      "learning_rate": 0.0009336610344954655,
      "loss": 0.9094,
      "step": 2590
    },
    {
      "epoch": 3.3854166666666665,
      "grad_norm": 0.7985663414001465,
      "learning_rate": 0.0009331494362157333,
      "loss": 0.9064,
      "step": 2600
    },
    {
      "epoch": 3.3854166666666665,
      "eval_loss": 0.9834493398666382,
      "eval_runtime": 2.0263,
      "eval_samples_per_second": 1515.547,
      "eval_steps_per_second": 94.753,
      "step": 2600
    },
    {
      "epoch": 3.3984375,
      "grad_norm": 0.7313529849052429,
      "learning_rate": 0.0009326360140950405,
      "loss": 0.9237,
      "step": 2610
    },
    {
      "epoch": 3.4114583333333335,
      "grad_norm": 0.7814658880233765,
      "learning_rate": 0.0009321207702952281,
      "loss": 0.9084,
      "step": 2620
    },
    {
      "epoch": 3.4244791666666665,
      "grad_norm": 0.6979455947875977,
      "learning_rate": 0.0009316037069858079,
      "loss": 0.9078,
      "step": 2630
    },
    {
      "epoch": 3.4375,
      "grad_norm": 0.866003155708313,
      "learning_rate": 0.000931084826343953,
      "loss": 0.9128,
      "step": 2640
    },
    {
      "epoch": 3.4505208333333335,
      "grad_norm": 1.0008748769760132,
      "learning_rate": 0.0009305641305544883,
      "loss": 0.8948,
      "step": 2650
    },
    {
      "epoch": 3.4635416666666665,
      "grad_norm": 1.091978907585144,
      "learning_rate": 0.000930041621809882,
      "loss": 0.9092,
      "step": 2660
    },
    {
      "epoch": 3.4765625,
      "grad_norm": 1.1745282411575317,
      "learning_rate": 0.0009295173023102357,
      "loss": 0.9157,
      "step": 2670
    },
    {
      "epoch": 3.4895833333333335,
      "grad_norm": 0.8439339399337769,
      "learning_rate": 0.0009289911742632759,
      "loss": 0.9198,
      "step": 2680
    },
    {
      "epoch": 3.5026041666666665,
      "grad_norm": 1.3618478775024414,
      "learning_rate": 0.0009284632398843439,
      "loss": 0.9192,
      "step": 2690
    },
    {
      "epoch": 3.515625,
      "grad_norm": 0.7141619920730591,
      "learning_rate": 0.000927933501396387,
      "loss": 0.9082,
      "step": 2700
    },
    {
      "epoch": 3.515625,
      "eval_loss": 0.9734699726104736,
      "eval_runtime": 2.1328,
      "eval_samples_per_second": 1439.918,
      "eval_steps_per_second": 90.024,
      "step": 2700
    },
    {
      "epoch": 3.5286458333333335,
      "grad_norm": 0.7494006752967834,
      "learning_rate": 0.0009274019610299487,
      "loss": 0.9024,
      "step": 2710
    },
    {
      "epoch": 3.5416666666666665,
      "grad_norm": 0.6491937637329102,
      "learning_rate": 0.00092686862102316,
      "loss": 0.9124,
      "step": 2720
    },
    {
      "epoch": 3.5546875,
      "grad_norm": 0.8571292757987976,
      "learning_rate": 0.0009263334836217295,
      "loss": 0.9205,
      "step": 2730
    },
    {
      "epoch": 3.5677083333333335,
      "grad_norm": 0.7101938128471375,
      "learning_rate": 0.0009257965510789334,
      "loss": 0.9123,
      "step": 2740
    },
    {
      "epoch": 3.5807291666666665,
      "grad_norm": 0.6004734635353088,
      "learning_rate": 0.0009252578256556074,
      "loss": 0.9066,
      "step": 2750
    },
    {
      "epoch": 3.59375,
      "grad_norm": 1.3482993841171265,
      "learning_rate": 0.000924717309620136,
      "loss": 0.936,
      "step": 2760
    },
    {
      "epoch": 3.6067708333333335,
      "grad_norm": 0.6261250376701355,
      "learning_rate": 0.0009241750052484435,
      "loss": 0.9166,
      "step": 2770
    },
    {
      "epoch": 3.6197916666666665,
      "grad_norm": 0.6556333303451538,
      "learning_rate": 0.0009236309148239839,
      "loss": 0.9024,
      "step": 2780
    },
    {
      "epoch": 3.6328125,
      "grad_norm": 0.793494462966919,
      "learning_rate": 0.0009230850406377322,
      "loss": 0.919,
      "step": 2790
    },
    {
      "epoch": 3.6458333333333335,
      "grad_norm": 1.7694292068481445,
      "learning_rate": 0.0009225373849881738,
      "loss": 0.9142,
      "step": 2800
    },
    {
      "epoch": 3.6458333333333335,
      "eval_loss": 0.9644098281860352,
      "eval_runtime": 2.6434,
      "eval_samples_per_second": 1161.782,
      "eval_steps_per_second": 72.635,
      "step": 2800
    },
    {
      "epoch": 3.6588541666666665,
      "grad_norm": 1.278599500656128,
      "learning_rate": 0.0009219879501812951,
      "loss": 0.895,
      "step": 2810
    },
    {
      "epoch": 3.671875,
      "grad_norm": 0.8968805074691772,
      "learning_rate": 0.0009214367385305745,
      "loss": 0.9064,
      "step": 2820
    },
    {
      "epoch": 3.6848958333333335,
      "grad_norm": 1.153709888458252,
      "learning_rate": 0.0009208837523569713,
      "loss": 0.8953,
      "step": 2830
    },
    {
      "epoch": 3.6979166666666665,
      "grad_norm": 0.8073410987854004,
      "learning_rate": 0.0009203289939889174,
      "loss": 0.8997,
      "step": 2840
    },
    {
      "epoch": 3.7109375,
      "grad_norm": 0.7820276021957397,
      "learning_rate": 0.0009197724657623066,
      "loss": 0.9085,
      "step": 2850
    },
    {
      "epoch": 3.7239583333333335,
      "grad_norm": 0.9155422449111938,
      "learning_rate": 0.0009192141700204844,
      "loss": 0.9005,
      "step": 2860
    },
    {
      "epoch": 3.7369791666666665,
      "grad_norm": 0.6245589852333069,
      "learning_rate": 0.0009186541091142395,
      "loss": 0.9125,
      "step": 2870
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.7800516486167908,
      "learning_rate": 0.0009180922854017927,
      "loss": 0.8996,
      "step": 2880
    },
    {
      "epoch": 3.7630208333333335,
      "grad_norm": 0.6425206065177917,
      "learning_rate": 0.0009175287012487873,
      "loss": 0.8997,
      "step": 2890
    },
    {
      "epoch": 3.7760416666666665,
      "grad_norm": 1.765030026435852,
      "learning_rate": 0.0009169633590282792,
      "loss": 0.8997,
      "step": 2900
    },
    {
      "epoch": 3.7760416666666665,
      "eval_loss": 0.9750373959541321,
      "eval_runtime": 2.2122,
      "eval_samples_per_second": 1388.211,
      "eval_steps_per_second": 86.791,
      "step": 2900
    },
    {
      "epoch": 3.7890625,
      "grad_norm": 0.9485762715339661,
      "learning_rate": 0.0009163962611207271,
      "loss": 0.9037,
      "step": 2910
    },
    {
      "epoch": 3.8020833333333335,
      "grad_norm": 0.9173509478569031,
      "learning_rate": 0.0009158274099139822,
      "loss": 0.897,
      "step": 2920
    },
    {
      "epoch": 3.8151041666666665,
      "grad_norm": 0.691145122051239,
      "learning_rate": 0.0009152568078032783,
      "loss": 0.9277,
      "step": 2930
    },
    {
      "epoch": 3.828125,
      "grad_norm": 0.8100621104240417,
      "learning_rate": 0.0009146844571912213,
      "loss": 0.9367,
      "step": 2940
    },
    {
      "epoch": 3.8411458333333335,
      "grad_norm": 1.286795735359192,
      "learning_rate": 0.0009141103604877798,
      "loss": 0.9063,
      "step": 2950
    },
    {
      "epoch": 3.8541666666666665,
      "grad_norm": 0.7251582145690918,
      "learning_rate": 0.0009135345201102746,
      "loss": 0.9106,
      "step": 2960
    },
    {
      "epoch": 3.8671875,
      "grad_norm": 0.5277442932128906,
      "learning_rate": 0.0009129569384833681,
      "loss": 0.9059,
      "step": 2970
    },
    {
      "epoch": 3.8802083333333335,
      "grad_norm": 0.6790202856063843,
      "learning_rate": 0.0009123776180390551,
      "loss": 0.9105,
      "step": 2980
    },
    {
      "epoch": 3.8932291666666665,
      "grad_norm": 0.7265515923500061,
      "learning_rate": 0.0009117965612166513,
      "loss": 0.9079,
      "step": 2990
    },
    {
      "epoch": 3.90625,
      "grad_norm": 1.1569430828094482,
      "learning_rate": 0.0009112137704627841,
      "loss": 0.8967,
      "step": 3000
    },
    {
      "epoch": 3.90625,
      "eval_loss": 0.9639607071876526,
      "eval_runtime": 2.4441,
      "eval_samples_per_second": 1256.506,
      "eval_steps_per_second": 78.557,
      "step": 3000
    },
    {
      "epoch": 3.9192708333333335,
      "grad_norm": 1.008482813835144,
      "learning_rate": 0.0009106292482313818,
      "loss": 0.9041,
      "step": 3010
    },
    {
      "epoch": 3.9322916666666665,
      "grad_norm": 0.8903132677078247,
      "learning_rate": 0.0009100429969836634,
      "loss": 0.911,
      "step": 3020
    },
    {
      "epoch": 3.9453125,
      "grad_norm": 0.6842715740203857,
      "learning_rate": 0.000909455019188128,
      "loss": 0.8952,
      "step": 3030
    },
    {
      "epoch": 3.9583333333333335,
      "grad_norm": 0.7678486704826355,
      "learning_rate": 0.0009088653173205446,
      "loss": 0.9089,
      "step": 3040
    },
    {
      "epoch": 3.9713541666666665,
      "grad_norm": 0.7279532551765442,
      "learning_rate": 0.0009082738938639421,
      "loss": 0.9138,
      "step": 3050
    },
    {
      "epoch": 3.984375,
      "grad_norm": 0.8462597131729126,
      "learning_rate": 0.0009076807513085976,
      "loss": 0.9069,
      "step": 3060
    },
    {
      "epoch": 3.9973958333333335,
      "grad_norm": 0.7995531558990479,
      "learning_rate": 0.0009070858921520277,
      "loss": 0.9004,
      "step": 3070
    },
    {
      "epoch": 4.010416666666667,
      "grad_norm": 1.2330052852630615,
      "learning_rate": 0.000906489318898976,
      "loss": 0.9108,
      "step": 3080
    },
    {
      "epoch": 4.0234375,
      "grad_norm": 0.7242454290390015,
      "learning_rate": 0.0009058910340614043,
      "loss": 0.8957,
      "step": 3090
    },
    {
      "epoch": 4.036458333333333,
      "grad_norm": 1.0295904874801636,
      "learning_rate": 0.0009052910401584812,
      "loss": 0.9057,
      "step": 3100
    },
    {
      "epoch": 4.036458333333333,
      "eval_loss": 0.9583218097686768,
      "eval_runtime": 3.0103,
      "eval_samples_per_second": 1020.155,
      "eval_steps_per_second": 63.78,
      "step": 3100
    },
    {
      "epoch": 4.049479166666667,
      "grad_norm": 0.6718576550483704,
      "learning_rate": 0.0009046893397165711,
      "loss": 0.8883,
      "step": 3110
    },
    {
      "epoch": 4.0625,
      "grad_norm": 0.7263920307159424,
      "learning_rate": 0.0009040859352692248,
      "loss": 0.8983,
      "step": 3120
    },
    {
      "epoch": 4.075520833333333,
      "grad_norm": 0.8366743922233582,
      "learning_rate": 0.0009034808293571672,
      "loss": 0.8919,
      "step": 3130
    },
    {
      "epoch": 4.088541666666667,
      "grad_norm": 0.7741657495498657,
      "learning_rate": 0.000902874024528288,
      "loss": 0.9018,
      "step": 3140
    },
    {
      "epoch": 4.1015625,
      "grad_norm": 0.5869261622428894,
      "learning_rate": 0.0009022655233376307,
      "loss": 0.9132,
      "step": 3150
    },
    {
      "epoch": 4.114583333333333,
      "grad_norm": 0.8892366886138916,
      "learning_rate": 0.0009016553283473808,
      "loss": 0.8919,
      "step": 3160
    },
    {
      "epoch": 4.127604166666667,
      "grad_norm": 0.6675017476081848,
      "learning_rate": 0.0009010434421268564,
      "loss": 0.8846,
      "step": 3170
    },
    {
      "epoch": 4.140625,
      "grad_norm": 0.8377596735954285,
      "learning_rate": 0.0009004298672524966,
      "loss": 0.883,
      "step": 3180
    },
    {
      "epoch": 4.153645833333333,
      "grad_norm": 1.2071220874786377,
      "learning_rate": 0.000899814606307851,
      "loss": 0.8832,
      "step": 3190
    },
    {
      "epoch": 4.166666666666667,
      "grad_norm": 1.1051757335662842,
      "learning_rate": 0.0008991976618835685,
      "loss": 0.887,
      "step": 3200
    },
    {
      "epoch": 4.166666666666667,
      "eval_loss": 0.9448989629745483,
      "eval_runtime": 2.171,
      "eval_samples_per_second": 1414.557,
      "eval_steps_per_second": 88.439,
      "step": 3200
    },
    {
      "epoch": 4.1796875,
      "grad_norm": 0.7500959038734436,
      "learning_rate": 0.0008985790365773862,
      "loss": 0.8905,
      "step": 3210
    },
    {
      "epoch": 4.192708333333333,
      "grad_norm": 0.6155418753623962,
      "learning_rate": 0.0008979587329941196,
      "loss": 0.8804,
      "step": 3220
    },
    {
      "epoch": 4.205729166666667,
      "grad_norm": 0.824845016002655,
      "learning_rate": 0.0008973367537456502,
      "loss": 0.9004,
      "step": 3230
    },
    {
      "epoch": 4.21875,
      "grad_norm": 0.7010290622711182,
      "learning_rate": 0.0008967131014509151,
      "loss": 0.8767,
      "step": 3240
    },
    {
      "epoch": 4.231770833333333,
      "grad_norm": 1.5003663301467896,
      "learning_rate": 0.0008960877787358968,
      "loss": 0.8844,
      "step": 3250
    },
    {
      "epoch": 4.244791666666667,
      "grad_norm": 1.1113866567611694,
      "learning_rate": 0.0008954607882336102,
      "loss": 0.8883,
      "step": 3260
    },
    {
      "epoch": 4.2578125,
      "grad_norm": 1.0299681425094604,
      "learning_rate": 0.0008948321325840937,
      "loss": 0.8859,
      "step": 3270
    },
    {
      "epoch": 4.270833333333333,
      "grad_norm": 0.5946207046508789,
      "learning_rate": 0.0008942018144343964,
      "loss": 0.8744,
      "step": 3280
    },
    {
      "epoch": 4.283854166666667,
      "grad_norm": 1.2534123659133911,
      "learning_rate": 0.000893569836438568,
      "loss": 0.8813,
      "step": 3290
    },
    {
      "epoch": 4.296875,
      "grad_norm": 1.4887906312942505,
      "learning_rate": 0.0008929362012576469,
      "loss": 0.8889,
      "step": 3300
    },
    {
      "epoch": 4.296875,
      "eval_loss": 0.9139902591705322,
      "eval_runtime": 2.0754,
      "eval_samples_per_second": 1479.693,
      "eval_steps_per_second": 92.511,
      "step": 3300
    },
    {
      "epoch": 4.309895833333333,
      "grad_norm": 0.7906559109687805,
      "learning_rate": 0.0008923009115596498,
      "loss": 0.8628,
      "step": 3310
    },
    {
      "epoch": 4.322916666666667,
      "grad_norm": 1.2354589700698853,
      "learning_rate": 0.0008916639700195593,
      "loss": 0.8779,
      "step": 3320
    },
    {
      "epoch": 4.3359375,
      "grad_norm": 1.180808424949646,
      "learning_rate": 0.0008910253793193138,
      "loss": 0.8796,
      "step": 3330
    },
    {
      "epoch": 4.348958333333333,
      "grad_norm": 1.3391308784484863,
      "learning_rate": 0.0008903851421477959,
      "loss": 0.8635,
      "step": 3340
    },
    {
      "epoch": 4.361979166666667,
      "grad_norm": 1.9308456182479858,
      "learning_rate": 0.0008897432612008205,
      "loss": 0.8818,
      "step": 3350
    },
    {
      "epoch": 4.375,
      "grad_norm": 1.5791096687316895,
      "learning_rate": 0.0008890997391811239,
      "loss": 0.8843,
      "step": 3360
    },
    {
      "epoch": 4.388020833333333,
      "grad_norm": 0.8206344246864319,
      "learning_rate": 0.0008884545787983528,
      "loss": 0.8759,
      "step": 3370
    },
    {
      "epoch": 4.401041666666667,
      "grad_norm": 0.8355898261070251,
      "learning_rate": 0.0008878077827690521,
      "loss": 0.871,
      "step": 3380
    },
    {
      "epoch": 4.4140625,
      "grad_norm": 0.746309757232666,
      "learning_rate": 0.0008871593538166536,
      "loss": 0.8723,
      "step": 3390
    },
    {
      "epoch": 4.427083333333333,
      "grad_norm": 1.033940076828003,
      "learning_rate": 0.0008865092946714657,
      "loss": 0.8713,
      "step": 3400
    },
    {
      "epoch": 4.427083333333333,
      "eval_loss": 0.9054687023162842,
      "eval_runtime": 2.2685,
      "eval_samples_per_second": 1353.748,
      "eval_steps_per_second": 84.637,
      "step": 3400
    },
    {
      "epoch": 4.440104166666667,
      "grad_norm": 0.9665868282318115,
      "learning_rate": 0.00088585760807066,
      "loss": 0.8598,
      "step": 3410
    },
    {
      "epoch": 4.453125,
      "grad_norm": 1.1193761825561523,
      "learning_rate": 0.000885204296758261,
      "loss": 0.8908,
      "step": 3420
    },
    {
      "epoch": 4.466145833333333,
      "grad_norm": 0.9364194869995117,
      "learning_rate": 0.0008845493634851347,
      "loss": 0.8743,
      "step": 3430
    },
    {
      "epoch": 4.479166666666667,
      "grad_norm": 0.7839981317520142,
      "learning_rate": 0.0008838928110089762,
      "loss": 0.854,
      "step": 3440
    },
    {
      "epoch": 4.4921875,
      "grad_norm": 0.7842042446136475,
      "learning_rate": 0.0008832346420942987,
      "loss": 0.8523,
      "step": 3450
    },
    {
      "epoch": 4.505208333333333,
      "grad_norm": 0.6982267498970032,
      "learning_rate": 0.0008825748595124214,
      "loss": 0.8682,
      "step": 3460
    },
    {
      "epoch": 4.518229166666667,
      "grad_norm": 0.947842001914978,
      "learning_rate": 0.0008819134660414584,
      "loss": 0.8421,
      "step": 3470
    },
    {
      "epoch": 4.53125,
      "grad_norm": 1.0158631801605225,
      "learning_rate": 0.0008812504644663065,
      "loss": 0.8625,
      "step": 3480
    },
    {
      "epoch": 4.544270833333333,
      "grad_norm": 0.8270583748817444,
      "learning_rate": 0.0008805858575786339,
      "loss": 0.8436,
      "step": 3490
    },
    {
      "epoch": 4.557291666666667,
      "grad_norm": 0.8846573233604431,
      "learning_rate": 0.0008799196481768676,
      "loss": 0.83,
      "step": 3500
    },
    {
      "epoch": 4.557291666666667,
      "eval_loss": 0.8836693167686462,
      "eval_runtime": 2.3739,
      "eval_samples_per_second": 1293.643,
      "eval_steps_per_second": 80.879,
      "step": 3500
    },
    {
      "epoch": 4.5703125,
      "grad_norm": 0.7342211604118347,
      "learning_rate": 0.0008792518390661831,
      "loss": 0.8418,
      "step": 3510
    },
    {
      "epoch": 4.583333333333333,
      "grad_norm": 0.7470449805259705,
      "learning_rate": 0.000878582433058491,
      "loss": 0.8603,
      "step": 3520
    },
    {
      "epoch": 4.596354166666667,
      "grad_norm": 0.9074499011039734,
      "learning_rate": 0.0008779114329724265,
      "loss": 0.8508,
      "step": 3530
    },
    {
      "epoch": 4.609375,
      "grad_norm": 0.6772894859313965,
      "learning_rate": 0.0008772388416333361,
      "loss": 0.848,
      "step": 3540
    },
    {
      "epoch": 4.622395833333333,
      "grad_norm": 0.7455216646194458,
      "learning_rate": 0.0008765646618732673,
      "loss": 0.8252,
      "step": 3550
    },
    {
      "epoch": 4.635416666666667,
      "grad_norm": 1.0698027610778809,
      "learning_rate": 0.0008758888965309553,
      "loss": 0.8357,
      "step": 3560
    },
    {
      "epoch": 4.6484375,
      "grad_norm": 0.8904828429222107,
      "learning_rate": 0.0008752115484518122,
      "loss": 0.8713,
      "step": 3570
    },
    {
      "epoch": 4.661458333333333,
      "grad_norm": 0.9561976790428162,
      "learning_rate": 0.0008745326204879138,
      "loss": 0.8669,
      "step": 3580
    },
    {
      "epoch": 4.674479166666667,
      "grad_norm": 1.1239051818847656,
      "learning_rate": 0.0008738521154979888,
      "loss": 0.8585,
      "step": 3590
    },
    {
      "epoch": 4.6875,
      "grad_norm": 2.6389315128326416,
      "learning_rate": 0.000873170036347406,
      "loss": 0.8434,
      "step": 3600
    },
    {
      "epoch": 4.6875,
      "eval_loss": 0.872273325920105,
      "eval_runtime": 2.2347,
      "eval_samples_per_second": 1374.24,
      "eval_steps_per_second": 85.918,
      "step": 3600
    },
    {
      "epoch": 4.700520833333333,
      "grad_norm": 1.3415155410766602,
      "learning_rate": 0.0008724863859081622,
      "loss": 0.8265,
      "step": 3610
    },
    {
      "epoch": 4.713541666666667,
      "grad_norm": 1.1820827722549438,
      "learning_rate": 0.0008718011670588709,
      "loss": 0.8543,
      "step": 3620
    },
    {
      "epoch": 4.7265625,
      "grad_norm": 0.8579853773117065,
      "learning_rate": 0.0008711143826847491,
      "loss": 0.8423,
      "step": 3630
    },
    {
      "epoch": 4.739583333333333,
      "grad_norm": 0.97223299741745,
      "learning_rate": 0.0008704260356776059,
      "loss": 0.8425,
      "step": 3640
    },
    {
      "epoch": 4.752604166666667,
      "grad_norm": 0.6476858258247375,
      "learning_rate": 0.0008697361289358301,
      "loss": 0.8513,
      "step": 3650
    },
    {
      "epoch": 4.765625,
      "grad_norm": 1.447845697402954,
      "learning_rate": 0.000869044665364378,
      "loss": 0.8402,
      "step": 3660
    },
    {
      "epoch": 4.778645833333333,
      "grad_norm": 0.947535514831543,
      "learning_rate": 0.0008683516478747611,
      "loss": 0.844,
      "step": 3670
    },
    {
      "epoch": 4.791666666666667,
      "grad_norm": 1.2410160303115845,
      "learning_rate": 0.0008676570793850338,
      "loss": 0.8451,
      "step": 3680
    },
    {
      "epoch": 4.8046875,
      "grad_norm": 1.0655980110168457,
      "learning_rate": 0.0008669609628197816,
      "loss": 0.8291,
      "step": 3690
    },
    {
      "epoch": 4.817708333333333,
      "grad_norm": 1.4534552097320557,
      "learning_rate": 0.0008662633011101085,
      "loss": 0.8442,
      "step": 3700
    },
    {
      "epoch": 4.817708333333333,
      "eval_loss": 0.8646258115768433,
      "eval_runtime": 2.0722,
      "eval_samples_per_second": 1481.991,
      "eval_steps_per_second": 92.655,
      "step": 3700
    },
    {
      "epoch": 4.830729166666667,
      "grad_norm": 1.1143466234207153,
      "learning_rate": 0.0008655640971936235,
      "loss": 0.8447,
      "step": 3710
    },
    {
      "epoch": 4.84375,
      "grad_norm": 1.39607572555542,
      "learning_rate": 0.0008648633540144304,
      "loss": 0.8448,
      "step": 3720
    },
    {
      "epoch": 4.856770833333333,
      "grad_norm": 1.0681291818618774,
      "learning_rate": 0.0008641610745231141,
      "loss": 0.8288,
      "step": 3730
    },
    {
      "epoch": 4.869791666666667,
      "grad_norm": 0.9227539300918579,
      "learning_rate": 0.0008634572616767279,
      "loss": 0.8498,
      "step": 3740
    },
    {
      "epoch": 4.8828125,
      "grad_norm": 1.2532411813735962,
      "learning_rate": 0.000862751918438782,
      "loss": 0.8237,
      "step": 3750
    },
    {
      "epoch": 4.895833333333333,
      "grad_norm": 1.1262311935424805,
      "learning_rate": 0.0008620450477792303,
      "loss": 0.8359,
      "step": 3760
    },
    {
      "epoch": 4.908854166666667,
      "grad_norm": 0.8760889768600464,
      "learning_rate": 0.0008613366526744584,
      "loss": 0.8407,
      "step": 3770
    },
    {
      "epoch": 4.921875,
      "grad_norm": 0.9503016471862793,
      "learning_rate": 0.0008606267361072702,
      "loss": 0.8257,
      "step": 3780
    },
    {
      "epoch": 4.934895833333333,
      "grad_norm": 1.030220627784729,
      "learning_rate": 0.0008599153010668768,
      "loss": 0.8448,
      "step": 3790
    },
    {
      "epoch": 4.947916666666667,
      "grad_norm": 1.0918231010437012,
      "learning_rate": 0.0008592023505488824,
      "loss": 0.8438,
      "step": 3800
    },
    {
      "epoch": 4.947916666666667,
      "eval_loss": 0.8571385145187378,
      "eval_runtime": 2.1241,
      "eval_samples_per_second": 1445.813,
      "eval_steps_per_second": 90.393,
      "step": 3800
    },
    {
      "epoch": 4.9609375,
      "grad_norm": 0.9894888997077942,
      "learning_rate": 0.0008584878875552727,
      "loss": 0.8218,
      "step": 3810
    },
    {
      "epoch": 4.973958333333333,
      "grad_norm": 1.4627394676208496,
      "learning_rate": 0.0008577719150944016,
      "loss": 0.8281,
      "step": 3820
    },
    {
      "epoch": 4.986979166666667,
      "grad_norm": 1.0011359453201294,
      "learning_rate": 0.0008570544361809791,
      "loss": 0.8364,
      "step": 3830
    },
    {
      "epoch": 5.0,
      "grad_norm": 1.3621121644973755,
      "learning_rate": 0.0008563354538360584,
      "loss": 0.8407,
      "step": 3840
    },
    {
      "epoch": 5.013020833333333,
      "grad_norm": 0.8344822525978088,
      "learning_rate": 0.000855614971087023,
      "loss": 0.8154,
      "step": 3850
    },
    {
      "epoch": 5.026041666666667,
      "grad_norm": 0.8311483860015869,
      "learning_rate": 0.0008548929909675735,
      "loss": 0.8197,
      "step": 3860
    },
    {
      "epoch": 5.0390625,
      "grad_norm": 0.6658823490142822,
      "learning_rate": 0.0008541695165177168,
      "loss": 0.811,
      "step": 3870
    },
    {
      "epoch": 5.052083333333333,
      "grad_norm": 1.3068492412567139,
      "learning_rate": 0.0008534445507837504,
      "loss": 0.7887,
      "step": 3880
    },
    {
      "epoch": 5.065104166666667,
      "grad_norm": 0.952122151851654,
      "learning_rate": 0.0008527180968182522,
      "loss": 0.825,
      "step": 3890
    },
    {
      "epoch": 5.078125,
      "grad_norm": 0.8528977632522583,
      "learning_rate": 0.0008519901576800657,
      "loss": 0.8369,
      "step": 3900
    },
    {
      "epoch": 5.078125,
      "eval_loss": 0.8530933260917664,
      "eval_runtime": 2.0593,
      "eval_samples_per_second": 1491.303,
      "eval_steps_per_second": 93.237,
      "step": 3900
    },
    {
      "epoch": 5.091145833333333,
      "grad_norm": 1.077829122543335,
      "learning_rate": 0.0008512607364342887,
      "loss": 0.8361,
      "step": 3910
    },
    {
      "epoch": 5.104166666666667,
      "grad_norm": 1.226416826248169,
      "learning_rate": 0.000850529836152259,
      "loss": 0.822,
      "step": 3920
    },
    {
      "epoch": 5.1171875,
      "grad_norm": 2.9149069786071777,
      "learning_rate": 0.0008497974599115423,
      "loss": 0.8389,
      "step": 3930
    },
    {
      "epoch": 5.130208333333333,
      "grad_norm": 0.914822518825531,
      "learning_rate": 0.0008490636107959193,
      "loss": 0.821,
      "step": 3940
    },
    {
      "epoch": 5.143229166666667,
      "grad_norm": 1.104305386543274,
      "learning_rate": 0.0008483282918953723,
      "loss": 0.8169,
      "step": 3950
    },
    {
      "epoch": 5.15625,
      "grad_norm": 1.291260004043579,
      "learning_rate": 0.000847591506306072,
      "loss": 0.8218,
      "step": 3960
    },
    {
      "epoch": 5.169270833333333,
      "grad_norm": 0.9405229091644287,
      "learning_rate": 0.0008468532571303653,
      "loss": 0.8149,
      "step": 3970
    },
    {
      "epoch": 5.182291666666667,
      "grad_norm": 0.9072703123092651,
      "learning_rate": 0.0008461135474767619,
      "loss": 0.8067,
      "step": 3980
    },
    {
      "epoch": 5.1953125,
      "grad_norm": 1.014986276626587,
      "learning_rate": 0.0008453723804599202,
      "loss": 0.8056,
      "step": 3990
    },
    {
      "epoch": 5.208333333333333,
      "grad_norm": 1.2331058979034424,
      "learning_rate": 0.0008446297592006359,
      "loss": 0.8409,
      "step": 4000
    },
    {
      "epoch": 5.208333333333333,
      "eval_loss": 0.8425207734107971,
      "eval_runtime": 2.0526,
      "eval_samples_per_second": 1496.179,
      "eval_steps_per_second": 93.542,
      "step": 4000
    },
    {
      "epoch": 5.221354166666667,
      "grad_norm": 1.8580868244171143,
      "learning_rate": 0.0008438856868258277,
      "loss": 0.8188,
      "step": 4010
    },
    {
      "epoch": 5.234375,
      "grad_norm": 1.03144109249115,
      "learning_rate": 0.0008431401664685243,
      "loss": 0.8202,
      "step": 4020
    },
    {
      "epoch": 5.247395833333333,
      "grad_norm": 0.8920867443084717,
      "learning_rate": 0.0008423932012678515,
      "loss": 0.8035,
      "step": 4030
    },
    {
      "epoch": 5.260416666666667,
      "grad_norm": 0.7675368785858154,
      "learning_rate": 0.000841644794369019,
      "loss": 0.809,
      "step": 4040
    },
    {
      "epoch": 5.2734375,
      "grad_norm": 0.6225672364234924,
      "learning_rate": 0.0008408949489233068,
      "loss": 0.8133,
      "step": 4050
    },
    {
      "epoch": 5.286458333333333,
      "grad_norm": 1.0200246572494507,
      "learning_rate": 0.0008401436680880519,
      "loss": 0.8014,
      "step": 4060
    },
    {
      "epoch": 5.299479166666667,
      "grad_norm": 0.974577009677887,
      "learning_rate": 0.0008393909550266354,
      "loss": 0.7928,
      "step": 4070
    },
    {
      "epoch": 5.3125,
      "grad_norm": 1.2188806533813477,
      "learning_rate": 0.0008386368129084694,
      "loss": 0.7929,
      "step": 4080
    },
    {
      "epoch": 5.325520833333333,
      "grad_norm": 1.009699821472168,
      "learning_rate": 0.0008378812449089826,
      "loss": 0.8106,
      "step": 4090
    },
    {
      "epoch": 5.338541666666667,
      "grad_norm": 0.6358245611190796,
      "learning_rate": 0.0008371242542096081,
      "loss": 0.8008,
      "step": 4100
    },
    {
      "epoch": 5.338541666666667,
      "eval_loss": 0.8351525068283081,
      "eval_runtime": 2.0479,
      "eval_samples_per_second": 1499.56,
      "eval_steps_per_second": 93.753,
      "step": 4100
    },
    {
      "epoch": 5.3515625,
      "grad_norm": 0.7858495116233826,
      "learning_rate": 0.0008363658439977692,
      "loss": 0.7882,
      "step": 4110
    },
    {
      "epoch": 5.364583333333333,
      "grad_norm": 0.9695323705673218,
      "learning_rate": 0.0008356060174668663,
      "loss": 0.8206,
      "step": 4120
    },
    {
      "epoch": 5.377604166666667,
      "grad_norm": 1.1370834112167358,
      "learning_rate": 0.0008348447778162636,
      "loss": 0.8092,
      "step": 4130
    },
    {
      "epoch": 5.390625,
      "grad_norm": 1.504071831703186,
      "learning_rate": 0.0008340821282512751,
      "loss": 0.8018,
      "step": 4140
    },
    {
      "epoch": 5.403645833333333,
      "grad_norm": 1.7117246389389038,
      "learning_rate": 0.0008333180719831522,
      "loss": 0.8232,
      "step": 4150
    },
    {
      "epoch": 5.416666666666667,
      "grad_norm": 0.7415554523468018,
      "learning_rate": 0.0008325526122290684,
      "loss": 0.8129,
      "step": 4160
    },
    {
      "epoch": 5.4296875,
      "grad_norm": 1.1786282062530518,
      "learning_rate": 0.0008317857522121077,
      "loss": 0.7939,
      "step": 4170
    },
    {
      "epoch": 5.442708333333333,
      "grad_norm": 0.7455736398696899,
      "learning_rate": 0.0008310174951612494,
      "loss": 0.8066,
      "step": 4180
    },
    {
      "epoch": 5.455729166666667,
      "grad_norm": 0.6805230379104614,
      "learning_rate": 0.000830247844311356,
      "loss": 0.7991,
      "step": 4190
    },
    {
      "epoch": 5.46875,
      "grad_norm": 0.8231510519981384,
      "learning_rate": 0.0008294768029031578,
      "loss": 0.7958,
      "step": 4200
    },
    {
      "epoch": 5.46875,
      "eval_loss": 0.8214922547340393,
      "eval_runtime": 2.0292,
      "eval_samples_per_second": 1513.411,
      "eval_steps_per_second": 94.619,
      "step": 4200
    },
    {
      "epoch": 5.481770833333333,
      "grad_norm": 0.7515600323677063,
      "learning_rate": 0.0008287043741832412,
      "loss": 0.8111,
      "step": 4210
    },
    {
      "epoch": 5.494791666666667,
      "grad_norm": 0.6855505704879761,
      "learning_rate": 0.0008279305614040337,
      "loss": 0.8101,
      "step": 4220
    },
    {
      "epoch": 5.5078125,
      "grad_norm": 0.9614880681037903,
      "learning_rate": 0.0008271553678237904,
      "loss": 0.8088,
      "step": 4230
    },
    {
      "epoch": 5.520833333333333,
      "grad_norm": 0.8558812737464905,
      "learning_rate": 0.0008263787967065809,
      "loss": 0.8102,
      "step": 4240
    },
    {
      "epoch": 5.533854166666667,
      "grad_norm": 0.9622074365615845,
      "learning_rate": 0.0008256008513222747,
      "loss": 0.8078,
      "step": 4250
    },
    {
      "epoch": 5.546875,
      "grad_norm": 0.7933893203735352,
      "learning_rate": 0.000824821534946528,
      "loss": 0.7936,
      "step": 4260
    },
    {
      "epoch": 5.559895833333333,
      "grad_norm": 0.5920971632003784,
      "learning_rate": 0.0008240408508607701,
      "loss": 0.7818,
      "step": 4270
    },
    {
      "epoch": 5.572916666666667,
      "grad_norm": 0.8529559969902039,
      "learning_rate": 0.0008232588023521887,
      "loss": 0.8033,
      "step": 4280
    },
    {
      "epoch": 5.5859375,
      "grad_norm": 0.7268394231796265,
      "learning_rate": 0.0008224753927137169,
      "loss": 0.8136,
      "step": 4290
    },
    {
      "epoch": 5.598958333333333,
      "grad_norm": 0.6770470142364502,
      "learning_rate": 0.0008216906252440192,
      "loss": 0.7936,
      "step": 4300
    },
    {
      "epoch": 5.598958333333333,
      "eval_loss": 0.8242894411087036,
      "eval_runtime": 2.1575,
      "eval_samples_per_second": 1423.428,
      "eval_steps_per_second": 88.993,
      "step": 4300
    },
    {
      "epoch": 5.611979166666667,
      "grad_norm": 1.2375096082687378,
      "learning_rate": 0.0008209045032474771,
      "loss": 0.7986,
      "step": 4310
    },
    {
      "epoch": 5.625,
      "grad_norm": 1.231029987335205,
      "learning_rate": 0.0008201170300341755,
      "loss": 0.8018,
      "step": 4320
    },
    {
      "epoch": 5.638020833333333,
      "grad_norm": 0.8107547760009766,
      "learning_rate": 0.0008193282089198897,
      "loss": 0.7924,
      "step": 4330
    },
    {
      "epoch": 5.651041666666667,
      "grad_norm": 1.2188702821731567,
      "learning_rate": 0.0008185380432260692,
      "loss": 0.805,
      "step": 4340
    },
    {
      "epoch": 5.6640625,
      "grad_norm": 1.3196308612823486,
      "learning_rate": 0.0008177465362798257,
      "loss": 0.8254,
      "step": 4350
    },
    {
      "epoch": 5.677083333333333,
      "grad_norm": 1.674230694770813,
      "learning_rate": 0.0008169536914139189,
      "loss": 0.8045,
      "step": 4360
    },
    {
      "epoch": 5.690104166666667,
      "grad_norm": 1.1012816429138184,
      "learning_rate": 0.0008161595119667411,
      "loss": 0.8242,
      "step": 4370
    },
    {
      "epoch": 5.703125,
      "grad_norm": 0.7674702405929565,
      "learning_rate": 0.0008153640012823049,
      "loss": 0.7837,
      "step": 4380
    },
    {
      "epoch": 5.716145833333333,
      "grad_norm": 1.9618160724639893,
      "learning_rate": 0.0008145671627102277,
      "loss": 0.7846,
      "step": 4390
    },
    {
      "epoch": 5.729166666666667,
      "grad_norm": 0.9642530679702759,
      "learning_rate": 0.0008137689996057183,
      "loss": 0.8121,
      "step": 4400
    },
    {
      "epoch": 5.729166666666667,
      "eval_loss": 0.8247301578521729,
      "eval_runtime": 2.0389,
      "eval_samples_per_second": 1506.222,
      "eval_steps_per_second": 94.17,
      "step": 4400
    },
    {
      "epoch": 5.7421875,
      "grad_norm": 0.9012106657028198,
      "learning_rate": 0.0008129695153295626,
      "loss": 0.8029,
      "step": 4410
    },
    {
      "epoch": 5.755208333333333,
      "grad_norm": 1.0183606147766113,
      "learning_rate": 0.0008121687132481101,
      "loss": 0.8045,
      "step": 4420
    },
    {
      "epoch": 5.768229166666667,
      "grad_norm": 0.7421652674674988,
      "learning_rate": 0.0008113665967332582,
      "loss": 0.7985,
      "step": 4430
    },
    {
      "epoch": 5.78125,
      "grad_norm": 0.7959133982658386,
      "learning_rate": 0.0008105631691624393,
      "loss": 0.7913,
      "step": 4440
    },
    {
      "epoch": 5.794270833333333,
      "grad_norm": 0.8684247732162476,
      "learning_rate": 0.0008097584339186066,
      "loss": 0.7904,
      "step": 4450
    },
    {
      "epoch": 5.807291666666667,
      "grad_norm": 0.8244611620903015,
      "learning_rate": 0.0008089523943902187,
      "loss": 0.8018,
      "step": 4460
    },
    {
      "epoch": 5.8203125,
      "grad_norm": 0.9034202694892883,
      "learning_rate": 0.0008081450539712265,
      "loss": 0.8174,
      "step": 4470
    },
    {
      "epoch": 5.833333333333333,
      "grad_norm": 0.7145469784736633,
      "learning_rate": 0.0008073364160610588,
      "loss": 0.8094,
      "step": 4480
    },
    {
      "epoch": 5.846354166666667,
      "grad_norm": 0.7540609836578369,
      "learning_rate": 0.0008065264840646071,
      "loss": 0.8134,
      "step": 4490
    },
    {
      "epoch": 5.859375,
      "grad_norm": 1.5042020082473755,
      "learning_rate": 0.0008057152613922119,
      "loss": 0.7945,
      "step": 4500
    },
    {
      "epoch": 5.859375,
      "eval_loss": 0.8211337327957153,
      "eval_runtime": 2.1306,
      "eval_samples_per_second": 1441.39,
      "eval_steps_per_second": 90.116,
      "step": 4500
    },
    {
      "epoch": 5.872395833333333,
      "grad_norm": 2.352172613143921,
      "learning_rate": 0.000804902751459649,
      "loss": 0.8098,
      "step": 4510
    },
    {
      "epoch": 5.885416666666667,
      "grad_norm": 1.500117540359497,
      "learning_rate": 0.0008040889576881135,
      "loss": 0.799,
      "step": 4520
    },
    {
      "epoch": 5.8984375,
      "grad_norm": 0.9216808676719666,
      "learning_rate": 0.0008032738835042068,
      "loss": 0.7833,
      "step": 4530
    },
    {
      "epoch": 5.911458333333333,
      "grad_norm": 0.86020827293396,
      "learning_rate": 0.0008024575323399216,
      "loss": 0.7895,
      "step": 4540
    },
    {
      "epoch": 5.924479166666667,
      "grad_norm": 0.8377103805541992,
      "learning_rate": 0.0008016399076326274,
      "loss": 0.7878,
      "step": 4550
    },
    {
      "epoch": 5.9375,
      "grad_norm": 0.6558135747909546,
      "learning_rate": 0.0008008210128250562,
      "loss": 0.798,
      "step": 4560
    },
    {
      "epoch": 5.950520833333333,
      "grad_norm": 0.8316189646720886,
      "learning_rate": 0.000800000851365288,
      "loss": 0.7838,
      "step": 4570
    },
    {
      "epoch": 5.963541666666667,
      "grad_norm": 0.9048812389373779,
      "learning_rate": 0.0007991794267067363,
      "loss": 0.8044,
      "step": 4580
    },
    {
      "epoch": 5.9765625,
      "grad_norm": 0.9272336363792419,
      "learning_rate": 0.0007983567423081331,
      "loss": 0.806,
      "step": 4590
    },
    {
      "epoch": 5.989583333333333,
      "grad_norm": 0.8565176725387573,
      "learning_rate": 0.0007975328016335153,
      "loss": 0.7851,
      "step": 4600
    },
    {
      "epoch": 5.989583333333333,
      "eval_loss": 0.825885534286499,
      "eval_runtime": 2.0986,
      "eval_samples_per_second": 1463.365,
      "eval_steps_per_second": 91.49,
      "step": 4600
    },
    {
      "epoch": 6.002604166666667,
      "grad_norm": 1.516136884689331,
      "learning_rate": 0.000796707608152209,
      "loss": 0.8009,
      "step": 4610
    },
    {
      "epoch": 6.015625,
      "grad_norm": 0.7132865786552429,
      "learning_rate": 0.000795881165338816,
      "loss": 0.7885,
      "step": 4620
    },
    {
      "epoch": 6.028645833333333,
      "grad_norm": 1.043491244316101,
      "learning_rate": 0.0007950534766731981,
      "loss": 0.7679,
      "step": 4630
    },
    {
      "epoch": 6.041666666666667,
      "grad_norm": 0.8824974298477173,
      "learning_rate": 0.0007942245456404629,
      "loss": 0.7813,
      "step": 4640
    },
    {
      "epoch": 6.0546875,
      "grad_norm": 0.7076281309127808,
      "learning_rate": 0.0007933943757309497,
      "loss": 0.7835,
      "step": 4650
    },
    {
      "epoch": 6.067708333333333,
      "grad_norm": 0.7075651288032532,
      "learning_rate": 0.000792562970440214,
      "loss": 0.7813,
      "step": 4660
    },
    {
      "epoch": 6.080729166666667,
      "grad_norm": 0.6619989275932312,
      "learning_rate": 0.0007917303332690129,
      "loss": 0.7832,
      "step": 4670
    },
    {
      "epoch": 6.09375,
      "grad_norm": 1.0434420108795166,
      "learning_rate": 0.0007908964677232906,
      "loss": 0.7797,
      "step": 4680
    },
    {
      "epoch": 6.106770833333333,
      "grad_norm": 0.8132249712944031,
      "learning_rate": 0.0007900613773141639,
      "loss": 0.7914,
      "step": 4690
    },
    {
      "epoch": 6.119791666666667,
      "grad_norm": 0.6633649468421936,
      "learning_rate": 0.0007892250655579063,
      "loss": 0.7722,
      "step": 4700
    },
    {
      "epoch": 6.119791666666667,
      "eval_loss": 0.8032964468002319,
      "eval_runtime": 2.1029,
      "eval_samples_per_second": 1460.354,
      "eval_steps_per_second": 91.302,
      "step": 4700
    },
    {
      "epoch": 6.1328125,
      "grad_norm": 1.17072331905365,
      "learning_rate": 0.000788387535975935,
      "loss": 0.7735,
      "step": 4710
    },
    {
      "epoch": 6.145833333333333,
      "grad_norm": 0.8454042077064514,
      "learning_rate": 0.0007875487920947941,
      "loss": 0.7764,
      "step": 4720
    },
    {
      "epoch": 6.158854166666667,
      "grad_norm": 0.7746113538742065,
      "learning_rate": 0.0007867088374461412,
      "loss": 0.7732,
      "step": 4730
    },
    {
      "epoch": 6.171875,
      "grad_norm": 1.3012986183166504,
      "learning_rate": 0.000785867675566732,
      "loss": 0.7906,
      "step": 4740
    },
    {
      "epoch": 6.184895833333333,
      "grad_norm": 0.9810649156570435,
      "learning_rate": 0.000785025309998405,
      "loss": 0.7879,
      "step": 4750
    },
    {
      "epoch": 6.197916666666667,
      "grad_norm": 0.7317612171173096,
      "learning_rate": 0.0007841817442880679,
      "loss": 0.7759,
      "step": 4760
    },
    {
      "epoch": 6.2109375,
      "grad_norm": 0.6892639398574829,
      "learning_rate": 0.0007833369819876808,
      "loss": 0.767,
      "step": 4770
    },
    {
      "epoch": 6.223958333333333,
      "grad_norm": 0.6370823383331299,
      "learning_rate": 0.0007824910266542427,
      "loss": 0.7683,
      "step": 4780
    },
    {
      "epoch": 6.236979166666667,
      "grad_norm": 0.8158428072929382,
      "learning_rate": 0.000781643881849776,
      "loss": 0.7917,
      "step": 4790
    },
    {
      "epoch": 6.25,
      "grad_norm": 0.6300100684165955,
      "learning_rate": 0.0007807955511413114,
      "loss": 0.7717,
      "step": 4800
    },
    {
      "epoch": 6.25,
      "eval_loss": 0.7972112894058228,
      "eval_runtime": 2.0472,
      "eval_samples_per_second": 1500.134,
      "eval_steps_per_second": 93.789,
      "step": 4800
    },
    {
      "epoch": 6.263020833333333,
      "grad_norm": 0.6763973236083984,
      "learning_rate": 0.0007799460381008735,
      "loss": 0.7817,
      "step": 4810
    },
    {
      "epoch": 6.276041666666667,
      "grad_norm": 1.497773289680481,
      "learning_rate": 0.0007790953463054646,
      "loss": 0.7808,
      "step": 4820
    },
    {
      "epoch": 6.2890625,
      "grad_norm": 0.9137438535690308,
      "learning_rate": 0.0007782434793370509,
      "loss": 0.8068,
      "step": 4830
    },
    {
      "epoch": 6.302083333333333,
      "grad_norm": 0.9979259371757507,
      "learning_rate": 0.0007773904407825467,
      "loss": 0.7784,
      "step": 4840
    },
    {
      "epoch": 6.315104166666667,
      "grad_norm": 0.9356669187545776,
      "learning_rate": 0.0007765362342337989,
      "loss": 0.7753,
      "step": 4850
    },
    {
      "epoch": 6.328125,
      "grad_norm": 0.809722900390625,
      "learning_rate": 0.0007756808632875736,
      "loss": 0.7785,
      "step": 4860
    },
    {
      "epoch": 6.341145833333333,
      "grad_norm": 1.4241085052490234,
      "learning_rate": 0.0007748243315455382,
      "loss": 0.797,
      "step": 4870
    },
    {
      "epoch": 6.354166666666667,
      "grad_norm": 1.0815225839614868,
      "learning_rate": 0.0007739666426142492,
      "loss": 0.7621,
      "step": 4880
    },
    {
      "epoch": 6.3671875,
      "grad_norm": 1.537941813468933,
      "learning_rate": 0.0007731078001051349,
      "loss": 0.7767,
      "step": 4890
    },
    {
      "epoch": 6.380208333333333,
      "grad_norm": 1.8448219299316406,
      "learning_rate": 0.0007722478076344811,
      "loss": 0.7953,
      "step": 4900
    },
    {
      "epoch": 6.380208333333333,
      "eval_loss": 0.8094154596328735,
      "eval_runtime": 2.2692,
      "eval_samples_per_second": 1353.341,
      "eval_steps_per_second": 84.611,
      "step": 4900
    },
    {
      "epoch": 6.393229166666667,
      "grad_norm": 0.6549848914146423,
      "learning_rate": 0.0007713866688234157,
      "loss": 0.8024,
      "step": 4910
    },
    {
      "epoch": 6.40625,
      "grad_norm": 1.1272706985473633,
      "learning_rate": 0.0007705243872978934,
      "loss": 0.7882,
      "step": 4920
    },
    {
      "epoch": 6.419270833333333,
      "grad_norm": 1.1259510517120361,
      "learning_rate": 0.0007696609666886804,
      "loss": 0.7846,
      "step": 4930
    },
    {
      "epoch": 6.432291666666667,
      "grad_norm": 1.1380616426467896,
      "learning_rate": 0.0007687964106313392,
      "loss": 0.7869,
      "step": 4940
    },
    {
      "epoch": 6.4453125,
      "grad_norm": 1.0521135330200195,
      "learning_rate": 0.0007679307227662135,
      "loss": 0.7779,
      "step": 4950
    },
    {
      "epoch": 6.458333333333333,
      "grad_norm": 0.8972378969192505,
      "learning_rate": 0.0007670639067384127,
      "loss": 0.7701,
      "step": 4960
    },
    {
      "epoch": 6.471354166666667,
      "grad_norm": 0.8092256784439087,
      "learning_rate": 0.0007661959661977957,
      "loss": 0.788,
      "step": 4970
    },
    {
      "epoch": 6.484375,
      "grad_norm": 1.1897937059402466,
      "learning_rate": 0.0007653269047989575,
      "loss": 0.7607,
      "step": 4980
    },
    {
      "epoch": 6.497395833333333,
      "grad_norm": 0.9122552275657654,
      "learning_rate": 0.0007644567262012114,
      "loss": 0.7743,
      "step": 4990
    },
    {
      "epoch": 6.510416666666667,
      "grad_norm": 0.8733287453651428,
      "learning_rate": 0.0007635854340685761,
      "loss": 0.7606,
      "step": 5000
    },
    {
      "epoch": 6.510416666666667,
      "eval_loss": 0.788664698600769,
      "eval_runtime": 2.0282,
      "eval_samples_per_second": 1514.115,
      "eval_steps_per_second": 94.663,
      "step": 5000
    },
    {
      "epoch": 6.5234375,
      "grad_norm": 1.6624623537063599,
      "learning_rate": 0.0007627130320697581,
      "loss": 0.7642,
      "step": 5010
    },
    {
      "epoch": 6.536458333333333,
      "grad_norm": 1.5369905233383179,
      "learning_rate": 0.0007618395238781378,
      "loss": 0.7683,
      "step": 5020
    },
    {
      "epoch": 6.549479166666667,
      "grad_norm": 0.8847424983978271,
      "learning_rate": 0.0007609649131717524,
      "loss": 0.781,
      "step": 5030
    },
    {
      "epoch": 6.5625,
      "grad_norm": 0.7815936207771301,
      "learning_rate": 0.0007600892036332825,
      "loss": 0.7809,
      "step": 5040
    },
    {
      "epoch": 6.575520833333333,
      "grad_norm": 0.7477092742919922,
      "learning_rate": 0.000759212398950035,
      "loss": 0.7832,
      "step": 5050
    },
    {
      "epoch": 6.588541666666667,
      "grad_norm": 0.8963338136672974,
      "learning_rate": 0.0007583345028139281,
      "loss": 0.7659,
      "step": 5060
    },
    {
      "epoch": 6.6015625,
      "grad_norm": 0.7925371527671814,
      "learning_rate": 0.0007574555189214755,
      "loss": 0.7741,
      "step": 5070
    },
    {
      "epoch": 6.614583333333333,
      "grad_norm": 0.9172325730323792,
      "learning_rate": 0.000756575450973772,
      "loss": 0.7877,
      "step": 5080
    },
    {
      "epoch": 6.627604166666667,
      "grad_norm": 0.8771463632583618,
      "learning_rate": 0.0007556943026764756,
      "loss": 0.7661,
      "step": 5090
    },
    {
      "epoch": 6.640625,
      "grad_norm": 0.5808592438697815,
      "learning_rate": 0.0007548120777397941,
      "loss": 0.7805,
      "step": 5100
    },
    {
      "epoch": 6.640625,
      "eval_loss": 0.7850638628005981,
      "eval_runtime": 2.0201,
      "eval_samples_per_second": 1520.213,
      "eval_steps_per_second": 95.044,
      "step": 5100
    },
    {
      "epoch": 6.653645833333333,
      "grad_norm": 0.8042756915092468,
      "learning_rate": 0.0007539287798784687,
      "loss": 0.772,
      "step": 5110
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 1.0256376266479492,
      "learning_rate": 0.000753044412811758,
      "loss": 0.7763,
      "step": 5120
    },
    {
      "epoch": 6.6796875,
      "grad_norm": 0.9128915071487427,
      "learning_rate": 0.0007521589802634228,
      "loss": 0.7853,
      "step": 5130
    },
    {
      "epoch": 6.692708333333333,
      "grad_norm": 0.8390884399414062,
      "learning_rate": 0.0007512724859617103,
      "loss": 0.781,
      "step": 5140
    },
    {
      "epoch": 6.705729166666667,
      "grad_norm": 0.843368649482727,
      "learning_rate": 0.0007503849336393381,
      "loss": 0.7723,
      "step": 5150
    },
    {
      "epoch": 6.71875,
      "grad_norm": 0.9069125056266785,
      "learning_rate": 0.0007494963270334794,
      "loss": 0.7617,
      "step": 5160
    },
    {
      "epoch": 6.731770833333333,
      "grad_norm": 1.1539777517318726,
      "learning_rate": 0.0007486066698857458,
      "loss": 0.7666,
      "step": 5170
    },
    {
      "epoch": 6.744791666666667,
      "grad_norm": 1.0030392408370972,
      "learning_rate": 0.000747715965942173,
      "loss": 0.769,
      "step": 5180
    },
    {
      "epoch": 6.7578125,
      "grad_norm": 0.8228885531425476,
      "learning_rate": 0.0007468242189532039,
      "loss": 0.7668,
      "step": 5190
    },
    {
      "epoch": 6.770833333333333,
      "grad_norm": 0.8933075666427612,
      "learning_rate": 0.0007459314326736737,
      "loss": 0.7717,
      "step": 5200
    },
    {
      "epoch": 6.770833333333333,
      "eval_loss": 0.7765960097312927,
      "eval_runtime": 2.0162,
      "eval_samples_per_second": 1523.126,
      "eval_steps_per_second": 95.226,
      "step": 5200
    },
    {
      "epoch": 6.783854166666667,
      "grad_norm": 0.8633125424385071,
      "learning_rate": 0.0007450376108627937,
      "loss": 0.7691,
      "step": 5210
    },
    {
      "epoch": 6.796875,
      "grad_norm": 1.3513449430465698,
      "learning_rate": 0.0007441427572841349,
      "loss": 0.7674,
      "step": 5220
    },
    {
      "epoch": 6.809895833333333,
      "grad_norm": 0.7725918292999268,
      "learning_rate": 0.0007432468757056135,
      "loss": 0.7646,
      "step": 5230
    },
    {
      "epoch": 6.822916666666667,
      "grad_norm": 0.9702967405319214,
      "learning_rate": 0.0007423499698994737,
      "loss": 0.7619,
      "step": 5240
    },
    {
      "epoch": 6.8359375,
      "grad_norm": 1.6168663501739502,
      "learning_rate": 0.0007414520436422725,
      "loss": 0.7796,
      "step": 5250
    },
    {
      "epoch": 6.848958333333333,
      "grad_norm": 1.0320199728012085,
      "learning_rate": 0.0007405531007148638,
      "loss": 0.7541,
      "step": 5260
    },
    {
      "epoch": 6.861979166666667,
      "grad_norm": 0.8354564905166626,
      "learning_rate": 0.0007396531449023821,
      "loss": 0.752,
      "step": 5270
    },
    {
      "epoch": 6.875,
      "grad_norm": 0.7401288151741028,
      "learning_rate": 0.0007387521799942271,
      "loss": 0.7731,
      "step": 5280
    },
    {
      "epoch": 6.888020833333333,
      "grad_norm": 0.7502011060714722,
      "learning_rate": 0.0007378502097840471,
      "loss": 0.7721,
      "step": 5290
    },
    {
      "epoch": 6.901041666666667,
      "grad_norm": 0.6449564099311829,
      "learning_rate": 0.0007369472380697235,
      "loss": 0.7715,
      "step": 5300
    },
    {
      "epoch": 6.901041666666667,
      "eval_loss": 0.7892113327980042,
      "eval_runtime": 2.5386,
      "eval_samples_per_second": 1209.744,
      "eval_steps_per_second": 75.634,
      "step": 5300
    },
    {
      "epoch": 6.9140625,
      "grad_norm": 0.8939216732978821,
      "learning_rate": 0.0007360432686533551,
      "loss": 0.7747,
      "step": 5310
    },
    {
      "epoch": 6.927083333333333,
      "grad_norm": 1.6673542261123657,
      "learning_rate": 0.0007351383053412411,
      "loss": 0.7501,
      "step": 5320
    },
    {
      "epoch": 6.940104166666667,
      "grad_norm": 0.8412860035896301,
      "learning_rate": 0.000734232351943866,
      "loss": 0.76,
      "step": 5330
    },
    {
      "epoch": 6.953125,
      "grad_norm": 1.2699401378631592,
      "learning_rate": 0.0007333254122758828,
      "loss": 0.7849,
      "step": 5340
    },
    {
      "epoch": 6.966145833333333,
      "grad_norm": 0.7963736057281494,
      "learning_rate": 0.0007324174901560977,
      "loss": 0.7628,
      "step": 5350
    },
    {
      "epoch": 6.979166666666667,
      "grad_norm": 0.9362851977348328,
      "learning_rate": 0.0007315085894074539,
      "loss": 0.7598,
      "step": 5360
    },
    {
      "epoch": 6.9921875,
      "grad_norm": 0.918724775314331,
      "learning_rate": 0.0007305987138570145,
      "loss": 0.7595,
      "step": 5370
    },
    {
      "epoch": 7.005208333333333,
      "grad_norm": 0.9330211281776428,
      "learning_rate": 0.000729687867335948,
      "loss": 0.7431,
      "step": 5380
    },
    {
      "epoch": 7.018229166666667,
      "grad_norm": 0.8190422654151917,
      "learning_rate": 0.0007287760536795105,
      "loss": 0.7847,
      "step": 5390
    },
    {
      "epoch": 7.03125,
      "grad_norm": 0.7043023109436035,
      "learning_rate": 0.0007278632767270309,
      "loss": 0.7513,
      "step": 5400
    },
    {
      "epoch": 7.03125,
      "eval_loss": 0.7806392312049866,
      "eval_runtime": 2.0128,
      "eval_samples_per_second": 1525.701,
      "eval_steps_per_second": 95.387,
      "step": 5400
    },
    {
      "epoch": 7.044270833333333,
      "grad_norm": 11.938966751098633,
      "learning_rate": 0.0007269495403218942,
      "loss": 0.769,
      "step": 5410
    },
    {
      "epoch": 7.057291666666667,
      "grad_norm": 0.8616974949836731,
      "learning_rate": 0.0007260348483115254,
      "loss": 0.7552,
      "step": 5420
    },
    {
      "epoch": 7.0703125,
      "grad_norm": 1.063293218612671,
      "learning_rate": 0.0007251192045473725,
      "loss": 0.7803,
      "step": 5430
    },
    {
      "epoch": 7.083333333333333,
      "grad_norm": 0.8985483646392822,
      "learning_rate": 0.0007242026128848918,
      "loss": 0.7754,
      "step": 5440
    },
    {
      "epoch": 7.096354166666667,
      "grad_norm": 0.8334847092628479,
      "learning_rate": 0.0007232850771835307,
      "loss": 0.7663,
      "step": 5450
    },
    {
      "epoch": 7.109375,
      "grad_norm": 0.7809131145477295,
      "learning_rate": 0.0007223666013067112,
      "loss": 0.7607,
      "step": 5460
    },
    {
      "epoch": 7.122395833333333,
      "grad_norm": 0.7963603734970093,
      "learning_rate": 0.0007214471891218147,
      "loss": 0.7603,
      "step": 5470
    },
    {
      "epoch": 7.135416666666667,
      "grad_norm": 1.1230652332305908,
      "learning_rate": 0.0007205268445001645,
      "loss": 0.7707,
      "step": 5480
    },
    {
      "epoch": 7.1484375,
      "grad_norm": 0.8240078687667847,
      "learning_rate": 0.0007196055713170104,
      "loss": 0.7544,
      "step": 5490
    },
    {
      "epoch": 7.161458333333333,
      "grad_norm": 0.7475759387016296,
      "learning_rate": 0.0007186833734515119,
      "loss": 0.7544,
      "step": 5500
    },
    {
      "epoch": 7.161458333333333,
      "eval_loss": 0.7758528590202332,
      "eval_runtime": 2.068,
      "eval_samples_per_second": 1485.009,
      "eval_steps_per_second": 92.843,
      "step": 5500
    },
    {
      "epoch": 7.174479166666667,
      "grad_norm": 0.7496329545974731,
      "learning_rate": 0.0007177602547867222,
      "loss": 0.7703,
      "step": 5510
    },
    {
      "epoch": 7.1875,
      "grad_norm": 0.7622600197792053,
      "learning_rate": 0.0007168362192095712,
      "loss": 0.7608,
      "step": 5520
    },
    {
      "epoch": 7.200520833333333,
      "grad_norm": 0.7765898108482361,
      "learning_rate": 0.0007159112706108502,
      "loss": 0.7502,
      "step": 5530
    },
    {
      "epoch": 7.213541666666667,
      "grad_norm": 0.8663772940635681,
      "learning_rate": 0.0007149854128851945,
      "loss": 0.7681,
      "step": 5540
    },
    {
      "epoch": 7.2265625,
      "grad_norm": 0.878393292427063,
      "learning_rate": 0.0007140586499310674,
      "loss": 0.7546,
      "step": 5550
    },
    {
      "epoch": 7.239583333333333,
      "grad_norm": 0.954590380191803,
      "learning_rate": 0.0007131309856507443,
      "loss": 0.7752,
      "step": 5560
    },
    {
      "epoch": 7.252604166666667,
      "grad_norm": 0.9677140116691589,
      "learning_rate": 0.0007122024239502951,
      "loss": 0.7556,
      "step": 5570
    },
    {
      "epoch": 7.265625,
      "grad_norm": 0.6419091820716858,
      "learning_rate": 0.0007112729687395689,
      "loss": 0.7529,
      "step": 5580
    },
    {
      "epoch": 7.278645833333333,
      "grad_norm": 0.7040967345237732,
      "learning_rate": 0.000710342623932177,
      "loss": 0.7388,
      "step": 5590
    },
    {
      "epoch": 7.291666666666667,
      "grad_norm": 0.9708749055862427,
      "learning_rate": 0.000709411393445476,
      "loss": 0.7549,
      "step": 5600
    },
    {
      "epoch": 7.291666666666667,
      "eval_loss": 0.7747796177864075,
      "eval_runtime": 2.0263,
      "eval_samples_per_second": 1515.576,
      "eval_steps_per_second": 94.754,
      "step": 5600
    },
    {
      "epoch": 7.3046875,
      "grad_norm": 0.9728480577468872,
      "learning_rate": 0.0007084792812005527,
      "loss": 0.7616,
      "step": 5610
    },
    {
      "epoch": 7.317708333333333,
      "grad_norm": 0.5946818590164185,
      "learning_rate": 0.0007075462911222057,
      "loss": 0.7712,
      "step": 5620
    },
    {
      "epoch": 7.330729166666667,
      "grad_norm": 0.7539743185043335,
      "learning_rate": 0.0007066124271389305,
      "loss": 0.751,
      "step": 5630
    },
    {
      "epoch": 7.34375,
      "grad_norm": 0.7184845209121704,
      "learning_rate": 0.0007056776931829021,
      "loss": 0.7485,
      "step": 5640
    },
    {
      "epoch": 7.356770833333333,
      "grad_norm": 1.4912333488464355,
      "learning_rate": 0.0007047420931899584,
      "loss": 0.7588,
      "step": 5650
    },
    {
      "epoch": 7.369791666666667,
      "grad_norm": 0.9566344618797302,
      "learning_rate": 0.0007038056310995844,
      "loss": 0.772,
      "step": 5660
    },
    {
      "epoch": 7.3828125,
      "grad_norm": 0.895529568195343,
      "learning_rate": 0.0007028683108548949,
      "loss": 0.7746,
      "step": 5670
    },
    {
      "epoch": 7.395833333333333,
      "grad_norm": 0.8877636790275574,
      "learning_rate": 0.0007019301364026177,
      "loss": 0.7655,
      "step": 5680
    },
    {
      "epoch": 7.408854166666667,
      "grad_norm": 0.8615682721138,
      "learning_rate": 0.0007009911116930778,
      "loss": 0.7434,
      "step": 5690
    },
    {
      "epoch": 7.421875,
      "grad_norm": 0.9244696497917175,
      "learning_rate": 0.0007000512406801805,
      "loss": 0.7605,
      "step": 5700
    },
    {
      "epoch": 7.421875,
      "eval_loss": 0.77596515417099,
      "eval_runtime": 2.0263,
      "eval_samples_per_second": 1515.583,
      "eval_steps_per_second": 94.755,
      "step": 5700
    },
    {
      "epoch": 7.434895833333333,
      "grad_norm": 0.7707769274711609,
      "learning_rate": 0.0006991105273213939,
      "loss": 0.7703,
      "step": 5710
    },
    {
      "epoch": 7.447916666666667,
      "grad_norm": 1.0372127294540405,
      "learning_rate": 0.0006981689755777334,
      "loss": 0.763,
      "step": 5720
    },
    {
      "epoch": 7.4609375,
      "grad_norm": 1.6797525882720947,
      "learning_rate": 0.0006972265894137447,
      "loss": 0.7505,
      "step": 5730
    },
    {
      "epoch": 7.473958333333333,
      "grad_norm": 0.6626437306404114,
      "learning_rate": 0.0006962833727974867,
      "loss": 0.7566,
      "step": 5740
    },
    {
      "epoch": 7.486979166666667,
      "grad_norm": 1.4112129211425781,
      "learning_rate": 0.0006953393297005146,
      "loss": 0.7502,
      "step": 5750
    },
    {
      "epoch": 7.5,
      "grad_norm": 3.1980838775634766,
      "learning_rate": 0.0006943944640978648,
      "loss": 0.7526,
      "step": 5760
    },
    {
      "epoch": 7.513020833333333,
      "grad_norm": 0.8229418992996216,
      "learning_rate": 0.0006934487799680357,
      "loss": 0.7657,
      "step": 5770
    },
    {
      "epoch": 7.526041666666667,
      "grad_norm": 0.8561535477638245,
      "learning_rate": 0.000692502281292973,
      "loss": 0.7621,
      "step": 5780
    },
    {
      "epoch": 7.5390625,
      "grad_norm": 0.8139312863349915,
      "learning_rate": 0.0006915549720580523,
      "loss": 0.7672,
      "step": 5790
    },
    {
      "epoch": 7.552083333333333,
      "grad_norm": 1.0857973098754883,
      "learning_rate": 0.0006906068562520612,
      "loss": 0.7498,
      "step": 5800
    },
    {
      "epoch": 7.552083333333333,
      "eval_loss": 0.7663991451263428,
      "eval_runtime": 2.088,
      "eval_samples_per_second": 1470.778,
      "eval_steps_per_second": 91.954,
      "step": 5800
    },
    {
      "epoch": 7.565104166666667,
      "grad_norm": 0.6672919988632202,
      "learning_rate": 0.0006896579378671848,
      "loss": 0.7693,
      "step": 5810
    },
    {
      "epoch": 7.578125,
      "grad_norm": 0.7414449453353882,
      "learning_rate": 0.0006887082208989864,
      "loss": 0.7622,
      "step": 5820
    },
    {
      "epoch": 7.591145833333333,
      "grad_norm": 0.887992262840271,
      "learning_rate": 0.0006877577093463927,
      "loss": 0.7277,
      "step": 5830
    },
    {
      "epoch": 7.604166666666667,
      "grad_norm": 0.8196621537208557,
      "learning_rate": 0.0006868064072116757,
      "loss": 0.7552,
      "step": 5840
    },
    {
      "epoch": 7.6171875,
      "grad_norm": 0.7821835279464722,
      "learning_rate": 0.0006858543185004365,
      "loss": 0.7791,
      "step": 5850
    },
    {
      "epoch": 7.630208333333333,
      "grad_norm": 0.9014390110969543,
      "learning_rate": 0.000684901447221588,
      "loss": 0.7651,
      "step": 5860
    },
    {
      "epoch": 7.643229166666667,
      "grad_norm": 0.8895977139472961,
      "learning_rate": 0.0006839477973873379,
      "loss": 0.7494,
      "step": 5870
    },
    {
      "epoch": 7.65625,
      "grad_norm": 0.8679277896881104,
      "learning_rate": 0.000682993373013173,
      "loss": 0.7432,
      "step": 5880
    },
    {
      "epoch": 7.669270833333333,
      "grad_norm": 0.9021350145339966,
      "learning_rate": 0.0006820381781178408,
      "loss": 0.7674,
      "step": 5890
    },
    {
      "epoch": 7.682291666666667,
      "grad_norm": 1.1044498682022095,
      "learning_rate": 0.0006810822167233332,
      "loss": 0.753,
      "step": 5900
    },
    {
      "epoch": 7.682291666666667,
      "eval_loss": 0.7636319398880005,
      "eval_runtime": 2.0225,
      "eval_samples_per_second": 1518.387,
      "eval_steps_per_second": 94.93,
      "step": 5900
    },
    {
      "epoch": 7.6953125,
      "grad_norm": 1.4816749095916748,
      "learning_rate": 0.0006801254928548699,
      "loss": 0.7556,
      "step": 5910
    },
    {
      "epoch": 7.708333333333333,
      "grad_norm": 1.5867077112197876,
      "learning_rate": 0.0006791680105408806,
      "loss": 0.7385,
      "step": 5920
    },
    {
      "epoch": 7.721354166666667,
      "grad_norm": 0.7537782192230225,
      "learning_rate": 0.0006782097738129891,
      "loss": 0.7461,
      "step": 5930
    },
    {
      "epoch": 7.734375,
      "grad_norm": 1.2107495069503784,
      "learning_rate": 0.0006772507867059953,
      "loss": 0.7434,
      "step": 5940
    },
    {
      "epoch": 7.747395833333333,
      "grad_norm": 0.7357276082038879,
      "learning_rate": 0.000676291053257859,
      "loss": 0.7524,
      "step": 5950
    },
    {
      "epoch": 7.760416666666667,
      "grad_norm": 1.202742338180542,
      "learning_rate": 0.0006753305775096826,
      "loss": 0.7416,
      "step": 5960
    },
    {
      "epoch": 7.7734375,
      "grad_norm": 1.6203104257583618,
      "learning_rate": 0.0006743693635056935,
      "loss": 0.7628,
      "step": 5970
    },
    {
      "epoch": 7.786458333333333,
      "grad_norm": 1.1968389749526978,
      "learning_rate": 0.0006734074152932287,
      "loss": 0.7554,
      "step": 5980
    },
    {
      "epoch": 7.799479166666667,
      "grad_norm": 1.8272459506988525,
      "learning_rate": 0.0006724447369227158,
      "loss": 0.7658,
      "step": 5990
    },
    {
      "epoch": 7.8125,
      "grad_norm": 1.0743824243545532,
      "learning_rate": 0.0006714813324476569,
      "loss": 0.7529,
      "step": 6000
    },
    {
      "epoch": 7.8125,
      "eval_loss": 0.767678439617157,
      "eval_runtime": 2.3559,
      "eval_samples_per_second": 1303.554,
      "eval_steps_per_second": 81.499,
      "step": 6000
    },
    {
      "epoch": 7.825520833333333,
      "grad_norm": 0.7219449877738953,
      "learning_rate": 0.0006705172059246119,
      "loss": 0.7497,
      "step": 6010
    },
    {
      "epoch": 7.838541666666667,
      "grad_norm": 0.7069119811058044,
      "learning_rate": 0.000669552361413181,
      "loss": 0.7251,
      "step": 6020
    },
    {
      "epoch": 7.8515625,
      "grad_norm": 0.6621808409690857,
      "learning_rate": 0.0006685868029759869,
      "loss": 0.765,
      "step": 6030
    },
    {
      "epoch": 7.864583333333333,
      "grad_norm": 0.8230882287025452,
      "learning_rate": 0.0006676205346786594,
      "loss": 0.7435,
      "step": 6040
    },
    {
      "epoch": 7.877604166666667,
      "grad_norm": 1.0131899118423462,
      "learning_rate": 0.0006666535605898162,
      "loss": 0.7484,
      "step": 6050
    },
    {
      "epoch": 7.890625,
      "grad_norm": 0.6394877433776855,
      "learning_rate": 0.0006656858847810479,
      "loss": 0.7495,
      "step": 6060
    },
    {
      "epoch": 7.903645833333333,
      "grad_norm": 1.0198931694030762,
      "learning_rate": 0.0006647175113268988,
      "loss": 0.7435,
      "step": 6070
    },
    {
      "epoch": 7.916666666666667,
      "grad_norm": 0.8879104852676392,
      "learning_rate": 0.0006637484443048516,
      "loss": 0.7662,
      "step": 6080
    },
    {
      "epoch": 7.9296875,
      "grad_norm": 0.8299992680549622,
      "learning_rate": 0.0006627786877953089,
      "loss": 0.7427,
      "step": 6090
    },
    {
      "epoch": 7.942708333333333,
      "grad_norm": 0.7407633066177368,
      "learning_rate": 0.0006618082458815764,
      "loss": 0.7528,
      "step": 6100
    },
    {
      "epoch": 7.942708333333333,
      "eval_loss": 0.7596703767776489,
      "eval_runtime": 2.0684,
      "eval_samples_per_second": 1484.689,
      "eval_steps_per_second": 92.823,
      "step": 6100
    },
    {
      "epoch": 7.955729166666667,
      "grad_norm": 0.9676679372787476,
      "learning_rate": 0.0006608371226498464,
      "loss": 0.7357,
      "step": 6110
    },
    {
      "epoch": 7.96875,
      "grad_norm": 0.6610141396522522,
      "learning_rate": 0.0006598653221891792,
      "loss": 0.748,
      "step": 6120
    },
    {
      "epoch": 7.981770833333333,
      "grad_norm": 1.8897764682769775,
      "learning_rate": 0.0006588928485914871,
      "loss": 0.7524,
      "step": 6130
    },
    {
      "epoch": 7.994791666666667,
      "grad_norm": 1.0751694440841675,
      "learning_rate": 0.000657919705951517,
      "loss": 0.7448,
      "step": 6140
    },
    {
      "epoch": 8.0078125,
      "grad_norm": 0.8300216794013977,
      "learning_rate": 0.0006569458983668322,
      "loss": 0.742,
      "step": 6150
    },
    {
      "epoch": 8.020833333333334,
      "grad_norm": 1.777076244354248,
      "learning_rate": 0.0006559714299377966,
      "loss": 0.7476,
      "step": 6160
    },
    {
      "epoch": 8.033854166666666,
      "grad_norm": 0.9169331789016724,
      "learning_rate": 0.0006549963047675562,
      "loss": 0.7319,
      "step": 6170
    },
    {
      "epoch": 8.046875,
      "grad_norm": 0.655857264995575,
      "learning_rate": 0.000654020526962022,
      "loss": 0.7485,
      "step": 6180
    },
    {
      "epoch": 8.059895833333334,
      "grad_norm": 0.550412118434906,
      "learning_rate": 0.0006530441006298544,
      "loss": 0.7549,
      "step": 6190
    },
    {
      "epoch": 8.072916666666666,
      "grad_norm": 0.9477311372756958,
      "learning_rate": 0.0006520670298824428,
      "loss": 0.7449,
      "step": 6200
    },
    {
      "epoch": 8.072916666666666,
      "eval_loss": 0.7615272998809814,
      "eval_runtime": 2.0464,
      "eval_samples_per_second": 1500.699,
      "eval_steps_per_second": 93.824,
      "step": 6200
    },
    {
      "epoch": 8.0859375,
      "grad_norm": 0.9505313634872437,
      "learning_rate": 0.000651089318833891,
      "loss": 0.76,
      "step": 6210
    },
    {
      "epoch": 8.098958333333334,
      "grad_norm": 0.8279374837875366,
      "learning_rate": 0.0006501109716009987,
      "loss": 0.7439,
      "step": 6220
    },
    {
      "epoch": 8.111979166666666,
      "grad_norm": 0.9656050801277161,
      "learning_rate": 0.0006491319923032446,
      "loss": 0.7465,
      "step": 6230
    },
    {
      "epoch": 8.125,
      "grad_norm": 0.8409455418586731,
      "learning_rate": 0.0006481523850627682,
      "loss": 0.7365,
      "step": 6240
    },
    {
      "epoch": 8.138020833333334,
      "grad_norm": 0.730749785900116,
      "learning_rate": 0.0006471721540043532,
      "loss": 0.7405,
      "step": 6250
    },
    {
      "epoch": 8.151041666666666,
      "grad_norm": 0.6972964406013489,
      "learning_rate": 0.0006461913032554108,
      "loss": 0.7435,
      "step": 6260
    },
    {
      "epoch": 8.1640625,
      "grad_norm": 2.5543527603149414,
      "learning_rate": 0.0006452098369459602,
      "loss": 0.7587,
      "step": 6270
    },
    {
      "epoch": 8.177083333333334,
      "grad_norm": 0.5281400084495544,
      "learning_rate": 0.0006442277592086134,
      "loss": 0.752,
      "step": 6280
    },
    {
      "epoch": 8.190104166666666,
      "grad_norm": 0.8242788314819336,
      "learning_rate": 0.000643245074178557,
      "loss": 0.7565,
      "step": 6290
    },
    {
      "epoch": 8.203125,
      "grad_norm": 0.7358657121658325,
      "learning_rate": 0.0006422617859935338,
      "loss": 0.7288,
      "step": 6300
    },
    {
      "epoch": 8.203125,
      "eval_loss": 0.7621440887451172,
      "eval_runtime": 2.0695,
      "eval_samples_per_second": 1483.962,
      "eval_steps_per_second": 92.778,
      "step": 6300
    },
    {
      "epoch": 8.216145833333334,
      "grad_norm": 2.727151870727539,
      "learning_rate": 0.0006412778987938272,
      "loss": 0.7358,
      "step": 6310
    },
    {
      "epoch": 8.229166666666666,
      "grad_norm": 0.7751616835594177,
      "learning_rate": 0.0006402934167222427,
      "loss": 0.7472,
      "step": 6320
    },
    {
      "epoch": 8.2421875,
      "grad_norm": 0.8126106262207031,
      "learning_rate": 0.0006393083439240896,
      "loss": 0.7502,
      "step": 6330
    },
    {
      "epoch": 8.255208333333334,
      "grad_norm": 0.7875732183456421,
      "learning_rate": 0.0006383226845471662,
      "loss": 0.7566,
      "step": 6340
    },
    {
      "epoch": 8.268229166666666,
      "grad_norm": 1.0520339012145996,
      "learning_rate": 0.0006373364427417394,
      "loss": 0.7633,
      "step": 6350
    },
    {
      "epoch": 8.28125,
      "grad_norm": 0.9729620814323425,
      "learning_rate": 0.0006363496226605289,
      "loss": 0.7416,
      "step": 6360
    },
    {
      "epoch": 8.294270833333334,
      "grad_norm": 0.9368773698806763,
      "learning_rate": 0.0006353622284586892,
      "loss": 0.7561,
      "step": 6370
    },
    {
      "epoch": 8.307291666666666,
      "grad_norm": 0.7030602097511292,
      "learning_rate": 0.0006343742642937928,
      "loss": 0.7522,
      "step": 6380
    },
    {
      "epoch": 8.3203125,
      "grad_norm": 0.6791430115699768,
      "learning_rate": 0.0006333857343258115,
      "loss": 0.7511,
      "step": 6390
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.5386459231376648,
      "learning_rate": 0.0006323966427170993,
      "loss": 0.7371,
      "step": 6400
    },
    {
      "epoch": 8.333333333333334,
      "eval_loss": 0.7642989754676819,
      "eval_runtime": 2.2367,
      "eval_samples_per_second": 1372.978,
      "eval_steps_per_second": 85.839,
      "step": 6400
    },
    {
      "epoch": 8.346354166666666,
      "grad_norm": 0.6724681258201599,
      "learning_rate": 0.0006314069936323759,
      "loss": 0.7505,
      "step": 6410
    },
    {
      "epoch": 8.359375,
      "grad_norm": 0.5887597799301147,
      "learning_rate": 0.0006304167912387075,
      "loss": 0.7338,
      "step": 6420
    },
    {
      "epoch": 8.372395833333334,
      "grad_norm": 0.9241687655448914,
      "learning_rate": 0.0006294260397054907,
      "loss": 0.7426,
      "step": 6430
    },
    {
      "epoch": 8.385416666666666,
      "grad_norm": 0.8829947710037231,
      "learning_rate": 0.0006284347432044342,
      "loss": 0.7435,
      "step": 6440
    },
    {
      "epoch": 8.3984375,
      "grad_norm": 0.7924380898475647,
      "learning_rate": 0.000627442905909541,
      "loss": 0.7414,
      "step": 6450
    },
    {
      "epoch": 8.411458333333334,
      "grad_norm": 0.7306022047996521,
      "learning_rate": 0.0006264505319970914,
      "loss": 0.7373,
      "step": 6460
    },
    {
      "epoch": 8.424479166666666,
      "grad_norm": 0.9799067378044128,
      "learning_rate": 0.0006254576256456257,
      "loss": 0.7299,
      "step": 6470
    },
    {
      "epoch": 8.4375,
      "grad_norm": 0.7560300827026367,
      "learning_rate": 0.0006244641910359253,
      "loss": 0.7269,
      "step": 6480
    },
    {
      "epoch": 8.450520833333334,
      "grad_norm": 1.4101099967956543,
      "learning_rate": 0.0006234702323509966,
      "loss": 0.7422,
      "step": 6490
    },
    {
      "epoch": 8.463541666666666,
      "grad_norm": 0.9358230829238892,
      "learning_rate": 0.000622475753776052,
      "loss": 0.7413,
      "step": 6500
    },
    {
      "epoch": 8.463541666666666,
      "eval_loss": 0.7532694935798645,
      "eval_runtime": 2.0323,
      "eval_samples_per_second": 1511.123,
      "eval_steps_per_second": 94.476,
      "step": 6500
    }
  ],
  "logging_steps": 10,
  "max_steps": 15360,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 20,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8905083715584.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
