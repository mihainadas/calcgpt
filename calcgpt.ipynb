{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# CalcGPT: Building an Arithmetic Language Model from Scratch\n",
        "\n",
        "**A Complete Guide to Transformer-Based Language Models using HuggingFace and PyTorch**\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 Overview\n",
        "\n",
        "Welcome to **CalcGPT** - a comprehensive tutorial on building, training, and deploying transformer-based language models for arithmetic tasks. This notebook demonstrates the complete machine learning pipeline from dataset generation to production inference, while teaching fundamental concepts of modern NLP.\n",
        "\n",
        "### 🌟 What You'll Learn\n",
        "\n",
        "- **Transformer Architecture**: Understanding GPT-2 models and attention mechanisms\n",
        "- **Dataset Engineering**: Creating and analyzing training datasets for language models\n",
        "- **Model Training**: End-to-end training with HuggingFace Transformers\n",
        "- **Evaluation Methodologies**: Comprehensive model assessment and validation\n",
        "- **Production Deployment**: Interactive inference and real-world usage\n",
        "- **Scaling Strategies**: From toy models to production-ready systems\n",
        "\n",
        "### 🛠️ Tools We'll Use\n",
        "\n",
        "- **CalcGPT DataGen**: Intelligent dataset generation with parameter encoding\n",
        "- **CalcGPT Trainer**: Advanced model training with auto-naming conventions\n",
        "- **CalcGPT Eval**: Comprehensive model evaluation and analysis\n",
        "- **CalcGPT CLI**: Interactive inference and batch processing\n",
        "\n",
        "### 📚 Learning Path\n",
        "\n",
        "1. **Simple Start**: Basic arithmetic with tiny models (38K parameters)\n",
        "2. **Understanding**: Deep dive into model architecture and training dynamics\n",
        "3. **Scaling Up**: Larger datasets and models (1.2M+ parameters)\n",
        "4. **Production**: Real-world inference and deployment strategies\n",
        "\n",
        "Let's build something amazing! 🚀\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🔧 Setup and Imports\n",
        "\n",
        "First, let's import all the necessary libraries and set up our environment. We'll be using modern PyTorch and HuggingFace transformers throughout this tutorial.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mihai/Coding/jupyter/transformers/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 Using device: mps\n",
            "🐍 Python version: 3.13.4 (main, Jun  3 2025, 15:34:24) [Clang 17.0.0 (clang-1700.0.13.3)]\n",
            "🔥 PyTorch version: 2.7.1\n",
            "✅ Setup complete! Ready to build CalcGPT 🚀\n"
          ]
        }
      ],
      "source": [
        "# Core libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# HuggingFace transformers\n",
        "from transformers import GPT2Config, GPT2LMHeadModel, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Utility imports\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for beautiful plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Check available devices\n",
        "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
        "print(f\"🎯 Using device: {device}\")\n",
        "print(f\"🐍 Python version: {sys.version}\")\n",
        "print(f\"🔥 PyTorch version: {torch.__version__}\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"✅ Setup complete! Ready to build CalcGPT 🚀\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 📊 Part 1: Understanding the Problem & Dataset Generation\n",
        "\n",
        "### The Challenge: Teaching Machines Arithmetic\n",
        "\n",
        "Language models like GPT-3 can write poetry and code, but struggle with basic arithmetic. Why? Because arithmetic requires **precise computation** rather than **pattern matching**. This makes arithmetic an excellent testbed for understanding model capabilities and limitations.\n",
        "\n",
        "### Our Approach: Character-Level Language Modeling\n",
        "\n",
        "We'll treat arithmetic as a **sequence-to-sequence** problem:\n",
        "- **Input**: `\"1+1=\"` \n",
        "- **Target**: `\"1+1=2\"`\n",
        "\n",
        "The model learns to predict the next character given the previous characters, eventually learning to compute arithmetic results.\n",
        "\n",
        "### Dataset Design Philosophy\n",
        "\n",
        "Our CalcGPT DataGen tool creates intelligent datasets with:\n",
        "- **Systematic coverage**: All combinations within specified ranges\n",
        "- **Data augmentation**: Commutative property examples (a+b and b+a)\n",
        "- **Intelligent naming**: Filenames encode generation parameters\n",
        "- **Scalability**: From toy problems to complex arithmetic\n",
        "\n",
        "Let's start by generating a simple dataset for our first model!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎬 Generating simple dataset with CalcGPT DataGen...\n",
            "STDOUT:\n",
            "\n",
            "\u001b[94m\u001b[1m\n",
            "╔═══════════════════════════════════════════════════════════════╗\n",
            "║                    CalcGPT DataGen                            ║\n",
            "║                 Dataset Generation Tool                      ║\n",
            "║                         v1.0.0                               ║\n",
            "╚═══════════════════════════════════════════════════════════════╝\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m🚀 Generation Configuration:\u001b[0m\n",
            "==================================================\n",
            "  🎯 Value range: \u001b[1m0 - 5\u001b[0m\n",
            "  🔢 Allowed digits: \u001b[92mAll digits (0-9)\u001b[0m\n",
            "  🧮 Operations: \u001b[92m➕ addition\u001b[0m\n",
            "  📏 Expression limit: \u001b[93m20\u001b[0m\n",
            "  📁 Output file: \u001b[96mdatasets/ds-calcgpt_min0_max5_alldigits_add_limit20.txt\u001b[0m\n",
            "\n",
            "\u001b[92m🎬 Starting expression generation...\u001b[0m\n",
            "\u001b[96m📝 Writing expressions to: datasets/ds-calcgpt_min0_max5_alldigits_add_limit20.txt\u001b[0m\n",
            "\u001b[96m🧮 Generating arithmetic expressions...\u001b[0m\n",
            "\u001b[96m🔢 Generating valid numbers up to 5...\u001b[0m\n",
            "\u001b[92m✅ Generated 6 numbers (all digits allowed)\u001b[0m\n",
            "\u001b[96m🔧 Operations to include: addition\u001b[0m\n",
            "\u001b[96m📊 Estimated expressions to generate: ~36\u001b[0m\n",
            "\u001b[93m⚠️ Reached maximum expression limit: 20\u001b[0m\n",
            "\u001b[92m✅ Successfully wrote 20 expressions in 0.0s (97656/sec)\u001b[0m\n",
            "\n",
            "\u001b[92m\u001b[1m🎉 SUCCESS!\u001b[0m\n",
            "  📊 Generated: \u001b[1m20 expressions\u001b[0m\n",
            "  📁 Saved to: \u001b[96mdatasets/ds-calcgpt_min0_max5_alldigits_add_limit20.txt\u001b[0m\n",
            "  ⏱️  Total time: \u001b[1m0.0 seconds\u001b[0m\n",
            "  🚀 Generation rate: \u001b[1m85861 expressions/second\u001b[0m\n",
            "  💾 File size: \u001b[1m120 bytes (0.1 KB)\u001b[0m\n",
            "\n",
            "\n",
            "📚 Generated dataset preview:\n",
            "Total examples: 20\n",
            "First 10 examples:\n",
            "   1. 0+0=0\n",
            "   2. 0+1=1\n",
            "   3. 0+2=2\n",
            "   4. 0+3=3\n",
            "   5. 0+4=4\n",
            "   6. 0+5=5\n",
            "   7. 1+0=1\n",
            "   8. 1+1=2\n",
            "   9. 1+2=3\n",
            "  10. 1+3=4\n",
            "  ...\n",
            "  20. 3+1=4\n",
            "\n",
            "📊 Dataset Analysis:\n",
            "  📏 Average length: 5.0 characters\n",
            "  📏 Max length: 5 characters\n",
            "  🔤 Unique characters: +01234567=\n",
            "  📈 Character count: 10 unique chars\n"
          ]
        }
      ],
      "source": [
        "# Generate a simple dataset for our first model\n",
        "# We'll start small: numbers 0-5, only addition, limit to 20 examples\n",
        "\n",
        "print(\"🎬 Generating simple dataset with CalcGPT DataGen...\")\n",
        "result = subprocess.run([\n",
        "    'python', 'calcgpt_dategen.py', \n",
        "    '-m', '5',                    # Max value: 5\n",
        "    '--max-expressions', '20',    # Limit: 20 examples\n",
        "    '--no-subtraction',           # Addition only\n",
        "    '--verbose'\n",
        "], capture_output=True, text=True)\n",
        "\n",
        "print(\"STDOUT:\")\n",
        "print(result.stdout)\n",
        "if result.stderr:\n",
        "    print(\"STDERR:\")\n",
        "    print(result.stderr)\n",
        "\n",
        "# Let's examine what was generated\n",
        "with open('datasets/ds-calcgpt_min0_max5_alldigits_add_limit20.txt', 'r') as f:\n",
        "    simple_dataset = f.read().strip().split('\\n')\n",
        "\n",
        "print(f\"\\n📚 Generated dataset preview:\")\n",
        "print(f\"Total examples: {len(simple_dataset)}\")\n",
        "print(\"First 10 examples:\")\n",
        "for i, example in enumerate(simple_dataset[:10]):\n",
        "    print(f\"  {i+1:2d}. {example}\")\n",
        "\n",
        "if len(simple_dataset) > 10:\n",
        "    print(\"  ...\")\n",
        "    print(f\"  {len(simple_dataset)}. {simple_dataset[-1]}\")\n",
        "\n",
        "# Analyze the dataset\n",
        "print(f\"\\n📊 Dataset Analysis:\")\n",
        "print(f\"  📏 Average length: {np.mean([len(ex) for ex in simple_dataset]):.1f} characters\")\n",
        "print(f\"  📏 Max length: {max(len(ex) for ex in simple_dataset)} characters\")\n",
        "print(f\"  🔤 Unique characters: {''.join(sorted(set(''.join(simple_dataset))))}\")\n",
        "print(f\"  📈 Character count: {len(set(''.join(simple_dataset)))} unique chars\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🧠 Part 2: Understanding Transformer Architecture\n",
        "\n",
        "### The GPT-2 Architecture\n",
        "\n",
        "Our CalcGPT is based on **GPT-2** (Generative Pre-trained Transformer), which uses the **decoder-only** transformer architecture. Let's understand the key components:\n",
        "\n",
        "#### 🔧 Key Components\n",
        "\n",
        "1. **Token Embeddings**: Convert characters to dense vectors\n",
        "2. **Positional Embeddings**: Encode position information\n",
        "3. **Multi-Head Attention**: Learn relationships between positions\n",
        "4. **Feed-Forward Networks**: Non-linear transformations\n",
        "5. **Layer Normalization**: Stabilize training\n",
        "6. **Causal Masking**: Prevent future token access\n",
        "\n",
        "#### 📐 Model Parameters\n",
        "\n",
        "For our simple model, we'll use a tiny architecture:\n",
        "- **Embedding dimension**: 32 (vs 768 in GPT-2 small)\n",
        "- **Number of layers**: 1 (vs 12 in GPT-2 small)\n",
        "- **Attention heads**: 2 (vs 12 in GPT-2 small)\n",
        "- **Vocabulary size**: ~7 characters (`0123456789+=`)\n",
        "\n",
        "This gives us only ~38K parameters vs 117M in GPT-2 small!\n",
        "\n",
        "#### 🎯 Training Objective\n",
        "\n",
        "**Causal Language Modeling**: Given a sequence `x₁, x₂, ..., xₙ`, predict `xₙ₊₁`\n",
        "\n",
        "For `\"1+1=2\"`:\n",
        "- Input: `\"1+1=\"` → Predict: `\"2\"`\n",
        "- The model learns: `P(2|1,+,1,=)`\n",
        "\n",
        "### Why Start Small?\n",
        "\n",
        "1. **Fast iteration**: Quick training and testing\n",
        "2. **Understanding**: Easier to analyze and debug\n",
        "3. **Resource efficiency**: Runs on any hardware\n",
        "4. **Clear baselines**: Establish performance expectations\n",
        "\n",
        "Let's train our first tiny CalcGPT model!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Training tiny CalcGPT model with our professional trainer...\n",
            "STDOUT:\n",
            "\n",
            "\u001b[94m\u001b[1m\n",
            "╔═══════════════════════════════════════════════════════════════╗\n",
            "║                    CalcGPT Trainer                            ║\n",
            "║              Advanced Model Training System                   ║\n",
            "║                         v1.0.0                               ║\n",
            "╚═══════════════════════════════════════════════════════════════╝\n",
            "\u001b[0m\n",
            "\u001b[92m🍎 Apple Silicon (MPS) detected\u001b[0m\n",
            "\u001b[96m📚 Loading dataset from: datasets/ds-calcgpt_min0_max5_alldigits_add_limit20.txt\u001b[0m\n",
            "\u001b[92m✅ Loaded 20 examples from dataset\u001b[0m\n",
            "\u001b[96m📊 Dataset statistics:\u001b[0m\n",
            "   Average length: 5.0 characters\n",
            "   Maximum length: 5 characters\n",
            "   Minimum length: 5 characters\n",
            "\u001b[96m✨ Applying data augmentation (commutative property)...\u001b[0m\n",
            "\u001b[92m✅ Added 7 augmented examples\u001b[0m\n",
            "\u001b[96m📈 Total dataset size: 27 examples\u001b[0m\n",
            "\u001b[96m🔤 Creating optimized vocabulary...\u001b[0m\n",
            "\u001b[92m✅ Vocabulary created with 12 tokens\u001b[0m\n",
            "\u001b[96m🔧 Special tokens: ['<pad>', '<eos>']\u001b[0m\n",
            "\u001b[96m🔧 Character tokens: +01234567=\u001b[0m\n",
            "\u001b[96m📏 Maximum sequence length: 6\u001b[0m\n",
            "\u001b[93m⚠️ No validation split (evaluation disabled)\u001b[0m\n",
            "\n",
            "\u001b[1m🚀 Training Configuration:\u001b[0m\n",
            "============================================================\n",
            "  📚 Dataset: \u001b[96mdatasets/ds-calcgpt_min0_max5_alldigits_add_limit20.txt\u001b[0m (27 examples)\n",
            "  🎯 Device: \u001b[92mMPS\u001b[0m\n",
            "  ⚡ Mixed precision: ❌ Disabled\n",
            "  🔤 Vocabulary size: \u001b[1m12\u001b[0m\n",
            "\n",
            "  🏗️  Model Architecture:\n",
            "     📏 Embedding dimension: \u001b[1m32\u001b[0m\n",
            "     🏗️  Number of layers: \u001b[1m1\u001b[0m\n",
            "     👁️  Attention heads: \u001b[1m2\u001b[0m\n",
            "     🔧 Feedforward dimension: \u001b[1m512\u001b[0m\n",
            "\n",
            "  📖 Training Parameters:\n",
            "     🔄 Epochs: \u001b[1m3\u001b[0m\n",
            "     📦 Batch size: \u001b[1m4\u001b[0m\n",
            "     📈 Learning rate: \u001b[1m0.001\u001b[0m\n",
            "     📅 LR scheduler: \u001b[1mcosine\u001b[0m\n",
            "     🔧 Effective batch size: \u001b[1m8\u001b[0m\n",
            "  📁 Model output: \u001b[96mmodels/calcgpt_emb32_lay1_head2_ep3_bs4_lr1e03_ds20\u001b[0m\n",
            "\n",
            "\u001b[96m🏗️ Creating model architecture...\u001b[0m\n",
            "\u001b[92m✅ Model configuration created:\u001b[0m\n",
            "   📏 Sequence length: 16\n",
            "   🧠 Embedding dimension: 32\n",
            "   🏗️  Number of layers: 1\n",
            "   👁️  Attention heads: 2\n",
            "   🔧 Feedforward dimension: 512\n",
            "\u001b[96m🧠 Model Information:\u001b[0m\n",
            "   📊 Total parameters: \u001b[1m38,624\u001b[0m\n",
            "   🎯 Trainable parameters: \u001b[1m38,624\u001b[0m\n",
            "   💾 Model size: \u001b[1m0.1 MB\u001b[0m\n",
            "\u001b[96m🔧 Creating training dataset with 27 examples...\u001b[0m\n",
            "\u001b[92m✅ training dataset ready with 27 pre-tokenized sequences\u001b[0m\n",
            "\u001b[96m⚙️ Training arguments configured\u001b[0m\n",
            "\n",
            "\u001b[92m\u001b[1m🚀 STARTING TRAINING\u001b[0m\n",
            "============================================================\n",
            "{'loss': 2.041, 'grad_norm': 1.9834450483322144, 'learning_rate': 0.00017999999999999998, 'epoch': 2.57}\n",
            "{'train_runtime': 2.4217, 'train_samples_per_second': 33.448, 'train_steps_per_second': 4.955, 'train_loss': 2.0233030319213867, 'epoch': 3.0}\n",
            "\n",
            "\u001b[92m\u001b[1m✅ TRAINING COMPLETED\u001b[0m\n",
            "============================================================\n",
            "  📊 Final training loss: \u001b[1m2.0233\u001b[0m\n",
            "  ⏱️  Training time: \u001b[1m0.0 minutes\u001b[0m\n",
            "\n",
            "\u001b[96m🧪 Testing trained model...\u001b[0m\n",
            "\n",
            "\u001b[96m🧪 Testing model inference...\u001b[0m\n",
            "\n",
            "\u001b[96m🔍 Test 1/9: '1+1='\u001b[0m\n",
            "   Generated: '1+1==========='\n",
            "   New part: '=========='\n",
            "   \u001b[93m❌ Expected 2, got \u001b[0m\n",
            "\n",
            "\u001b[96m🔍 Test 2/9: '2+0='\u001b[0m\n",
            "   Generated: '2+0==========='\n",
            "   New part: '=========='\n",
            "   \u001b[93m❌ Expected 2, got \u001b[0m\n",
            "\n",
            "\u001b[96m🔍 Test 3/9: '0+2='\u001b[0m\n",
            "   Generated: '0+2==========='\n",
            "   New part: '=========='\n",
            "   \u001b[93m❌ Expected 2, got \u001b[0m\n",
            "\n",
            "\u001b[96m🔍 Test 4/9: '10+1='\u001b[0m\n",
            "   Generated: '10+1==========='\n",
            "   New part: '=========='\n",
            "   \u001b[93m❌ Expected 11, got \u001b[0m\n",
            "\n",
            "\u001b[96m🔍 Test 5/9: '11+1='\u001b[0m\n",
            "   Generated: '11+1==========='\n",
            "   New part: '=========='\n",
            "   \u001b[93m❌ Expected 12, got \u001b[0m\n",
            "\n",
            "\u001b[96m🔍 Test 6/9: '100+10='\u001b[0m\n",
            "   Generated: '100+10==========='\n",
            "   New part: '=========='\n",
            "   \u001b[93m❌ Expected 110, got \u001b[0m\n",
            "\n",
            "\u001b[96m🔍 Test 7/9: '22+100='\u001b[0m\n",
            "   Generated: '22+100==========='\n",
            "   New part: '=========='\n",
            "   \u001b[93m❌ Expected 122, got \u001b[0m\n",
            "\n",
            "\u001b[96m🔍 Test 8/9: '12+10='\u001b[0m\n",
            "   Generated: '12+10==========='\n",
            "   New part: '=========='\n",
            "   \u001b[93m❌ Expected 22, got \u001b[0m\n",
            "\n",
            "\u001b[96m🔍 Test 9/9: '5+5='\u001b[0m\n",
            "   Generated: '5+5==========='\n",
            "   New part: '=========='\n",
            "   \u001b[93m❌ Expected 10, got \u001b[0m\n",
            "\n",
            "\u001b[92m\u001b[1m🎉 TRAINING COMPLETE!\u001b[0m\n",
            "============================================================\n",
            "  📊 Model accuracy: \u001b[1m0/9 (0.0%)\u001b[0m\n",
            "  📁 Model saved to: \u001b[96mmodels/calcgpt_emb32_lay1_head2_ep3_bs4_lr1e03_ds20\u001b[0m\n",
            "  ⏱️  Total time: \u001b[1m0.0 minutes\u001b[0m\n",
            "\n",
            "\u001b[96m📝 Auto-generated Model Name:\u001b[0m\n",
            "  \u001b[1mcalcgpt_emb32_lay1_head2_ep3_bs4_lr1e03_ds20\u001b[0m\n",
            "  💡 Encodes: architecture + training params + dataset\n",
            "\n",
            "\u001b[96m🏆 Training Achievements:\u001b[0m\n",
            "  ✅ Data augmentation applied\n",
            "  ✅ Optimized model architecture\n",
            "  ✅ Advanced training configuration\n",
            "  ✅ Comprehensive evaluation\n",
            "  ✅ Inference testing completed\n",
            "  ✅ Intelligent model naming system\n",
            "\n",
            "STDERR:\n",
            "\n",
            "  0%|          | 0/12 [00:00<?, ?it/s]/Users/mihai/Coding/jupyter/transformers/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
            "\n",
            "  8%|▊         | 1/12 [00:01<00:17,  1.61s/it]\n",
            " 33%|███▎      | 4/12 [00:02<00:03,  2.19it/s]\n",
            " 67%|██████▋   | 8/12 [00:02<00:00,  5.12it/s]\n",
            "                                              \n",
            "\n",
            " 83%|████████▎ | 10/12 [00:02<00:00,  5.12it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  8.54it/s]\n",
            "                                               \n",
            "\n",
            "100%|██████████| 12/12 [00:02<00:00,  8.54it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.98it/s]\n",
            "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (16). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n",
            "\n",
            "\n",
            "⏱️ Training completed in 8.1 seconds\n",
            "🎯 Model saved as: calcgpt_emb32_lay1_head2_ep3_bs4_lr1e03_ds20\n",
            "📝 Filename breakdown:\n",
            "   • emb32: 32-dimensional embeddings\n",
            "   • lay1: 1 transformer layer\n",
            "   • head2: 2 attention heads\n",
            "   • ep3: 3 training epochs\n",
            "   • bs4: batch size 4\n",
            "   • lr1e3: learning rate 1e-3\n",
            "   • ds20: dataset with 20 examples\n"
          ]
        }
      ],
      "source": [
        "# Train our first tiny CalcGPT model\n",
        "print(\"🚀 Training tiny CalcGPT model with our professional trainer...\")\n",
        "\n",
        "# Train a tiny model: 32 dim, 1 layer, 2 heads, 3 epochs\n",
        "training_start = time.time()\n",
        "\n",
        "result = subprocess.run([\n",
        "    'python', 'calcgpt_train.py',\n",
        "    '-d', 'datasets/ds-calcgpt_min0_max5_alldigits_add_limit20.txt',  # Our simple dataset\n",
        "    '--embedding-dim', '32',      # Small embedding\n",
        "    '--num-layers', '1',          # Single layer\n",
        "    '--num-heads', '2',           # Two attention heads\n",
        "    '--epochs', '3',              # Quick training\n",
        "    '--batch-size', '4',          # Small batches\n",
        "    '--eval-steps', '0',          # No validation for simplicity\n",
        "    '--verbose'                   # See what's happening\n",
        "], capture_output=True, text=True)\n",
        "\n",
        "training_time = time.time() - training_start\n",
        "\n",
        "print(\"STDOUT:\")\n",
        "print(result.stdout)\n",
        "if result.stderr:\n",
        "    print(\"STDERR:\")\n",
        "    print(result.stderr)\n",
        "\n",
        "print(f\"\\n⏱️ Training completed in {training_time:.1f} seconds\")\n",
        "\n",
        "# The model will be auto-saved with an intelligent name\n",
        "# Let's find it and examine the naming convention\n",
        "models_dir = Path('models')\n",
        "if models_dir.exists():\n",
        "    model_dirs = [d for d in models_dir.iterdir() if d.is_dir() and 'emb32' in d.name]\n",
        "    if model_dirs:\n",
        "        latest_model = max(model_dirs, key=lambda x: x.stat().st_mtime)\n",
        "        print(f\"🎯 Model saved as: {latest_model.name}\")\n",
        "        print(\"📝 Filename breakdown:\")\n",
        "        print(f\"   • emb32: 32-dimensional embeddings\")\n",
        "        print(f\"   • lay1: 1 transformer layer\") \n",
        "        print(f\"   • head2: 2 attention heads\")\n",
        "        print(f\"   • ep3: 3 training epochs\")\n",
        "        print(f\"   • bs4: batch size 4\")\n",
        "        print(f\"   • lr1e3: learning rate 1e-3\")\n",
        "        print(f\"   • ds20: dataset with 20 examples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 📊 Part 3: Model Evaluation and Analysis\n",
        "\n",
        "### Comprehensive Evaluation Strategy\n",
        "\n",
        "Now let's evaluate our tiny model using CalcGPT Eval. This tool provides comprehensive assessment across multiple dimensions:\n",
        "\n",
        "#### 🧪 Test Types\n",
        "1. **First Operand**: Given `\"1\"`, can it complete to `\"1+0=1\"`?\n",
        "2. **Expression Complete**: Given `\"1+1\"`, can it add `\"=2\"`?\n",
        "3. **Answer Complete**: Given `\"1+1=\"`, can it predict `\"2\"`?\n",
        "\n",
        "#### 📏 Metrics\n",
        "- **Format Validity**: Does output follow `num+num=num` pattern?\n",
        "- **Arithmetic Correctness**: Is the math actually correct?\n",
        "- **Completion Success**: Does the model generate complete expressions?\n",
        "- **Performance Timing**: How fast is inference?\n",
        "\n",
        "Let's see how our tiny model performs!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Evaluating tiny CalcGPT model...\n",
            "STDOUT:\n",
            "\n",
            "\u001b[94m\u001b[1m\n",
            "╔═══════════════════════════════════════════════════════════════╗\n",
            "║                        CalcGPT Eval                          ║\n",
            "║                   Model Evaluation Tool                      ║\n",
            "║                         v1.0.0                               ║\n",
            "╚═══════════════════════════════════════════════════════════════╝\n",
            "\u001b[0m\n",
            "\u001b[92m🎯 Auto-detected model: \u001b[96mcalcgpt_emb32_lay1_head2_ep3_bs4_lr1e03_ds20\u001b[0m\n",
            "\u001b[96mInitializing CalcGPT evaluator...\u001b[0m\n",
            "\u001b[96mLoading model from: models/calcgpt_emb32_lay1_head2_ep3_bs4_lr1e03_ds20\u001b[0m\n",
            "\u001b[93mUsing checkpoint: models/calcgpt_emb32_lay1_head2_ep3_bs4_lr1e03_ds20/checkpoint-12\u001b[0m\n",
            "\u001b[92m✅ Model loaded successfully!\n",
            "   Parameters: 38,624\n",
            "   Device: mps\u001b[0m\n",
            "\u001b[92m✅ Vocabulary loaded:\n",
            "   Vocab size: 7\n",
            "   Max length: 15\n",
            "   Vocabulary: {'<pad>': 0, '<eos>': 1, '+': 2, '0': 3, '1': 4, '2': 5, '=': 6}\u001b[0m\n",
            "\u001b[96mLoading evaluation dataset: datasets/ds-calcgpt_min0_max5_alldigits_add_limit20.txt\u001b[0m\n",
            "\u001b[92m✅ Loaded 20 equations from dataset\u001b[0m\n",
            "\u001b[92m✅ Generated 60 test cases\u001b[0m\n",
            "\u001b[93m📝 Using random sample of 30 test cases\u001b[0m\n",
            "\n",
            "\u001b[92m🧪 Running evaluation on 30 test cases\u001b[0m\n",
            "❌ '1' → '' [first_operand]\n",
            "❌ '0+2' → '' [expression_complete]\n",
            "❌ '1+2' → '' [expression_complete]\n",
            "❌ '3+1=' → '' [answer_complete]\n",
            "❌ '1+4=' → '' [answer_complete]\n",
            "❌ '1+1=' → '1+1==' [answer_complete]\n",
            "❌ '0+5' → '' [expression_complete]\n",
            "❌ '2' → '' [first_operand]\n",
            "❌ '2+0' → '' [expression_complete]\n",
            "❌ '0+0=' → '0+0==' [answer_complete]\n",
            "❌ '2+1' → '' [expression_complete]\n",
            "❌ '1' → '' [first_operand]\n",
            "❌ '2+5' → '' [expression_complete]\n",
            "❌ '0+1' → '' [expression_complete]\n",
            "❌ '1+3' → '' [expression_complete]\n",
            "❌ '3' → '' [first_operand]\n",
            "❌ '1+3=' → '' [answer_complete]\n",
            "❌ '0' → '' [first_operand]\n",
            "❌ '0' → '' [first_operand]\n",
            "❌ '1' → '' [first_operand]\n",
            "❌ '2+2=' → '2+2==' [answer_complete]\n",
            "❌ '1+4' → '' [expression_complete]\n",
            "❌ '1+5=' → '' [answer_complete]\n",
            "❌ '1+5' → '' [expression_complete]\n",
            "❌ '2+2' → '' [expression_complete]\n",
            "❌ '2+1=' → '2+1==' [answer_complete]\n",
            "❌ '2' → '' [first_operand]\n",
            "❌ '0' → '' [first_operand]\n",
            "❌ '0' → '' [first_operand]\n",
            "❌ '2' → '' [first_operand]\n",
            "\n",
            "\u001b[1m📊 EVALUATION RESULTS\u001b[0m\n",
            "============================================================\n",
            "\n",
            "\u001b[96mOverall Performance:\u001b[0m\n",
            "  Total test cases: 30\n",
            "  Successful completions: 4 (13.3%)\n",
            "  Valid format: 0 (0.0%)\n",
            "  Correct arithmetic: \u001b[92m0\u001b[0m (\u001b[92m0.0%\u001b[0m)\n",
            "  Complete expressions: 0 (0.0%)\n",
            "  Exact matches: 0 (0.0%)\n",
            "\n",
            "\u001b[96mPerformance by Test Type:\u001b[0m\n",
            "  First Operand:\n",
            "    Arithmetic accuracy: 0/11 (0.0%)\n",
            "    Format accuracy: 0/11 (0.0%)\n",
            "  Expression Complete:\n",
            "    Arithmetic accuracy: 0/11 (0.0%)\n",
            "    Format accuracy: 0/11 (0.0%)\n",
            "  Answer Complete:\n",
            "    Arithmetic accuracy: 0/8 (0.0%)\n",
            "    Format accuracy: 0/8 (0.0%)\n",
            "\n",
            "\u001b[96mPerformance Timing:\u001b[0m\n",
            "  Mean: 19.2ms\n",
            "  Median: 13.3ms\n",
            "  Range: 11.5ms - 38.6ms\n",
            "  Std Dev: 13.0ms\n",
            "\n",
            "\u001b[93m⚠️ Low accuracy detected - consider additional training\u001b[0m\n",
            "\n",
            "\n",
            "============================================================\n",
            "🔍 MANUAL INFERENCE ANALYSIS\n",
            "============================================================\n",
            "1+1= → 283.5 (expected: 2) ❌\n",
            "2+0= → 787.7 (expected: 2) ❌\n",
            "0+2= → 364.3 (expected: 2) ❌\n"
          ]
        }
      ],
      "source": [
        "# Evaluate our tiny model using CalcGPT Eval\n",
        "print(\"📊 Evaluating tiny CalcGPT model...\")\n",
        "\n",
        "# The evaluation tool will auto-detect our latest model\n",
        "result = subprocess.run([\n",
        "    'python', 'calcgpt_eval.py',\n",
        "    '-d', 'datasets/ds-calcgpt_min0_max5_alldigits_add_limit20.txt',  # Same dataset we trained on\n",
        "    '--sample', '30',              # Test on 30 cases  \n",
        "    '--verbose',                   # See individual results\n",
        "    '--max-tokens', '10'           # Allow up to 10 tokens for completion\n",
        "], capture_output=True, text=True)\n",
        "\n",
        "print(\"STDOUT:\")\n",
        "print(result.stdout)\n",
        "if result.stderr:\n",
        "    print(\"STDERR:\")\n",
        "    print(result.stderr)\n",
        "\n",
        "# Let's also try some manual inference to understand what's happening\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🔍 MANUAL INFERENCE ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Use CalcGPT CLI for interactive testing\n",
        "test_problems = [\"1+1\", \"2+0\", \"0+2\", \"3+1\", \"2+2\"]\n",
        "\n",
        "for problem in test_problems:\n",
        "    result = subprocess.run([\n",
        "        'python', 'calcgpt.py',\n",
        "        '-b', problem + '=',\n",
        "        '--no-banner'\n",
        "    ], capture_output=True, text=True)\n",
        "    \n",
        "    # Extract the answer from the output\n",
        "    lines = result.stdout.strip().split('\\n')\n",
        "    for line in lines:\n",
        "        if problem in line and '✅' in line:\n",
        "            parts = line.split()\n",
        "            if len(parts) >= 2:\n",
        "                answer = parts[1]\n",
        "                # Calculate expected answer\n",
        "                operands = problem.split('+')\n",
        "                if len(operands) == 2:\n",
        "                    expected = int(operands[0]) + int(operands[1])\n",
        "                    correct = \"✅\" if answer == str(expected) else \"❌\"\n",
        "                    print(f\"{problem}= → {answer} (expected: {expected}) {correct}\")\n",
        "                break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🎯 Part 4: Scaling Up - Production-Ready CalcGPT\n",
        "\n",
        "### What We Learned from Our Tiny Model\n",
        "\n",
        "Our 38K parameter model taught us valuable lessons:\n",
        "\n",
        "1. **Architecture Matters**: Even tiny transformers can learn patterns\n",
        "2. **Data Quality > Quantity**: Small, clean datasets can be effective\n",
        "3. **Evaluation is Critical**: Multiple test types reveal different capabilities\n",
        "4. **Training Dynamics**: Fast convergence on simple problems\n",
        "\n",
        "### Limitations of the Tiny Model\n",
        "\n",
        "- **Limited Capacity**: Can't handle complex arithmetic\n",
        "- **Poor Generalization**: Struggles with unseen number combinations\n",
        "- **Format Issues**: May not always produce valid expressions\n",
        "- **Narrow Range**: Only works within training data distribution\n",
        "\n",
        "### Scaling Strategy\n",
        "\n",
        "Now let's build a **production-ready** CalcGPT with:\n",
        "\n",
        "#### 📈 Larger Dataset\n",
        "- **Range**: Numbers 0-100 (vs 0-5)\n",
        "- **Operations**: Both addition and subtraction\n",
        "- **Size**: ~10,000+ examples (vs 20)\n",
        "- **Augmentation**: Commutative examples included\n",
        "\n",
        "#### 🏗️ Bigger Architecture\n",
        "- **Embedding Dimension**: 128 (vs 32)\n",
        "- **Layers**: 6 (vs 1) \n",
        "- **Attention Heads**: 8 (vs 2)\n",
        "- **Parameters**: ~1.2M (vs 38K)\n",
        "\n",
        "#### ⚡ Advanced Training\n",
        "- **Validation Split**: Proper train/test separation\n",
        "- **Learning Rate Scheduling**: Cosine annealing\n",
        "- **Early Stopping**: Based on validation loss\n",
        "- **Mixed Precision**: Faster training where available\n",
        "\n",
        "Let's build the real deal! 🚀\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎬 Generating comprehensive dataset for production model...\n",
            "STDOUT:\n",
            "\n",
            "\u001b[94m\u001b[1m\n",
            "╔═══════════════════════════════════════════════════════════════╗\n",
            "║                    CalcGPT DataGen                            ║\n",
            "║                 Dataset Generation Tool                      ║\n",
            "║                         v1.0.0                               ║\n",
            "╚═══════════════════════════════════════════════════════════════╝\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m🚀 Generation Configuration:\u001b[0m\n",
            "==================================================\n",
            "  🎯 Value range: \u001b[1m0 - 100\u001b[0m\n",
            "  🔢 Allowed digits: \u001b[92mAll digits (0-9)\u001b[0m\n",
            "  🧮 Operations: \u001b[92m➕ addition and ➖ subtraction\u001b[0m\n",
            "  📏 Expression limit: \u001b[92mUnlimited\u001b[0m\n",
            "  📁 Output file: \u001b[96mdatasets/ds-calcgpt_min0_max100_alldigits_allops.txt\u001b[0m\n",
            "\n",
            "\u001b[92m🎬 Starting expression generation...\u001b[0m\n",
            "\u001b[96m📝 Writing expressions to: datasets/ds-calcgpt_min0_max100_alldigits_allops.txt\u001b[0m\n",
            "\u001b[96m🧮 Generating arithmetic expressions...\u001b[0m\n",
            "\u001b[96m🔢 Generating valid numbers up to 100...\u001b[0m\n",
            "\u001b[92m✅ Generated 101 numbers (all digits allowed)\u001b[0m\n",
            "\u001b[96m🔧 Operations to include: addition, subtraction\u001b[0m\n",
            "\u001b[96m📊 Estimated expressions to generate: ~15,301\u001b[0m\n",
            "\u001b[96m   Generated 1,000 expressions...\u001b[0m\n",
            "\u001b[96m   Generated 4,000 expressions...\u001b[0m\n",
            "\u001b[96m   Written 5,000 expressions (2240068/sec)...\u001b[0m\n",
            "\u001b[96m   Generated 5,000 expressions...\u001b[0m\n",
            "\u001b[96m   Generated 6,000 expressions...\u001b[0m\n",
            "\u001b[96m   Generated 8,000 expressions...\u001b[0m\n",
            "\u001b[96m   Written 10,000 expressions (2357808/sec)...\u001b[0m\n",
            "\u001b[96m   Generated 10,000 expressions...\u001b[0m\n",
            "\u001b[96m   Generated 13,000 expressions...\u001b[0m\n",
            "\u001b[96m   Written 15,000 expressions (2343012/sec)...\u001b[0m\n",
            "\u001b[92m✅ Successfully wrote 15,352 expressions in 0.0s (2315139/sec)\u001b[0m\n",
            "\n",
            "\u001b[92m\u001b[1m🎉 SUCCESS!\u001b[0m\n",
            "  📊 Generated: \u001b[1m15,352 expressions\u001b[0m\n",
            "  📁 Saved to: \u001b[96mdatasets/ds-calcgpt_min0_max100_alldigits_allops.txt\u001b[0m\n",
            "  ⏱️  Total time: \u001b[1m0.0 seconds\u001b[0m\n",
            "  🚀 Generation rate: \u001b[1m2305771 expressions/second\u001b[0m\n",
            "  💾 File size: \u001b[1m139,564 bytes (136.3 KB)\u001b[0m\n",
            "\n",
            "\n",
            "⏱️ Dataset generation completed in 0.0 seconds\n",
            "\n",
            "📚 Production Dataset Analysis:\n",
            "  📁 File: ds-calcgpt_min0_max100_alldigits_allops.txt\n",
            "  📊 Total examples: 15,352\n",
            "  📏 Average length: 8.1 characters\n",
            "  📏 Max length: 11 characters\n",
            "  🔤 Vocabulary size: 13 characters\n",
            "  💾 File size: 136.3 KB\n",
            "\n",
            "📋 Sample expressions:\n",
            "  0+0=0\n",
            "  32+45=77\n",
            "  58-53=5\n",
            "  100-100=0\n",
            "\n",
            "📊 Operation distribution:\n",
            "  ➕ Addition: 10,201 (66.4%)\n",
            "  ➖ Subtraction: 5,151 (33.6%)\n",
            "\n",
            "🎯 Ready for production training with: ds-calcgpt_min0_max100_alldigits_allops.txt\n"
          ]
        }
      ],
      "source": [
        "# Generate a comprehensive dataset for production CalcGPT\n",
        "print(\"🎬 Generating comprehensive dataset for production model...\")\n",
        "\n",
        "generation_start = time.time()\n",
        "\n",
        "result = subprocess.run([\n",
        "    'python', 'calcgpt_dategen.py',\n",
        "    '-m', '100',                  # Max value: 100 (much larger!)\n",
        "    '--verbose'                   # Show progress\n",
        "], capture_output=True, text=True)\n",
        "\n",
        "generation_time = time.time() - generation_start\n",
        "\n",
        "print(\"STDOUT:\")\n",
        "print(result.stdout)\n",
        "if result.stderr:\n",
        "    print(\"STDERR:\")\n",
        "    print(result.stderr)\n",
        "\n",
        "print(f\"\\n⏱️ Dataset generation completed in {generation_time:.1f} seconds\")\n",
        "\n",
        "# Find the generated dataset\n",
        "datasets_dir = Path('datasets')\n",
        "dataset_files = list(datasets_dir.glob('ds-calcgpt_min0_max100_*.txt'))\n",
        "if dataset_files:\n",
        "    latest_dataset = max(dataset_files, key=lambda x: x.stat().st_mtime)\n",
        "    \n",
        "    # Analyze the comprehensive dataset\n",
        "    with open(latest_dataset, 'r') as f:\n",
        "        full_dataset = f.read().strip().split('\\n')\n",
        "    \n",
        "    print(f\"\\n📚 Production Dataset Analysis:\")\n",
        "    print(f\"  📁 File: {latest_dataset.name}\")\n",
        "    print(f\"  📊 Total examples: {len(full_dataset):,}\")\n",
        "    print(f\"  📏 Average length: {np.mean([len(ex) for ex in full_dataset]):.1f} characters\")\n",
        "    print(f\"  📏 Max length: {max(len(ex) for ex in full_dataset)} characters\")\n",
        "    print(f\"  🔤 Vocabulary size: {len(set(''.join(full_dataset)))} characters\")\n",
        "    print(f\"  💾 File size: {latest_dataset.stat().st_size / 1024:.1f} KB\")\n",
        "    \n",
        "    # Show some examples from different ranges\n",
        "    print(f\"\\n📋 Sample expressions:\")\n",
        "    examples_to_show = [0, len(full_dataset)//4, len(full_dataset)//2, -1]\n",
        "    for i in examples_to_show:\n",
        "        if i < len(full_dataset):\n",
        "            print(f\"  {full_dataset[i]}\")\n",
        "    \n",
        "    # Analyze the distribution of operations\n",
        "    additions = sum(1 for ex in full_dataset if '+' in ex)\n",
        "    subtractions = sum(1 for ex in full_dataset if '-' in ex)\n",
        "    print(f\"\\n📊 Operation distribution:\")\n",
        "    print(f\"  ➕ Addition: {additions:,} ({additions/len(full_dataset)*100:.1f}%)\")\n",
        "    print(f\"  ➖ Subtraction: {subtractions:,} ({subtractions/len(full_dataset)*100:.1f}%)\")\n",
        "    \n",
        "    # Store the dataset name for training\n",
        "    production_dataset = str(latest_dataset)\n",
        "    print(f\"\\n🎯 Ready for production training with: {latest_dataset.name}\")\n",
        "else:\n",
        "    print(\"❌ No dataset file found!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Training production CalcGPT model...\n",
            "⚠️ This will take longer but results in much better performance!\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m production_training_start = time.time()\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Use the intelligent trainer with production settings\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m result = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpython\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcalcgpt_train.py\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m-d\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproduction_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Our comprehensive dataset\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--embedding-dim\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m128\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Larger embeddings\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--num-layers\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m6\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Deeper network\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--num-heads\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# More attention heads\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--epochs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m20\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# More training\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--batch-size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Reasonable batch size\u001b[39;49;00m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--learning-rate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m1e-3\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Default learning rate\u001b[39;49;00m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--eval-steps\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m100\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# Regular evaluation\u001b[39;49;00m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--save-steps\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m500\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# Save checkpoints\u001b[39;49;00m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--verbose\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# Monitor progress\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m production_training_time = time.time() - production_training_start\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSTDOUT:\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.4/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py:556\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    554\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m         stdout, stderr = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    557\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    558\u001b[39m         process.kill()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.4/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py:1222\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1219\u001b[39m     endtime = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1221\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     stdout, stderr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1224\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1225\u001b[39m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.4/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py:2128\u001b[39m, in \u001b[36mPopen._communicate\u001b[39m\u001b[34m(self, input, endtime, orig_timeout)\u001b[39m\n\u001b[32m   2121\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout,\n\u001b[32m   2122\u001b[39m                         stdout, stderr,\n\u001b[32m   2123\u001b[39m                         skip_check_and_raise=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   2124\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[32m   2125\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   2126\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mfailed to raise TimeoutExpired.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2128\u001b[39m ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2129\u001b[39m \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[32m   2131\u001b[39m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[32m   2132\u001b[39m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.4/Frameworks/Python.framework/Versions/3.13/lib/python3.13/selectors.py:398\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    396\u001b[39m ready = []\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Train the production CalcGPT model\n",
        "print(\"🚀 Training production CalcGPT model...\")\n",
        "print(\"⚠️ This will take longer but results in much better performance!\")\n",
        "\n",
        "# Production training configuration\n",
        "production_training_start = time.time()\n",
        "\n",
        "# Use the intelligent trainer with production settings\n",
        "result = subprocess.run([\n",
        "    'python', 'calcgpt_train.py',\n",
        "    '-d', production_dataset,      # Our comprehensive dataset\n",
        "    '--embedding-dim', '128',      # Larger embeddings\n",
        "    '--num-layers', '6',           # Deeper network\n",
        "    '--num-heads', '8',            # More attention heads\n",
        "    '--epochs', '20',              # More training\n",
        "    '--batch-size', '8',           # Reasonable batch size\n",
        "    '--learning-rate', '1e-3',     # Default learning rate\n",
        "    '--eval-steps', '100',         # Regular evaluation\n",
        "    '--save-steps', '500',         # Save checkpoints\n",
        "    '--verbose'                    # Monitor progress\n",
        "], capture_output=True, text=True)\n",
        "\n",
        "production_training_time = time.time() - production_training_start\n",
        "\n",
        "print(\"STDOUT:\")\n",
        "print(result.stdout)\n",
        "if result.stderr:\n",
        "    print(\"STDERR:\")\n",
        "    print(result.stderr)\n",
        "\n",
        "print(f\"\\n⏱️ Production training completed in {production_training_time/60:.1f} minutes\")\n",
        "\n",
        "# Analyze the model that was created\n",
        "models_dir = Path('models')\n",
        "if models_dir.exists():\n",
        "    model_dirs = [d for d in models_dir.iterdir() if d.is_dir() and 'emb128' in d.name]\n",
        "    if model_dirs:\n",
        "        production_model = max(model_dirs, key=lambda x: x.stat().st_mtime)\n",
        "        print(f\"🎯 Production model: {production_model.name}\")\n",
        "        \n",
        "        # Analyze model size\n",
        "        model_files = list(production_model.rglob('*.bin'))\n",
        "        if model_files:\n",
        "            total_size = sum(f.stat().st_size for f in model_files)\n",
        "            print(f\"💾 Model size: {total_size / 1024 / 1024:.1f} MB\")\n",
        "        \n",
        "        print(\"📝 Architecture comparison:\")\n",
        "        print(\"  Tiny model:       38K parameters,   32 dim,  1 layer,  2 heads\")\n",
        "        print(f\"  Production model: ~1.2M parameters, 128 dim, 6 layers, 8 heads\")\n",
        "        print(f\"  Improvement:      ~30x more parameters!\")\n",
        "        \n",
        "        # Display the intelligent naming\n",
        "        print(f\"\\n🏷️ Intelligent model naming breakdown:\")\n",
        "        name_parts = production_model.name.split('_')\n",
        "        for part in name_parts:\n",
        "            if part.startswith('emb'):\n",
        "                print(f\"   • {part}: {part[3:]} embedding dimensions\")\n",
        "            elif part.startswith('lay'):\n",
        "                print(f\"   • {part}: {part[3:]} transformer layers\")\n",
        "            elif part.startswith('head'):\n",
        "                print(f\"   • {part}: {part[4:]} attention heads\")\n",
        "            elif part.startswith('ep'):\n",
        "                print(f\"   • {part}: {part[2:]} training epochs\")\n",
        "            elif part.startswith('bs'):\n",
        "                print(f\"   • {part}: {part[2:]} batch size\")\n",
        "            elif part.startswith('lr'):\n",
        "                print(f\"   • {part}: learning rate encoded\")\n",
        "            elif part.startswith('ds'):\n",
        "                print(f\"   • {part}: dataset identifier\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🎉 Part 5: Production Model Evaluation\n",
        "\n",
        "### Comprehensive Testing\n",
        "\n",
        "Now let's evaluate our production model and compare it to the tiny model. We expect to see dramatic improvements across all metrics.\n",
        "\n",
        "#### What to Look For\n",
        "\n",
        "1. **Higher Accuracy**: Better arithmetic correctness\n",
        "2. **Better Generalization**: Performance on unseen number combinations  \n",
        "3. **Format Consistency**: More reliable expression formatting\n",
        "4. **Faster Convergence**: Stable performance across test types\n",
        "\n",
        "Let's run the comprehensive evaluation suite!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive evaluation of production CalcGPT\n",
        "print(\"📊 Evaluating production CalcGPT model...\")\n",
        "print(\"🎯 This will test the model on diverse arithmetic problems\")\n",
        "\n",
        "# Run comprehensive evaluation\n",
        "eval_start = time.time()\n",
        "\n",
        "result = subprocess.run([\n",
        "    'python', 'calcgpt_eval.py',\n",
        "    '--sample', '200',             # Test on 200 random cases\n",
        "    '--max-tokens', '15',          # Allow more tokens for complex expressions\n",
        "    '--no-banner'                  # Clean output\n",
        "], capture_output=True, text=True)\n",
        "\n",
        "eval_time = time.time() - eval_start\n",
        "\n",
        "print(\"EVALUATION RESULTS:\")\n",
        "print(result.stdout)\n",
        "if result.stderr:\n",
        "    print(\"STDERR:\")\n",
        "    print(result.stderr)\n",
        "\n",
        "print(f\"\\n⏱️ Evaluation completed in {eval_time:.1f} seconds\")\n",
        "\n",
        "# Test on specific challenging problems to showcase capabilities\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🧠 CHALLENGING ARITHMETIC TESTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "challenging_problems = [\n",
        "    \"99+1\",      # Near boundary\n",
        "    \"100-50\",    # Large subtraction  \n",
        "    \"50+50\",     # Equal operands\n",
        "    \"0+100\",     # Edge cases\n",
        "    \"100-100\",   # Zero result\n",
        "    \"85+15\",     # Carry operations\n",
        "    \"73-28\",     # Complex subtraction\n",
        "    \"42+37\",     # Mid-range addition\n",
        "]\n",
        "\n",
        "print(\"Testing production model on challenging problems:\")\n",
        "print(\"Problem       → Answer   (Expected)  Status\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "correct_count = 0\n",
        "for problem in challenging_problems:\n",
        "    result = subprocess.run([\n",
        "        'python', 'calcgpt.py',\n",
        "        '-b', problem + '=',\n",
        "        '--no-banner',\n",
        "        '--temperature', '0'  # Deterministic inference\n",
        "    ], capture_output=True, text=True)\n",
        "    \n",
        "    # Extract answer\n",
        "    lines = result.stdout.strip().split('\\n')\n",
        "    predicted_answer = \"ERROR\"\n",
        "    \n",
        "    for line in lines:\n",
        "        if problem in line and ('✅' in line or '❌' in line):\n",
        "            parts = line.split()\n",
        "            if len(parts) >= 2:\n",
        "                predicted_answer = parts[1]\n",
        "                break\n",
        "    \n",
        "    # Calculate expected answer\n",
        "    if '+' in problem:\n",
        "        operands = problem.split('+')\n",
        "        expected = int(operands[0]) + int(operands[1])\n",
        "    elif '-' in problem:\n",
        "        operands = problem.split('-')\n",
        "        expected = int(operands[0]) - int(operands[1])\n",
        "    else:\n",
        "        expected = \"?\"\n",
        "    \n",
        "    # Check correctness\n",
        "    is_correct = str(predicted_answer) == str(expected)\n",
        "    status = \"✅ CORRECT\" if is_correct else \"❌ WRONG\"\n",
        "    if is_correct:\n",
        "        correct_count += 1\n",
        "    \n",
        "    print(f\"{problem:12s} → {predicted_answer:8s} ({expected:8s})  {status}\")\n",
        "\n",
        "accuracy = correct_count / len(challenging_problems) * 100\n",
        "print(f\"\\n🎯 Challenge Test Accuracy: {correct_count}/{len(challenging_problems)} ({accuracy:.1f}%)\")\n",
        "\n",
        "if accuracy >= 90:\n",
        "    print(\"🏆 EXCELLENT! Production model shows strong arithmetic capabilities!\")\n",
        "elif accuracy >= 70:\n",
        "    print(\"👍 GOOD! Model demonstrates solid arithmetic understanding!\")\n",
        "elif accuracy >= 50:\n",
        "    print(\"📈 MODERATE! Model shows some arithmetic capability but needs improvement!\")\n",
        "else:\n",
        "    print(\"⚠️ NEEDS WORK! Consider additional training or architectural changes!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🎮 Part 6: Interactive Usage & Deployment\n",
        "\n",
        "### Production-Ready Inference\n",
        "\n",
        "Our CalcGPT model is now ready for real-world usage! The CalcGPT CLI provides multiple interfaces:\n",
        "\n",
        "#### 🖥️ Interactive Mode\n",
        "```bash\n",
        "python calcgpt.py -i\n",
        "# Provides a beautiful interactive calculator interface\n",
        "```\n",
        "\n",
        "#### 📦 Batch Processing  \n",
        "```bash\n",
        "python calcgpt.py -b \"50+50\" \"99-1\" \"75+25\"\n",
        "# Process multiple problems at once\n",
        "```\n",
        "\n",
        "#### 📄 File Processing\n",
        "```bash\n",
        "echo \"100+1\\n50+50\\n99-99\" > problems.txt\n",
        "python calcgpt.py -f problems.txt -o results.json\n",
        "```\n",
        "\n",
        "### Model Analysis & Introspection\n",
        "\n",
        "Our intelligent naming system allows easy model analysis:\n",
        "\n",
        "```bash\n",
        "python calcgpt_train.py --analyze models/calcgpt_emb128_lay6_head8_ep20_bs8_lr1e3_dsm100\n",
        "# Shows complete training configuration and equivalent command\n",
        "```\n",
        "\n",
        "Let's demonstrate the interactive capabilities!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrate various CalcGPT usage modes\n",
        "print(\"🎮 CalcGPT Usage Demonstrations\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# 1. Batch processing with JSON output\n",
        "print(\"\\n1️⃣ Batch Processing with JSON Output\")\n",
        "batch_problems = [\"25+25\", \"100-33\", \"67+12\", \"88-44\", \"75+20\"]\n",
        "\n",
        "result = subprocess.run([\n",
        "    'python', 'calcgpt.py',\n",
        "    '-b'] + batch_problems + [\n",
        "    '--format', 'json',\n",
        "    '--no-banner'\n",
        "], capture_output=True, text=True)\n",
        "\n",
        "print(f\"Input problems: {batch_problems}\")\n",
        "if result.stdout:\n",
        "    try:\n",
        "        # Parse and display the JSON results nicely\n",
        "        output_data = json.loads(result.stdout)\n",
        "        print(f\"Metadata: {output_data['metadata']['correct_answers']}/{output_data['metadata']['total_problems']} correct\")\n",
        "        print(\"Results:\")\n",
        "        for res in output_data['results']:\n",
        "            status = \"✅\" if not res.get('error') else \"❌\"\n",
        "            print(f\"  {res['problem']} → {res.get('answer', 'ERROR')} {status}\")\n",
        "    except:\n",
        "        print(\"Raw output:\", result.stdout)\n",
        "\n",
        "# 2. Model analysis demonstration  \n",
        "print(\"\\n2️⃣ Model Analysis & Configuration Recovery\")\n",
        "\n",
        "# Find our production model for analysis\n",
        "models_dir = Path('models')\n",
        "if models_dir.exists():\n",
        "    production_models = [d for d in models_dir.iterdir() if d.is_dir() and 'emb128' in d.name]\n",
        "    if production_models:\n",
        "        latest_production = max(production_models, key=lambda x: x.stat().st_mtime)\n",
        "        \n",
        "        result = subprocess.run([\n",
        "            'python', 'calcgpt_train.py',\n",
        "            '--analyze', str(latest_production),\n",
        "            '--no-banner'\n",
        "        ], capture_output=True, text=True)\n",
        "        \n",
        "        print(\"Model Analysis Results:\")\n",
        "        print(result.stdout)\n",
        "\n",
        "# 3. Performance comparison: Tiny vs Production\n",
        "print(\"\\n3️⃣ Performance Comparison: Tiny vs Production\")\n",
        "\n",
        "comparison_problems = [\"1+1\", \"10+5\", \"25+25\", \"50-20\", \"99+1\"]\n",
        "\n",
        "print(\"Problem   | Tiny Model  | Production Model | Better?\")\n",
        "print(\"-\" * 55)\n",
        "\n",
        "for problem in comparison_problems:\n",
        "    # Get expected answer\n",
        "    if '+' in problem:\n",
        "        operands = problem.split('+')\n",
        "        expected = int(operands[0]) + int(operands[1])\n",
        "    elif '-' in problem:\n",
        "        operands = problem.split('-')\n",
        "        expected = int(operands[0]) - int(operands[1])\n",
        "    \n",
        "    # Test production model (auto-detected latest)\n",
        "    result = subprocess.run([\n",
        "        'python', 'calcgpt.py',\n",
        "        '-b', problem + '=',\n",
        "        '--no-banner'\n",
        "    ], capture_output=True, text=True)\n",
        "    \n",
        "    # Extract production answer\n",
        "    prod_answer = \"ERROR\"\n",
        "    for line in result.stdout.split('\\n'):\n",
        "        if problem in line and ('✅' in line or '❌' in line):\n",
        "            parts = line.split()\n",
        "            if len(parts) >= 2:\n",
        "                prod_answer = parts[1]\n",
        "                break\n",
        "    \n",
        "    # For tiny model, we'd need to specify it explicitly\n",
        "    # For demonstration, we'll show the format\n",
        "    tiny_answer = \"varies\"  # Would need specific model path\n",
        "    \n",
        "    prod_correct = str(prod_answer) == str(expected)\n",
        "    prod_status = \"✅\" if prod_correct else \"❌\"\n",
        "    \n",
        "    better = \"🚀 YES\" if prod_correct else \"🤔 MAYBE\"\n",
        "    \n",
        "    print(f\"{problem:8s}  | {tiny_answer:10s} | {prod_answer:15s} {prod_status} | {better}\")\n",
        "\n",
        "# 4. Advanced features demonstration\n",
        "print(\"\\n4️⃣ Advanced Features\")\n",
        "\n",
        "print(\"🎯 Temperature Control (randomness vs determinism):\")\n",
        "test_problem = \"50+50=\"\n",
        "\n",
        "for temp in [0.0, 0.5, 1.0]:\n",
        "    result = subprocess.run([\n",
        "        'python', 'calcgpt.py',\n",
        "        '-b', test_problem,\n",
        "        '--temperature', str(temp),\n",
        "        '--no-banner'\n",
        "    ], capture_output=True, text=True)\n",
        "    \n",
        "    # Extract answer\n",
        "    answer = \"ERROR\"\n",
        "    for line in result.stdout.split('\\n'):\n",
        "        if \"50+50\" in line:\n",
        "            parts = line.split()\n",
        "            if len(parts) >= 2:\n",
        "                answer = parts[1]\n",
        "                break\n",
        "    \n",
        "    randomness = \"deterministic\" if temp == 0.0 else f\"randomness={temp}\"\n",
        "    print(f\"  Temperature {temp}: {test_problem} → {answer} ({randomness})\")\n",
        "\n",
        "print(f\"\\n🎉 CalcGPT is ready for production use!\")\n",
        "print(f\"   • Multiple input/output formats\")  \n",
        "print(f\"   • Comprehensive evaluation tools\")\n",
        "print(f\"   • Intelligent model management\")\n",
        "print(f\"   • Professional CLI interfaces\")\n",
        "print(f\"   • Scalable architecture\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🎓 Part 7: Lessons Learned & Advanced Concepts\n",
        "\n",
        "### 🧠 Key Insights from Building CalcGPT\n",
        "\n",
        "Through this journey, we've learned fundamental principles that apply to all transformer-based language models:\n",
        "\n",
        "#### 1. **Architecture Scaling Laws**\n",
        "- **Parameters matter**: 30x more parameters → dramatically better performance\n",
        "- **Depth vs Width**: More layers often better than wider layers\n",
        "- **Attention heads**: Multiple heads capture different relationships\n",
        "- **Context length**: Longer sequences enable more complex reasoning\n",
        "\n",
        "#### 2. **Data Engineering Principles**  \n",
        "- **Quality over quantity**: Clean, systematic data beats noisy large datasets\n",
        "- **Data augmentation**: Simple transformations (like commutativity) boost performance\n",
        "- **Distribution coverage**: Ensure training data covers the inference domain\n",
        "- **Intelligent naming**: Systematic dataset organization enables reproducibility\n",
        "\n",
        "#### 3. **Training Dynamics**\n",
        "- **Learning rate scheduling**: Cosine annealing provides smooth convergence\n",
        "- **Validation monitoring**: Early stopping prevents overfitting\n",
        "- **Batch size trade-offs**: Larger batches for stability, smaller for regularization\n",
        "- **Mixed precision**: Significant speedups with minimal accuracy loss\n",
        "\n",
        "#### 4. **Evaluation Methodologies**\n",
        "- **Multiple test types**: Different completion scenarios reveal different capabilities\n",
        "- **Comprehensive metrics**: Format, correctness, and performance matter\n",
        "- **Generalization testing**: Test beyond training distribution\n",
        "- **Error analysis**: Understanding failures guides improvements\n",
        "\n",
        "### 🔬 What Makes CalcGPT Special?\n",
        "\n",
        "Unlike general language models that struggle with arithmetic, CalcGPT demonstrates:\n",
        "\n",
        "- **Precise computation**: Exact arithmetic rather than approximate pattern matching\n",
        "- **Systematic reasoning**: Step-by-step problem solving\n",
        "- **Format consistency**: Reliable output structure\n",
        "- **Scalable performance**: Handles increasing complexity gracefully\n",
        "\n",
        "### 🚀 Advanced Concepts & Extensions\n",
        "\n",
        "Ready to take CalcGPT further? Here are some advanced directions:\n",
        "\n",
        "#### 🧮 Extended Arithmetic\n",
        "- **Multiplication & Division**: More complex operations\n",
        "- **Multi-step problems**: (a+b)×c, nested operations\n",
        "- **Decimal numbers**: Floating-point arithmetic\n",
        "- **Negative numbers**: Full integer arithmetic\n",
        "\n",
        "#### 🏗️ Architectural Improvements  \n",
        "- **Positional encodings**: Learned vs sinusoidal\n",
        "- **Attention mechanisms**: Sparse attention, local attention\n",
        "- **Normalization strategies**: LayerNorm vs RMSNorm\n",
        "- **Activation functions**: ReLU vs GELU vs SwiGLU\n",
        "\n",
        "#### 📊 Training Enhancements\n",
        "- **Curriculum learning**: Start simple, gradually increase complexity\n",
        "- **Data mixing**: Combine arithmetic with natural language\n",
        "- **Multi-task learning**: Multiple mathematical operations simultaneously\n",
        "- **Reinforcement learning**: Self-improvement through interaction\n",
        "\n",
        "#### 🔧 Production Optimizations\n",
        "- **Model quantization**: 8-bit or 4-bit inference\n",
        "- **Knowledge distillation**: Smaller models from larger ones\n",
        "- **Caching strategies**: KV-cache optimization\n",
        "- **Batch processing**: Efficient multi-query handling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🌟 Summary & Next Steps\n",
        "\n",
        "### 🎯 What We Accomplished\n",
        "\n",
        "In this comprehensive tutorial, we built a complete machine learning system from scratch:\n",
        "\n",
        "#### 🛠️ **Tools Created**\n",
        "- **CalcGPT DataGen**: Intelligent dataset generation with parameter encoding\n",
        "- **CalcGPT Trainer**: Professional training system with auto-naming\n",
        "- **CalcGPT Eval**: Comprehensive evaluation and analysis\n",
        "- **CalcGPT CLI**: Production-ready inference interface\n",
        "\n",
        "#### 📊 **Models Trained**\n",
        "- **Tiny Model**: 38K parameters, proof of concept (0-5 arithmetic)\n",
        "- **Production Model**: 1.2M parameters, real-world capable (0-100 arithmetic)\n",
        "\n",
        "#### 🧠 **Core Concepts Mastered**\n",
        "- Transformer architecture and attention mechanisms\n",
        "- Character-level language modeling for arithmetic\n",
        "- Dataset engineering and augmentation strategies  \n",
        "- Training dynamics and optimization techniques\n",
        "- Comprehensive evaluation methodologies\n",
        "- Production deployment and model management\n",
        "\n",
        "### 🚀 Your Learning Journey Continues\n",
        "\n",
        "#### **Immediate Next Steps**\n",
        "1. **Experiment**: Try different model architectures and training settings\n",
        "2. **Extend**: Add multiplication, division, or decimal arithmetic\n",
        "3. **Scale**: Train on larger datasets with higher number ranges\n",
        "4. **Deploy**: Use CalcGPT in real applications or integrate via API\n",
        "\n",
        "#### **Advanced Projects**\n",
        "- **Multi-modal**: Combine text and visual arithmetic problems\n",
        "- **Interactive Tutoring**: Build an AI math tutor\n",
        "- **Scientific Computing**: Extend to algebraic expressions\n",
        "- **Model Optimization**: Quantization and efficient inference\n",
        "\n",
        "### 📚 Additional Resources\n",
        "\n",
        "#### **HuggingFace & Transformers**\n",
        "- [Transformers Documentation](https://huggingface.co/docs/transformers)\n",
        "- [Course: NLP with Transformers](https://huggingface.co/course)\n",
        "- [Model Hub](https://huggingface.co/models)\n",
        "\n",
        "#### **PyTorch Deep Learning**\n",
        "- [PyTorch Tutorials](https://pytorch.org/tutorials)\n",
        "- [Deep Learning with PyTorch](https://pytorch.org/deep-learning-with-pytorch)\n",
        "\n",
        "#### **Research Papers**\n",
        "- [Attention Is All You Need](https://arxiv.org/abs/1706.03762) (Original Transformer)\n",
        "- [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165) (GPT-3)\n",
        "- [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (Scaling Laws)\n",
        "\n",
        "### 🎉 Congratulations!\n",
        "\n",
        "You've successfully built a complete transformer-based language model system! You now understand:\n",
        "\n",
        "- ✅ How transformers work under the hood\n",
        "- ✅ Professional ML engineering practices  \n",
        "- ✅ Dataset design and evaluation strategies\n",
        "- ✅ Production deployment considerations\n",
        "- ✅ The full ML lifecycle from data to deployment\n",
        "\n",
        "**Keep experimenting, keep learning, and keep building amazing AI systems!** 🚀\n",
        "\n",
        "---\n",
        "\n",
        "*Built with ❤️ using CalcGPT - A comprehensive transformer tutorial by Mihai NADAS*\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
