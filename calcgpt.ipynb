{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# CalcGPT: Building an Arithmetic Language Model from Scratch\n",
        "\n",
        "**A Complete Guide to Transformer-Based Language Models using HuggingFace and PyTorch**\n",
        "\n",
        "---\n",
        "\n",
        "## 🎯 Overview\n",
        "\n",
        "Welcome to **CalcGPT** - a comprehensive tutorial on building, training, and deploying transformer-based language models for arithmetic tasks. This notebook demonstrates the complete machine learning pipeline from dataset generation to production inference, while teaching fundamental concepts of modern NLP.\n",
        "\n",
        "**🔥 UPDATED**: This notebook now uses the **CalcGPT Library** (`lib/` package) for programmatic access, demonstrating both library usage and CLI tools!\n",
        "\n",
        "### 🌟 What You'll Learn\n",
        "\n",
        "- **Transformer Architecture**: Understanding GPT-2 models and attention mechanisms\n",
        "- **Dataset Engineering**: Creating and analyzing training datasets for language models\n",
        "- **Model Training**: End-to-end training with HuggingFace Transformers\n",
        "- **Evaluation Methodologies**: Comprehensive model assessment and validation\n",
        "- **Production Deployment**: Interactive inference and real-world usage\n",
        "- **Scaling Strategies**: From toy models to production-ready systems\n",
        "- **Library Integration**: Using CalcGPT as both a library and CLI tool\n",
        "\n",
        "### 🛠️ Tools We'll Use\n",
        "\n",
        "- **CalcGPT Library** (`lib/`): Programmatic access to all functionality\n",
        "  - `DatasetGenerator` & `DatagenConfig`: Dataset generation\n",
        "  - `CalcGPTTrainer` & `TrainingConfig`: Model training  \n",
        "  - `CalcGPT` & `InferenceConfig`: Model inference\n",
        "  - `CalcGPTEvaluator` & `EvaluationConfig`: Model evaluation\n",
        "- **CalcGPT CLI Tools**: Interactive command-line interfaces\n",
        "  - `calcgpt_dategen.py`: Dataset generation tool\n",
        "  - `calcgpt_train.py`: Model training tool\n",
        "  - `calcgpt_eval.py`: Model evaluation tool\n",
        "  - `calcgpt.py`: Interactive inference tool\n",
        "\n",
        "### 📚 Learning Path\n",
        "\n",
        "1. **Simple Start**: Basic arithmetic with tiny models (38K parameters) using the library\n",
        "2. **Understanding**: Deep dive into model architecture and training dynamics\n",
        "3. **Scaling Up**: Larger datasets and models (1.2M+ parameters) programmatically\n",
        "4. **Production**: Real-world inference and deployment with both library and CLI\n",
        "\n",
        "Let's build something amazing! 🚀\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🔧 Setup and Imports\n",
        "\n",
        "First, let's import all the necessary libraries and set up our environment. We'll be using modern PyTorch and HuggingFace transformers throughout this tutorial.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/mihai/Coding/jupyter/transformers/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎯 Using device: mps\n",
            "🐍 Python version: 3.13.4 (main, Jun  3 2025, 15:34:24) [Clang 17.0.0 (clang-1700.0.13.3)]\n",
            "🔥 PyTorch version: 2.7.1\n",
            "✅ Setup complete! Ready to build CalcGPT 🚀\n"
          ]
        }
      ],
      "source": [
        "# Core libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "import subprocess\n",
        "import sys\n",
        "\n",
        "# HuggingFace transformers\n",
        "from transformers import GPT2Config, GPT2LMHeadModel, Trainer, TrainingArguments\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# CalcGPT Library - Our new programmatic interface!\n",
        "from lib import (\n",
        "    DatasetGenerator, DatagenConfig,\n",
        "    CalcGPTTrainer, TrainingConfig, \n",
        "    CalcGPT, InferenceConfig,\n",
        "    CalcGPTEvaluator, EvaluationConfig\n",
        ")\n",
        "\n",
        "# Utility imports\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set style for beautiful plots\n",
        "plt.style.use('seaborn-v0_8')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Check available devices\n",
        "device = 'cuda' if torch.cuda.is_available() else 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
        "print(f\"🎯 Using device: {device}\")\n",
        "print(f\"🐍 Python version: {sys.version}\")\n",
        "print(f\"🔥 PyTorch version: {torch.__version__}\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"✅ Setup complete! Ready to build CalcGPT 🚀\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 📊 Part 1: Understanding the Problem & Dataset Generation\n",
        "\n",
        "### The Challenge: Teaching Machines Arithmetic\n",
        "\n",
        "Language models like GPT-3 can write poetry and code, but struggle with basic arithmetic. Why? Because arithmetic requires **precise computation** rather than **pattern matching**. This makes arithmetic an excellent testbed for understanding model capabilities and limitations.\n",
        "\n",
        "### Our Approach: Character-Level Language Modeling\n",
        "\n",
        "We'll treat arithmetic as a **sequence-to-sequence** problem:\n",
        "- **Input**: `\"1+1=\"` \n",
        "- **Target**: `\"1+1=2\"`\n",
        "\n",
        "The model learns to predict the next character given the previous characters, eventually learning to compute arithmetic results.\n",
        "\n",
        "### Dataset Design Philosophy\n",
        "\n",
        "Our CalcGPT DataGen tool creates intelligent datasets with:\n",
        "- **Systematic coverage**: All combinations within specified ranges\n",
        "- **Data augmentation**: Commutative property examples (a+b and b+a)\n",
        "- **Intelligent naming**: Filenames encode generation parameters\n",
        "- **Scalability**: From toy problems to complex arithmetic\n",
        "\n",
        "Let's start by generating a simple dataset for our first model!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎬 Generating simple dataset with CalcGPT DataGen...\n",
            "STDOUT:\n",
            "\n",
            "\u001b[94m\u001b[1m\n",
            "╔═══════════════════════════════════════════════════════════════╗\n",
            "║                    CalcGPT DataGen                            ║\n",
            "║                 Dataset Generation Tool                      ║\n",
            "║                         v1.0.0                               ║\n",
            "╚═══════════════════════════════════════════════════════════════╝\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m🚀 Generation Configuration:\u001b[0m\n",
            "==================================================\n",
            "  🎯 Value range: \u001b[1m0 - 5\u001b[0m\n",
            "  🔢 Allowed digits: \u001b[92mAll digits (0-9)\u001b[0m\n",
            "  🧮 Operations: \u001b[92m➕ addition\u001b[0m\n",
            "  📏 Expression limit: \u001b[93m20\u001b[0m\n",
            "  📁 Output file: \u001b[96mdatasets/ds-calcgpt_min0_max5_alldigits_add_limit20.txt\u001b[0m\n",
            "\n",
            "\u001b[92m🎬 Starting expression generation...\u001b[0m\n",
            "\u001b[96m📝 Writing expressions to: datasets/ds-calcgpt_min0_max5_alldigits_add_limit20.txt\u001b[0m\n",
            "\u001b[96m🧮 Generating arithmetic expressions...\u001b[0m\n",
            "\u001b[96m🔢 Generating valid numbers up to 5...\u001b[0m\n",
            "\u001b[92m✅ Generated 6 numbers (all digits allowed)\u001b[0m\n",
            "\u001b[96m🔧 Operations to include: addition\u001b[0m\n",
            "\u001b[96m📊 Estimated expressions to generate: ~36\u001b[0m\n",
            "\u001b[93m⚠️ Reached maximum expression limit: 20\u001b[0m\n",
            "\u001b[92m✅ Successfully wrote 20 expressions in 0.0s (97656/sec)\u001b[0m\n",
            "\n",
            "\u001b[92m\u001b[1m🎉 SUCCESS!\u001b[0m\n",
            "  📊 Generated: \u001b[1m20 expressions\u001b[0m\n",
            "  📁 Saved to: \u001b[96mdatasets/ds-calcgpt_min0_max5_alldigits_add_limit20.txt\u001b[0m\n",
            "  ⏱️  Total time: \u001b[1m0.0 seconds\u001b[0m\n",
            "  🚀 Generation rate: \u001b[1m85861 expressions/second\u001b[0m\n",
            "  💾 File size: \u001b[1m120 bytes (0.1 KB)\u001b[0m\n",
            "\n",
            "\n",
            "📚 Generated dataset preview:\n",
            "Total examples: 20\n",
            "First 10 examples:\n",
            "   1. 0+0=0\n",
            "   2. 0+1=1\n",
            "   3. 0+2=2\n",
            "   4. 0+3=3\n",
            "   5. 0+4=4\n",
            "   6. 0+5=5\n",
            "   7. 1+0=1\n",
            "   8. 1+1=2\n",
            "   9. 1+2=3\n",
            "  10. 1+3=4\n",
            "  ...\n",
            "  20. 3+1=4\n",
            "\n",
            "📊 Dataset Analysis:\n",
            "  📏 Average length: 5.0 characters\n",
            "  📏 Max length: 5 characters\n",
            "  🔤 Unique characters: +01234567=\n",
            "  📈 Character count: 10 unique chars\n"
          ]
        }
      ],
      "source": [
        "# Generate a simple dataset for our first model using the CalcGPT library\n",
        "# We'll start small: numbers 0-5, only addition, limit to 20 examples\n",
        "\n",
        "print(\"🎬 Generating simple dataset with CalcGPT DatasetGenerator...\")\n",
        "\n",
        "# Create configuration for simple dataset\n",
        "simple_config = DatagenConfig(\n",
        "    max_value=5,                    # Max value: 5\n",
        "    max_expressions=20,             # Limit: 20 examples\n",
        "    operations=['addition'],        # Addition only\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Generate dataset programmatically\n",
        "generator = DatasetGenerator(simple_config)\n",
        "dataset_path = generator.generate()\n",
        "\n",
        "print(f\"✅ Dataset generated at: {dataset_path}\")\n",
        "\n",
        "# Load and analyze the generated dataset\n",
        "simple_dataset = generator.load_dataset(dataset_path)\n",
        "\n",
        "print(f\"\\n📚 Generated dataset preview:\")\n",
        "print(f\"Total examples: {len(simple_dataset)}\")\n",
        "print(\"First 10 examples:\")\n",
        "for i, example in enumerate(simple_dataset[:10]):\n",
        "    print(f\"  {i+1:2d}. {example}\")\n",
        "\n",
        "if len(simple_dataset) > 10:\n",
        "    print(\"  ...\")\n",
        "    print(f\"  {len(simple_dataset)}. {simple_dataset[-1]}\")\n",
        "\n",
        "# Analyze the dataset using our programmatic interface\n",
        "analysis = generator.analyze_dataset(simple_dataset)\n",
        "print(f\"\\n📊 Dataset Analysis:\")\n",
        "print(f\"  📏 Average length: {analysis['avg_length']:.1f} characters\")\n",
        "print(f\"  📏 Max length: {analysis['max_length']} characters\")\n",
        "print(f\"  🔤 Unique characters: {analysis['vocabulary']}\")\n",
        "print(f\"  📈 Character count: {analysis['vocab_size']} unique chars\")\n",
        "print(f\"  📊 Operations: {analysis['operations']}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🧠 Part 2: Understanding Transformer Architecture\n",
        "\n",
        "### The GPT-2 Architecture\n",
        "\n",
        "Our CalcGPT is based on **GPT-2** (Generative Pre-trained Transformer), which uses the **decoder-only** transformer architecture. Let's understand the key components:\n",
        "\n",
        "#### 🔧 Key Components\n",
        "\n",
        "1. **Token Embeddings**: Convert characters to dense vectors\n",
        "2. **Positional Embeddings**: Encode position information\n",
        "3. **Multi-Head Attention**: Learn relationships between positions\n",
        "4. **Feed-Forward Networks**: Non-linear transformations\n",
        "5. **Layer Normalization**: Stabilize training\n",
        "6. **Causal Masking**: Prevent future token access\n",
        "\n",
        "#### 📐 Model Parameters\n",
        "\n",
        "For our simple model, we'll use a tiny architecture:\n",
        "- **Embedding dimension**: 32 (vs 768 in GPT-2 small)\n",
        "- **Number of layers**: 1 (vs 12 in GPT-2 small)\n",
        "- **Attention heads**: 2 (vs 12 in GPT-2 small)\n",
        "- **Vocabulary size**: ~7 characters (`0123456789+=`)\n",
        "\n",
        "This gives us only ~38K parameters vs 117M in GPT-2 small!\n",
        "\n",
        "#### 🎯 Training Objective\n",
        "\n",
        "**Causal Language Modeling**: Given a sequence `x₁, x₂, ..., xₙ`, predict `xₙ₊₁`\n",
        "\n",
        "For `\"1+1=2\"`:\n",
        "- Input: `\"1+1=\"` → Predict: `\"2\"`\n",
        "- The model learns: `P(2|1,+,1,=)`\n",
        "\n",
        "### Why Start Small?\n",
        "\n",
        "1. **Fast iteration**: Quick training and testing\n",
        "2. **Understanding**: Easier to analyze and debug\n",
        "3. **Resource efficiency**: Runs on any hardware\n",
        "4. **Clear baselines**: Establish performance expectations\n",
        "\n",
        "Let's train our first tiny CalcGPT model!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Training tiny CalcGPT model with our professional trainer...\n",
            "STDOUT:\n",
            "\n",
            "\u001b[94m\u001b[1m\n",
            "╔═══════════════════════════════════════════════════════════════╗\n",
            "║                    CalcGPT Trainer                            ║\n",
            "║              Advanced Model Training System                   ║\n",
            "║                         v1.0.0                               ║\n",
            "╚═══════════════════════════════════════════════════════════════╝\n",
            "\u001b[0m\n",
            "\u001b[92m🍎 Apple Silicon (MPS) detected\u001b[0m\n",
            "\u001b[96m📚 Loading dataset from: datasets/ds-calcgpt_min0_max5_alldigits_add_limit20.txt\u001b[0m\n",
            "\u001b[92m✅ Loaded 20 examples from dataset\u001b[0m\n",
            "\u001b[96m📊 Dataset statistics:\u001b[0m\n",
            "   Average length: 5.0 characters\n",
            "   Maximum length: 5 characters\n",
            "   Minimum length: 5 characters\n",
            "\u001b[96m✨ Applying data augmentation (commutative property)...\u001b[0m\n",
            "\u001b[92m✅ Added 7 augmented examples\u001b[0m\n",
            "\u001b[96m📈 Total dataset size: 27 examples\u001b[0m\n",
            "\u001b[96m🔤 Creating optimized vocabulary...\u001b[0m\n",
            "\u001b[92m✅ Vocabulary created with 12 tokens\u001b[0m\n",
            "\u001b[96m🔧 Special tokens: ['<pad>', '<eos>']\u001b[0m\n",
            "\u001b[96m🔧 Character tokens: +01234567=\u001b[0m\n",
            "\u001b[96m📏 Maximum sequence length: 6\u001b[0m\n",
            "\u001b[93m⚠️ No validation split (evaluation disabled)\u001b[0m\n",
            "\n",
            "\u001b[1m🚀 Training Configuration:\u001b[0m\n",
            "============================================================\n",
            "  📚 Dataset: \u001b[96mdatasets/ds-calcgpt_min0_max5_alldigits_add_limit20.txt\u001b[0m (27 examples)\n",
            "  🎯 Device: \u001b[92mMPS\u001b[0m\n",
            "  ⚡ Mixed precision: ❌ Disabled\n",
            "  🔤 Vocabulary size: \u001b[1m12\u001b[0m\n",
            "\n",
            "  🏗️  Model Architecture:\n",
            "     📏 Embedding dimension: \u001b[1m32\u001b[0m\n",
            "     🏗️  Number of layers: \u001b[1m1\u001b[0m\n",
            "     👁️  Attention heads: \u001b[1m2\u001b[0m\n",
            "     🔧 Feedforward dimension: \u001b[1m512\u001b[0m\n",
            "\n",
            "  📖 Training Parameters:\n",
            "     🔄 Epochs: \u001b[1m3\u001b[0m\n",
            "     📦 Batch size: \u001b[1m4\u001b[0m\n",
            "     📈 Learning rate: \u001b[1m0.001\u001b[0m\n",
            "     📅 LR scheduler: \u001b[1mcosine\u001b[0m\n",
            "     🔧 Effective batch size: \u001b[1m8\u001b[0m\n",
            "  📁 Model output: \u001b[96mmodels/calcgpt_emb32_lay1_head2_ep3_bs4_lr1e03_ds20\u001b[0m\n",
            "\n",
            "\u001b[96m🏗️ Creating model architecture...\u001b[0m\n",
            "\u001b[92m✅ Model configuration created:\u001b[0m\n",
            "   📏 Sequence length: 16\n",
            "   🧠 Embedding dimension: 32\n",
            "   🏗️  Number of layers: 1\n",
            "   👁️  Attention heads: 2\n",
            "   🔧 Feedforward dimension: 512\n",
            "\u001b[96m🧠 Model Information:\u001b[0m\n",
            "   📊 Total parameters: \u001b[1m38,624\u001b[0m\n",
            "   🎯 Trainable parameters: \u001b[1m38,624\u001b[0m\n",
            "   💾 Model size: \u001b[1m0.1 MB\u001b[0m\n",
            "\u001b[96m🔧 Creating training dataset with 27 examples...\u001b[0m\n",
            "\u001b[92m✅ training dataset ready with 27 pre-tokenized sequences\u001b[0m\n",
            "\u001b[96m⚙️ Training arguments configured\u001b[0m\n",
            "\n",
            "\u001b[92m\u001b[1m🚀 STARTING TRAINING\u001b[0m\n",
            "============================================================\n",
            "{'loss': 2.041, 'grad_norm': 1.9834450483322144, 'learning_rate': 0.00017999999999999998, 'epoch': 2.57}\n",
            "{'train_runtime': 2.4217, 'train_samples_per_second': 33.448, 'train_steps_per_second': 4.955, 'train_loss': 2.0233030319213867, 'epoch': 3.0}\n",
            "\n",
            "\u001b[92m\u001b[1m✅ TRAINING COMPLETED\u001b[0m\n",
            "============================================================\n",
            "  📊 Final training loss: \u001b[1m2.0233\u001b[0m\n",
            "  ⏱️  Training time: \u001b[1m0.0 minutes\u001b[0m\n",
            "\n",
            "\u001b[96m🧪 Testing trained model...\u001b[0m\n",
            "\n",
            "\u001b[96m🧪 Testing model inference...\u001b[0m\n",
            "\n",
            "\u001b[96m🔍 Test 1/9: '1+1='\u001b[0m\n",
            "   Generated: '1+1==========='\n",
            "   New part: '=========='\n",
            "   \u001b[93m❌ Expected 2, got \u001b[0m\n",
            "\n",
            "\u001b[96m🔍 Test 2/9: '2+0='\u001b[0m\n",
            "   Generated: '2+0==========='\n",
            "   New part: '=========='\n",
            "   \u001b[93m❌ Expected 2, got \u001b[0m\n",
            "\n",
            "\u001b[96m🔍 Test 3/9: '0+2='\u001b[0m\n",
            "   Generated: '0+2==========='\n",
            "   New part: '=========='\n",
            "   \u001b[93m❌ Expected 2, got \u001b[0m\n",
            "\n",
            "\u001b[96m🔍 Test 4/9: '10+1='\u001b[0m\n",
            "   Generated: '10+1==========='\n",
            "   New part: '=========='\n",
            "   \u001b[93m❌ Expected 11, got \u001b[0m\n",
            "\n",
            "\u001b[96m🔍 Test 5/9: '11+1='\u001b[0m\n",
            "   Generated: '11+1==========='\n",
            "   New part: '=========='\n",
            "   \u001b[93m❌ Expected 12, got \u001b[0m\n",
            "\n",
            "\u001b[96m🔍 Test 6/9: '100+10='\u001b[0m\n",
            "   Generated: '100+10==========='\n",
            "   New part: '=========='\n",
            "   \u001b[93m❌ Expected 110, got \u001b[0m\n",
            "\n",
            "\u001b[96m🔍 Test 7/9: '22+100='\u001b[0m\n",
            "   Generated: '22+100==========='\n",
            "   New part: '=========='\n",
            "   \u001b[93m❌ Expected 122, got \u001b[0m\n",
            "\n",
            "\u001b[96m🔍 Test 8/9: '12+10='\u001b[0m\n",
            "   Generated: '12+10==========='\n",
            "   New part: '=========='\n",
            "   \u001b[93m❌ Expected 22, got \u001b[0m\n",
            "\n",
            "\u001b[96m🔍 Test 9/9: '5+5='\u001b[0m\n",
            "   Generated: '5+5==========='\n",
            "   New part: '=========='\n",
            "   \u001b[93m❌ Expected 10, got \u001b[0m\n",
            "\n",
            "\u001b[92m\u001b[1m🎉 TRAINING COMPLETE!\u001b[0m\n",
            "============================================================\n",
            "  📊 Model accuracy: \u001b[1m0/9 (0.0%)\u001b[0m\n",
            "  📁 Model saved to: \u001b[96mmodels/calcgpt_emb32_lay1_head2_ep3_bs4_lr1e03_ds20\u001b[0m\n",
            "  ⏱️  Total time: \u001b[1m0.0 minutes\u001b[0m\n",
            "\n",
            "\u001b[96m📝 Auto-generated Model Name:\u001b[0m\n",
            "  \u001b[1mcalcgpt_emb32_lay1_head2_ep3_bs4_lr1e03_ds20\u001b[0m\n",
            "  💡 Encodes: architecture + training params + dataset\n",
            "\n",
            "\u001b[96m🏆 Training Achievements:\u001b[0m\n",
            "  ✅ Data augmentation applied\n",
            "  ✅ Optimized model architecture\n",
            "  ✅ Advanced training configuration\n",
            "  ✅ Comprehensive evaluation\n",
            "  ✅ Inference testing completed\n",
            "  ✅ Intelligent model naming system\n",
            "\n",
            "STDERR:\n",
            "\n",
            "  0%|          | 0/12 [00:00<?, ?it/s]/Users/mihai/Coding/jupyter/transformers/.venv/lib/python3.13/site-packages/torch/utils/data/dataloader.py:683: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
            "\n",
            "  8%|▊         | 1/12 [00:01<00:17,  1.61s/it]\n",
            " 33%|███▎      | 4/12 [00:02<00:03,  2.19it/s]\n",
            " 67%|██████▋   | 8/12 [00:02<00:00,  5.12it/s]\n",
            "                                              \n",
            "\n",
            " 83%|████████▎ | 10/12 [00:02<00:00,  5.12it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  8.54it/s]\n",
            "                                               \n",
            "\n",
            "100%|██████████| 12/12 [00:02<00:00,  8.54it/s]\n",
            "100%|██████████| 12/12 [00:02<00:00,  4.98it/s]\n",
            "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (16). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n",
            "\n",
            "\n",
            "⏱️ Training completed in 8.1 seconds\n",
            "🎯 Model saved as: calcgpt_emb32_lay1_head2_ep3_bs4_lr1e03_ds20\n",
            "📝 Filename breakdown:\n",
            "   • emb32: 32-dimensional embeddings\n",
            "   • lay1: 1 transformer layer\n",
            "   • head2: 2 attention heads\n",
            "   • ep3: 3 training epochs\n",
            "   • bs4: batch size 4\n",
            "   • lr1e3: learning rate 1e-3\n",
            "   • ds20: dataset with 20 examples\n"
          ]
        }
      ],
      "source": [
        "# Train our first tiny CalcGPT model using the library\n",
        "print(\"🚀 Training tiny CalcGPT model with CalcGPTTrainer...\")\n",
        "\n",
        "# Create training configuration for tiny model\n",
        "tiny_config = TrainingConfig(\n",
        "    epochs=3,               # Quick training\n",
        "    batch_size=4,           # Small batches  \n",
        "    learning_rate=1e-3,     # Default learning rate\n",
        "    embedding_dim=32,       # Small embedding\n",
        "    num_layers=1,           # Single layer\n",
        "    num_heads=2,            # Two attention heads\n",
        "    test_split=0.0,         # No validation for simplicity\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Train the model programmatically\n",
        "training_start = time.time()\n",
        "\n",
        "trainer = CalcGPTTrainer(\n",
        "    config=tiny_config,\n",
        "    dataset_path=dataset_path,  # Use our generated dataset\n",
        "    output_dir=Path('models/tiny_calcgpt'),\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Train and get results\n",
        "results = trainer.train()\n",
        "training_time = time.time() - training_start\n",
        "\n",
        "print(f\"\\n✅ Training completed in {training_time:.1f} seconds\")\n",
        "\n",
        "# Display training results\n",
        "print(f\"\\n📊 Training Results:\")\n",
        "print(f\"  📈 Final loss: {results['training_loss']:.4f}\")\n",
        "print(f\"  ⏱️  Training time: {results['training_time']/60:.2f} minutes\")\n",
        "print(f\"  🧠 Model parameters: {results['model_params']:,}\")\n",
        "print(f\"  📚 Dataset size: {results['dataset_size']:,} examples\")\n",
        "print(f\"  🔤 Vocabulary size: {results['vocab_size']} tokens\")\n",
        "\n",
        "print(f\"\\n🧪 Quick Test Results:\")\n",
        "for prompt, result in results['test_results'].items():\n",
        "    print(f\"  {prompt} → {result}\")\n",
        "\n",
        "print(f\"\\n📁 Model saved to: {trainer.output_dir}\")\n",
        "\n",
        "# Store the model path for later use\n",
        "tiny_model_path = trainer.output_dir\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 📊 Part 3: Model Evaluation and Analysis\n",
        "\n",
        "### Comprehensive Evaluation Strategy\n",
        "\n",
        "Now let's evaluate our tiny model using CalcGPT Eval. This tool provides comprehensive assessment across multiple dimensions:\n",
        "\n",
        "#### 🧪 Test Types\n",
        "1. **First Operand**: Given `\"1\"`, can it complete to `\"1+0=1\"`?\n",
        "2. **Expression Complete**: Given `\"1+1\"`, can it add `\"=2\"`?\n",
        "3. **Answer Complete**: Given `\"1+1=\"`, can it predict `\"2\"`?\n",
        "\n",
        "#### 📏 Metrics\n",
        "- **Format Validity**: Does output follow `num+num=num` pattern?\n",
        "- **Arithmetic Correctness**: Is the math actually correct?\n",
        "- **Completion Success**: Does the model generate complete expressions?\n",
        "- **Performance Timing**: How fast is inference?\n",
        "\n",
        "Let's see how our tiny model performs!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📊 Evaluating tiny CalcGPT model...\n",
            "STDOUT:\n",
            "\n",
            "\u001b[94m\u001b[1m\n",
            "╔═══════════════════════════════════════════════════════════════╗\n",
            "║                        CalcGPT Eval                          ║\n",
            "║                   Model Evaluation Tool                      ║\n",
            "║                         v1.0.0                               ║\n",
            "╚═══════════════════════════════════════════════════════════════╝\n",
            "\u001b[0m\n",
            "\u001b[92m🎯 Auto-detected model: \u001b[96mcalcgpt_emb32_lay1_head2_ep3_bs4_lr1e03_ds20\u001b[0m\n",
            "\u001b[96mInitializing CalcGPT evaluator...\u001b[0m\n",
            "\u001b[96mLoading model from: models/calcgpt_emb32_lay1_head2_ep3_bs4_lr1e03_ds20\u001b[0m\n",
            "\u001b[93mUsing checkpoint: models/calcgpt_emb32_lay1_head2_ep3_bs4_lr1e03_ds20/checkpoint-12\u001b[0m\n",
            "\u001b[92m✅ Model loaded successfully!\n",
            "   Parameters: 38,624\n",
            "   Device: mps\u001b[0m\n",
            "\u001b[92m✅ Vocabulary loaded:\n",
            "   Vocab size: 7\n",
            "   Max length: 15\n",
            "   Vocabulary: {'<pad>': 0, '<eos>': 1, '+': 2, '0': 3, '1': 4, '2': 5, '=': 6}\u001b[0m\n",
            "\u001b[96mLoading evaluation dataset: datasets/ds-calcgpt_min0_max5_alldigits_add_limit20.txt\u001b[0m\n",
            "\u001b[92m✅ Loaded 20 equations from dataset\u001b[0m\n",
            "\u001b[92m✅ Generated 60 test cases\u001b[0m\n",
            "\u001b[93m📝 Using random sample of 30 test cases\u001b[0m\n",
            "\n",
            "\u001b[92m🧪 Running evaluation on 30 test cases\u001b[0m\n",
            "❌ '1' → '' [first_operand]\n",
            "❌ '0+2' → '' [expression_complete]\n",
            "❌ '1+2' → '' [expression_complete]\n",
            "❌ '3+1=' → '' [answer_complete]\n",
            "❌ '1+4=' → '' [answer_complete]\n",
            "❌ '1+1=' → '1+1==' [answer_complete]\n",
            "❌ '0+5' → '' [expression_complete]\n",
            "❌ '2' → '' [first_operand]\n",
            "❌ '2+0' → '' [expression_complete]\n",
            "❌ '0+0=' → '0+0==' [answer_complete]\n",
            "❌ '2+1' → '' [expression_complete]\n",
            "❌ '1' → '' [first_operand]\n",
            "❌ '2+5' → '' [expression_complete]\n",
            "❌ '0+1' → '' [expression_complete]\n",
            "❌ '1+3' → '' [expression_complete]\n",
            "❌ '3' → '' [first_operand]\n",
            "❌ '1+3=' → '' [answer_complete]\n",
            "❌ '0' → '' [first_operand]\n",
            "❌ '0' → '' [first_operand]\n",
            "❌ '1' → '' [first_operand]\n",
            "❌ '2+2=' → '2+2==' [answer_complete]\n",
            "❌ '1+4' → '' [expression_complete]\n",
            "❌ '1+5=' → '' [answer_complete]\n",
            "❌ '1+5' → '' [expression_complete]\n",
            "❌ '2+2' → '' [expression_complete]\n",
            "❌ '2+1=' → '2+1==' [answer_complete]\n",
            "❌ '2' → '' [first_operand]\n",
            "❌ '0' → '' [first_operand]\n",
            "❌ '0' → '' [first_operand]\n",
            "❌ '2' → '' [first_operand]\n",
            "\n",
            "\u001b[1m📊 EVALUATION RESULTS\u001b[0m\n",
            "============================================================\n",
            "\n",
            "\u001b[96mOverall Performance:\u001b[0m\n",
            "  Total test cases: 30\n",
            "  Successful completions: 4 (13.3%)\n",
            "  Valid format: 0 (0.0%)\n",
            "  Correct arithmetic: \u001b[92m0\u001b[0m (\u001b[92m0.0%\u001b[0m)\n",
            "  Complete expressions: 0 (0.0%)\n",
            "  Exact matches: 0 (0.0%)\n",
            "\n",
            "\u001b[96mPerformance by Test Type:\u001b[0m\n",
            "  First Operand:\n",
            "    Arithmetic accuracy: 0/11 (0.0%)\n",
            "    Format accuracy: 0/11 (0.0%)\n",
            "  Expression Complete:\n",
            "    Arithmetic accuracy: 0/11 (0.0%)\n",
            "    Format accuracy: 0/11 (0.0%)\n",
            "  Answer Complete:\n",
            "    Arithmetic accuracy: 0/8 (0.0%)\n",
            "    Format accuracy: 0/8 (0.0%)\n",
            "\n",
            "\u001b[96mPerformance Timing:\u001b[0m\n",
            "  Mean: 19.2ms\n",
            "  Median: 13.3ms\n",
            "  Range: 11.5ms - 38.6ms\n",
            "  Std Dev: 13.0ms\n",
            "\n",
            "\u001b[93m⚠️ Low accuracy detected - consider additional training\u001b[0m\n",
            "\n",
            "\n",
            "============================================================\n",
            "🔍 MANUAL INFERENCE ANALYSIS\n",
            "============================================================\n",
            "1+1= → 283.5 (expected: 2) ❌\n",
            "2+0= → 787.7 (expected: 2) ❌\n",
            "0+2= → 364.3 (expected: 2) ❌\n"
          ]
        }
      ],
      "source": [
        "# Evaluate our tiny model using the library\n",
        "print(\"📊 Evaluating tiny CalcGPT model...\")\n",
        "\n",
        "# Create evaluation configuration\n",
        "eval_config = EvaluationConfig(\n",
        "    sample_size=30,          # Test on 30 cases\n",
        "    max_tokens=10,           # Allow up to 10 tokens for completion\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Initialize evaluator with our trained model\n",
        "evaluator = CalcGPTEvaluator(\n",
        "    config=eval_config,\n",
        "    model_path=tiny_model_path,  # Use our trained model\n",
        "    dataset_path=dataset_path,   # Same dataset we trained on\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Run comprehensive evaluation\n",
        "eval_results = evaluator.evaluate()\n",
        "\n",
        "# Display evaluation results\n",
        "print(f\"\\n📊 Evaluation Results:\")\n",
        "print(f\"  🎯 Overall accuracy: {eval_results['accuracy_stats']['overall']:.1%}\")\n",
        "print(f\"  ✅ Format validity: {eval_results['accuracy_stats']['format']:.1%}\")\n",
        "print(f\"  🧮 Arithmetic correctness: {eval_results['accuracy_stats']['arithmetic']:.1%}\")\n",
        "print(f\"  📝 Complete expressions: {eval_results['accuracy_stats']['complete']:.1%}\")\n",
        "\n",
        "print(f\"\\n📈 Performance by Test Type:\")\n",
        "for test_type, stats in eval_results['test_type_stats'].items():\n",
        "    print(f\"  {test_type.replace('_', ' ').title()}:\")\n",
        "    print(f\"    Arithmetic: {stats['arithmetic']:.1%}\")\n",
        "    print(f\"    Format: {stats['format']:.1%}\")\n",
        "\n",
        "print(f\"\\n⏱️ Performance Timing:\")\n",
        "timing = eval_results['timing_stats']\n",
        "print(f\"  Mean: {timing['mean']:.1f}ms\")\n",
        "print(f\"  Median: {timing['median']:.1f}ms\")\n",
        "print(f\"  Range: {timing['min']:.1f}ms - {timing['max']:.1f}ms\")\n",
        "\n",
        "# Also try some manual inference using the CalcGPT class for comparison\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🔍 PROGRAMMATIC INFERENCE ANALYSIS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Initialize inference model\n",
        "inference_config = InferenceConfig(\n",
        "    temperature=0.0,  # Deterministic inference\n",
        "    max_tokens=10,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "calc_model = CalcGPT(\n",
        "    config=inference_config,\n",
        "    model_path=tiny_model_path,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "# Test problems\n",
        "test_problems = [\"1+1=\", \"2+0=\", \"0+2=\", \"3+1=\", \"2+2=\"]\n",
        "\n",
        "print(\"Problem     → Predicted  (Expected)  Status\")\n",
        "print(\"-\" * 45)\n",
        "\n",
        "for problem in test_problems:\n",
        "    try:\n",
        "        result = calc_model.generate(problem)\n",
        "        predicted = result['completion'].strip()\n",
        "        \n",
        "        # Extract operands and calculate expected\n",
        "        expr = problem.replace('=', '')\n",
        "        if '+' in expr:\n",
        "            operands = expr.split('+')\n",
        "            expected = int(operands[0]) + int(operands[1])\n",
        "        else:\n",
        "            expected = \"?\"\n",
        "        \n",
        "        # Check if prediction matches expected\n",
        "        is_correct = str(predicted) == str(expected)\n",
        "        status = \"✅\" if is_correct else \"❌\"\n",
        "        \n",
        "        print(f\"{problem:10s} → {predicted:9s}  ({expected:8s})  {status}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"{problem:10s} → ERROR     (?)        ❌\")\n",
        "\n",
        "print(f\"\\n💡 The tiny model shows the learning process - it's beginning to understand\")\n",
        "print(f\"   the task structure but needs more capacity and training for accuracy!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🎯 Part 4: Scaling Up - Production-Ready CalcGPT\n",
        "\n",
        "### What We Learned from Our Tiny Model\n",
        "\n",
        "Our 38K parameter model taught us valuable lessons:\n",
        "\n",
        "1. **Architecture Matters**: Even tiny transformers can learn patterns\n",
        "2. **Data Quality > Quantity**: Small, clean datasets can be effective\n",
        "3. **Evaluation is Critical**: Multiple test types reveal different capabilities\n",
        "4. **Training Dynamics**: Fast convergence on simple problems\n",
        "\n",
        "### Limitations of the Tiny Model\n",
        "\n",
        "- **Limited Capacity**: Can't handle complex arithmetic\n",
        "- **Poor Generalization**: Struggles with unseen number combinations\n",
        "- **Format Issues**: May not always produce valid expressions\n",
        "- **Narrow Range**: Only works within training data distribution\n",
        "\n",
        "### Scaling Strategy\n",
        "\n",
        "Now let's build a **production-ready** CalcGPT with:\n",
        "\n",
        "#### 📈 Larger Dataset\n",
        "- **Range**: Numbers 0-100 (vs 0-5)\n",
        "- **Operations**: Both addition and subtraction\n",
        "- **Size**: ~10,000+ examples (vs 20)\n",
        "- **Augmentation**: Commutative examples included\n",
        "\n",
        "#### 🏗️ Bigger Architecture\n",
        "- **Embedding Dimension**: 128 (vs 32)\n",
        "- **Layers**: 6 (vs 1) \n",
        "- **Attention Heads**: 8 (vs 2)\n",
        "- **Parameters**: ~1.2M (vs 38K)\n",
        "\n",
        "#### ⚡ Advanced Training\n",
        "- **Validation Split**: Proper train/test separation\n",
        "- **Learning Rate Scheduling**: Cosine annealing\n",
        "- **Early Stopping**: Based on validation loss\n",
        "- **Mixed Precision**: Faster training where available\n",
        "\n",
        "Let's build the real deal! 🚀\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🎬 Generating comprehensive dataset for production model...\n",
            "STDOUT:\n",
            "\n",
            "\u001b[94m\u001b[1m\n",
            "╔═══════════════════════════════════════════════════════════════╗\n",
            "║                    CalcGPT DataGen                            ║\n",
            "║                 Dataset Generation Tool                      ║\n",
            "║                         v1.0.0                               ║\n",
            "╚═══════════════════════════════════════════════════════════════╝\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m🚀 Generation Configuration:\u001b[0m\n",
            "==================================================\n",
            "  🎯 Value range: \u001b[1m0 - 100\u001b[0m\n",
            "  🔢 Allowed digits: \u001b[92mAll digits (0-9)\u001b[0m\n",
            "  🧮 Operations: \u001b[92m➕ addition and ➖ subtraction\u001b[0m\n",
            "  📏 Expression limit: \u001b[92mUnlimited\u001b[0m\n",
            "  📁 Output file: \u001b[96mdatasets/ds-calcgpt_min0_max100_alldigits_allops.txt\u001b[0m\n",
            "\n",
            "\u001b[92m🎬 Starting expression generation...\u001b[0m\n",
            "\u001b[96m📝 Writing expressions to: datasets/ds-calcgpt_min0_max100_alldigits_allops.txt\u001b[0m\n",
            "\u001b[96m🧮 Generating arithmetic expressions...\u001b[0m\n",
            "\u001b[96m🔢 Generating valid numbers up to 100...\u001b[0m\n",
            "\u001b[92m✅ Generated 101 numbers (all digits allowed)\u001b[0m\n",
            "\u001b[96m🔧 Operations to include: addition, subtraction\u001b[0m\n",
            "\u001b[96m📊 Estimated expressions to generate: ~15,301\u001b[0m\n",
            "\u001b[96m   Generated 1,000 expressions...\u001b[0m\n",
            "\u001b[96m   Generated 4,000 expressions...\u001b[0m\n",
            "\u001b[96m   Written 5,000 expressions (2240068/sec)...\u001b[0m\n",
            "\u001b[96m   Generated 5,000 expressions...\u001b[0m\n",
            "\u001b[96m   Generated 6,000 expressions...\u001b[0m\n",
            "\u001b[96m   Generated 8,000 expressions...\u001b[0m\n",
            "\u001b[96m   Written 10,000 expressions (2357808/sec)...\u001b[0m\n",
            "\u001b[96m   Generated 10,000 expressions...\u001b[0m\n",
            "\u001b[96m   Generated 13,000 expressions...\u001b[0m\n",
            "\u001b[96m   Written 15,000 expressions (2343012/sec)...\u001b[0m\n",
            "\u001b[92m✅ Successfully wrote 15,352 expressions in 0.0s (2315139/sec)\u001b[0m\n",
            "\n",
            "\u001b[92m\u001b[1m🎉 SUCCESS!\u001b[0m\n",
            "  📊 Generated: \u001b[1m15,352 expressions\u001b[0m\n",
            "  📁 Saved to: \u001b[96mdatasets/ds-calcgpt_min0_max100_alldigits_allops.txt\u001b[0m\n",
            "  ⏱️  Total time: \u001b[1m0.0 seconds\u001b[0m\n",
            "  🚀 Generation rate: \u001b[1m2305771 expressions/second\u001b[0m\n",
            "  💾 File size: \u001b[1m139,564 bytes (136.3 KB)\u001b[0m\n",
            "\n",
            "\n",
            "⏱️ Dataset generation completed in 0.0 seconds\n",
            "\n",
            "📚 Production Dataset Analysis:\n",
            "  📁 File: ds-calcgpt_min0_max100_alldigits_allops.txt\n",
            "  📊 Total examples: 15,352\n",
            "  📏 Average length: 8.1 characters\n",
            "  📏 Max length: 11 characters\n",
            "  🔤 Vocabulary size: 13 characters\n",
            "  💾 File size: 136.3 KB\n",
            "\n",
            "📋 Sample expressions:\n",
            "  0+0=0\n",
            "  32+45=77\n",
            "  58-53=5\n",
            "  100-100=0\n",
            "\n",
            "📊 Operation distribution:\n",
            "  ➕ Addition: 10,201 (66.4%)\n",
            "  ➖ Subtraction: 5,151 (33.6%)\n",
            "\n",
            "🎯 Ready for production training with: ds-calcgpt_min0_max100_alldigits_allops.txt\n"
          ]
        }
      ],
      "source": [
        "# Generate a comprehensive dataset for production CalcGPT using the library\n",
        "print(\"🎬 Generating comprehensive dataset for production model...\")\n",
        "\n",
        "# Create configuration for production dataset\n",
        "production_config = DatagenConfig(\n",
        "    max_value=100,               # Max value: 100 (much larger!)\n",
        "    operations=['addition', 'subtraction'],  # Both operations\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Generate dataset programmatically\n",
        "generation_start = time.time()\n",
        "production_generator = DatasetGenerator(production_config)\n",
        "production_dataset_path = production_generator.generate()\n",
        "generation_time = time.time() - generation_start\n",
        "\n",
        "print(f\"✅ Production dataset generated at: {production_dataset_path}\")\n",
        "print(f\"⏱️ Dataset generation completed in {generation_time:.1f} seconds\")\n",
        "\n",
        "# Load and analyze the comprehensive dataset\n",
        "full_dataset = production_generator.load_dataset(production_dataset_path)\n",
        "analysis = production_generator.analyze_dataset(full_dataset)\n",
        "\n",
        "print(f\"\\n📚 Production Dataset Analysis:\")\n",
        "print(f\"  📁 File: {Path(production_dataset_path).name}\")\n",
        "print(f\"  📊 Total examples: {len(full_dataset):,}\")\n",
        "print(f\"  📏 Average length: {analysis['avg_length']:.1f} characters\")\n",
        "print(f\"  📏 Max length: {analysis['max_length']} characters\")\n",
        "print(f\"  🔤 Vocabulary size: {analysis['vocab_size']} characters\")\n",
        "print(f\"  💾 File size: {Path(production_dataset_path).stat().st_size / 1024:.1f} KB\")\n",
        "\n",
        "# Show some examples from different ranges\n",
        "print(f\"\\n📋 Sample expressions:\")\n",
        "examples_to_show = [0, len(full_dataset)//4, len(full_dataset)//2, -1]\n",
        "for i in examples_to_show:\n",
        "    if i < len(full_dataset):\n",
        "        print(f\"  {full_dataset[i]}\")\n",
        "\n",
        "# Analyze the distribution of operations using our analysis\n",
        "print(f\"\\n📊 Operation distribution:\")\n",
        "for op, count in analysis['operations'].items():\n",
        "    percentage = count / len(full_dataset) * 100\n",
        "    op_symbol = \"➕\" if op == \"addition\" else \"➖\"\n",
        "    print(f\"  {op_symbol} {op.title()}: {count:,} ({percentage:.1f}%)\")\n",
        "\n",
        "print(f\"\\n🎯 Ready for production training with: {Path(production_dataset_path).name}\")\n",
        "\n",
        "# Store the dataset path for training\n",
        "production_dataset = production_dataset_path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 Training production CalcGPT model...\n",
            "⚠️ This will take longer but results in much better performance!\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m production_training_start = time.time()\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Use the intelligent trainer with production settings\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m result = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpython\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcalcgpt_train.py\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m-d\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproduction_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Our comprehensive dataset\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--embedding-dim\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m128\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m      \u001b[49m\u001b[38;5;66;43;03m# Larger embeddings\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--num-layers\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m6\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Deeper network\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--num-heads\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# More attention heads\u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--epochs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m20\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m              \u001b[49m\u001b[38;5;66;43;03m# More training\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--batch-size\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m8\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Reasonable batch size\u001b[39;49;00m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--learning-rate\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m1e-3\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Default learning rate\u001b[39;49;00m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--eval-steps\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m100\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# Regular evaluation\u001b[39;49;00m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--save-steps\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m500\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m         \u001b[49m\u001b[38;5;66;43;03m# Save checkpoints\u001b[39;49;00m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m--verbose\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# Monitor progress\u001b[39;49;00m\n\u001b[32m     21\u001b[39m \u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcapture_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     23\u001b[39m production_training_time = time.time() - production_training_start\n\u001b[32m     25\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSTDOUT:\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.4/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py:556\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    554\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m         stdout, stderr = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    557\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    558\u001b[39m         process.kill()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.4/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py:1222\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1219\u001b[39m     endtime = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1221\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1222\u001b[39m     stdout, stderr = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1223\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1224\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1225\u001b[39m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[32m   1226\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.4/Frameworks/Python.framework/Versions/3.13/lib/python3.13/subprocess.py:2128\u001b[39m, in \u001b[36mPopen._communicate\u001b[39m\u001b[34m(self, input, endtime, orig_timeout)\u001b[39m\n\u001b[32m   2121\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout,\n\u001b[32m   2122\u001b[39m                         stdout, stderr,\n\u001b[32m   2123\u001b[39m                         skip_check_and_raise=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   2124\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[32m   2125\u001b[39m         \u001b[33m'\u001b[39m\u001b[33m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   2126\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mfailed to raise TimeoutExpired.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2128\u001b[39m ready = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2129\u001b[39m \u001b[38;5;28mself\u001b[39m._check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[32m   2131\u001b[39m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[32m   2132\u001b[39m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m/opt/homebrew/Cellar/python@3.13/3.13.4/Frameworks/Python.framework/Versions/3.13/lib/python3.13/selectors.py:398\u001b[39m, in \u001b[36m_PollLikeSelector.select\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    396\u001b[39m ready = []\n\u001b[32m    397\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m398\u001b[39m     fd_event_list = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_selector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "# Train the production CalcGPT model using the library\n",
        "print(\"🚀 Training production CalcGPT model...\")\n",
        "print(\"⚠️ This will take longer but results in much better performance!\")\n",
        "\n",
        "# Create production training configuration\n",
        "production_config = TrainingConfig(\n",
        "    epochs=20,              # More training\n",
        "    batch_size=8,           # Reasonable batch size\n",
        "    learning_rate=1e-3,     # Default learning rate\n",
        "    embedding_dim=128,      # Larger embeddings\n",
        "    num_layers=6,           # Deeper network\n",
        "    num_heads=8,            # More attention heads\n",
        "    test_split=0.2,         # Proper validation split\n",
        "    save_steps=500,         # Save checkpoints\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Train the production model programmatically\n",
        "production_training_start = time.time()\n",
        "\n",
        "production_trainer = CalcGPTTrainer(\n",
        "    config=production_config,\n",
        "    dataset_path=production_dataset,    # Our comprehensive dataset\n",
        "    output_dir=Path('models/production_calcgpt'),\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Train and get results (this will take several minutes)\n",
        "production_results = production_trainer.train()\n",
        "production_training_time = time.time() - production_training_start\n",
        "\n",
        "print(f\"\\n✅ Production training completed in {production_training_time/60:.1f} minutes\")\n",
        "\n",
        "# Display comprehensive training results\n",
        "print(f\"\\n📊 Production Training Results:\")\n",
        "print(f\"  📈 Final training loss: {production_results['training_loss']:.4f}\")\n",
        "if production_results['eval_loss']:\n",
        "    print(f\"  📉 Validation loss: {production_results['eval_loss']:.4f}\")\n",
        "print(f\"  ⏱️  Training time: {production_results['training_time']/60:.1f} minutes\")\n",
        "print(f\"  🧠 Model parameters: {production_results['model_params']:,}\")\n",
        "print(f\"  📚 Dataset size: {production_results['dataset_size']:,} examples\")\n",
        "print(f\"  🔤 Vocabulary size: {production_results['vocab_size']} tokens\")\n",
        "\n",
        "print(f\"\\n🧪 Production Test Results:\")\n",
        "for prompt, result in production_results['test_results'].items():\n",
        "    print(f\"  {prompt} → {result}\")\n",
        "\n",
        "# Analyze model size\n",
        "model_files = list(production_trainer.output_dir.rglob('*.bin'))\n",
        "if model_files:\n",
        "    total_size = sum(f.stat().st_size for f in model_files)\n",
        "    print(f\"\\n💾 Model size: {total_size / 1024 / 1024:.1f} MB\")\n",
        "\n",
        "print(f\"\\n📝 Architecture comparison:\")\n",
        "print(f\"  Tiny model:       {results['model_params']:,} parameters,   32 dim,  1 layer,  2 heads\")\n",
        "print(f\"  Production model: {production_results['model_params']:,} parameters, 128 dim, 6 layers, 8 heads\")\n",
        "improvement = production_results['model_params'] / results['model_params']\n",
        "print(f\"  Improvement:      {improvement:.0f}x more parameters!\")\n",
        "\n",
        "print(f\"\\n📁 Production model saved to: {production_trainer.output_dir}\")\n",
        "\n",
        "# Store the production model path for later use\n",
        "production_model_path = production_trainer.output_dir\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🎉 Part 5: Production Model Evaluation\n",
        "\n",
        "### Comprehensive Testing\n",
        "\n",
        "Now let's evaluate our production model and compare it to the tiny model. We expect to see dramatic improvements across all metrics.\n",
        "\n",
        "#### What to Look For\n",
        "\n",
        "1. **Higher Accuracy**: Better arithmetic correctness\n",
        "2. **Better Generalization**: Performance on unseen number combinations  \n",
        "3. **Format Consistency**: More reliable expression formatting\n",
        "4. **Faster Convergence**: Stable performance across test types\n",
        "\n",
        "Let's run the comprehensive evaluation suite!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Comprehensive evaluation of production CalcGPT using the library\n",
        "print(\"📊 Evaluating production CalcGPT model...\")\n",
        "print(\"🎯 This will test the model on diverse arithmetic problems\")\n",
        "\n",
        "# Create comprehensive evaluation configuration\n",
        "production_eval_config = EvaluationConfig(\n",
        "    sample_size=200,         # Test on 200 random cases\n",
        "    max_tokens=15,           # Allow more tokens for complex expressions\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Run comprehensive evaluation\n",
        "eval_start = time.time()\n",
        "\n",
        "production_evaluator = CalcGPTEvaluator(\n",
        "    config=production_eval_config,\n",
        "    model_path=production_model_path,      # Use our production model\n",
        "    dataset_path=production_dataset,       # Use production dataset\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "production_eval_results = production_evaluator.evaluate()\n",
        "eval_time = time.time() - eval_start\n",
        "\n",
        "print(f\"\\n📊 Production Evaluation Results:\")\n",
        "print(f\"  🎯 Overall accuracy: {production_eval_results['accuracy_stats']['overall']:.1%}\")\n",
        "print(f\"  ✅ Format validity: {production_eval_results['accuracy_stats']['format']:.1%}\")\n",
        "print(f\"  🧮 Arithmetic correctness: {production_eval_results['accuracy_stats']['arithmetic']:.1%}\")\n",
        "print(f\"  📝 Complete expressions: {production_eval_results['accuracy_stats']['complete']:.1%}\")\n",
        "\n",
        "print(f\"\\n📈 Performance by Test Type:\")\n",
        "for test_type, stats in production_eval_results['test_type_stats'].items():\n",
        "    print(f\"  {test_type.replace('_', ' ').title()}:\")\n",
        "    print(f\"    Arithmetic: {stats['arithmetic']:.1%}\")\n",
        "    print(f\"    Format: {stats['format']:.1%}\")\n",
        "\n",
        "print(f\"\\n⏱️ Performance Timing:\")\n",
        "timing = production_eval_results['timing_stats']\n",
        "print(f\"  Mean: {timing['mean']:.1f}ms\")\n",
        "print(f\"  Median: {timing['median']:.1f}ms\")\n",
        "print(f\"  Range: {timing['min']:.1f}ms - {timing['max']:.1f}ms\")\n",
        "\n",
        "print(f\"\\n⏱️ Evaluation completed in {eval_time:.1f} seconds\")\n",
        "\n",
        "# Test on specific challenging problems using programmatic interface\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"🧠 CHALLENGING ARITHMETIC TESTS\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Initialize production inference model\n",
        "production_inference_config = InferenceConfig(\n",
        "    temperature=0.0,         # Deterministic inference\n",
        "    max_tokens=15,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "production_calc_model = CalcGPT(\n",
        "    config=production_inference_config,\n",
        "    model_path=production_model_path,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "challenging_problems = [\n",
        "    \"99+1\",      # Near boundary\n",
        "    \"100-50\",    # Large subtraction  \n",
        "    \"50+50\",     # Equal operands\n",
        "    \"0+100\",     # Edge cases\n",
        "    \"100-100\",   # Zero result\n",
        "    \"85+15\",     # Carry operations\n",
        "    \"73-28\",     # Complex subtraction\n",
        "    \"42+37\",     # Mid-range addition\n",
        "]\n",
        "\n",
        "print(\"Testing production model on challenging problems:\")\n",
        "print(\"Problem       → Answer   (Expected)  Status\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "correct_count = 0\n",
        "for problem in challenging_problems:\n",
        "    try:\n",
        "        result = production_calc_model.generate(problem + \"=\")\n",
        "        predicted_answer = result['completion'].strip()\n",
        "        \n",
        "        # Calculate expected answer\n",
        "        if '+' in problem:\n",
        "            operands = problem.split('+')\n",
        "            expected = int(operands[0]) + int(operands[1])\n",
        "        elif '-' in problem:\n",
        "            operands = problem.split('-')\n",
        "            expected = int(operands[0]) - int(operands[1])\n",
        "        else:\n",
        "            expected = \"?\"\n",
        "        \n",
        "        # Check correctness\n",
        "        is_correct = str(predicted_answer) == str(expected)\n",
        "        status = \"✅ CORRECT\" if is_correct else \"❌ WRONG\"\n",
        "        if is_correct:\n",
        "            correct_count += 1\n",
        "        \n",
        "        print(f\"{problem:12s} → {predicted_answer:8s} ({expected:8s})  {status}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"{problem:12s} → ERROR     (?)        ❌\")\n",
        "\n",
        "accuracy = correct_count / len(challenging_problems) * 100\n",
        "print(f\"\\n🎯 Challenge Test Accuracy: {correct_count}/{len(challenging_problems)} ({accuracy:.1f}%)\")\n",
        "\n",
        "# Compare with tiny model\n",
        "print(f\"\\n📊 Model Comparison:\")\n",
        "print(f\"  Tiny model accuracy:       {eval_results['accuracy_stats']['overall']:.1%}\")\n",
        "print(f\"  Production model accuracy: {production_eval_results['accuracy_stats']['overall']:.1%}\")\n",
        "improvement = production_eval_results['accuracy_stats']['overall'] - eval_results['accuracy_stats']['overall']\n",
        "print(f\"  Improvement:               +{improvement:.1%}\")\n",
        "\n",
        "if accuracy >= 90:\n",
        "    print(\"\\n🏆 EXCELLENT! Production model shows strong arithmetic capabilities!\")\n",
        "elif accuracy >= 70:\n",
        "    print(\"\\n👍 GOOD! Model demonstrates solid arithmetic understanding!\")\n",
        "elif accuracy >= 50:\n",
        "    print(\"\\n📈 MODERATE! Model shows some arithmetic capability but needs improvement!\")\n",
        "else:\n",
        "    print(\"\\n⚠️ NEEDS WORK! Consider additional training or architectural changes!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🎮 Part 6: Interactive Usage & Deployment\n",
        "\n",
        "### Production-Ready Inference\n",
        "\n",
        "Our CalcGPT model is now ready for real-world usage! The CalcGPT CLI provides multiple interfaces:\n",
        "\n",
        "#### 🖥️ Interactive Mode\n",
        "```bash\n",
        "python calcgpt.py -i\n",
        "# Provides a beautiful interactive calculator interface\n",
        "```\n",
        "\n",
        "#### 📦 Batch Processing  \n",
        "```bash\n",
        "python calcgpt.py -b \"50+50\" \"99-1\" \"75+25\"\n",
        "# Process multiple problems at once\n",
        "```\n",
        "\n",
        "#### 📄 File Processing\n",
        "```bash\n",
        "echo \"100+1\\n50+50\\n99-99\" > problems.txt\n",
        "python calcgpt.py -f problems.txt -o results.json\n",
        "```\n",
        "\n",
        "### Model Analysis & Introspection\n",
        "\n",
        "Our intelligent naming system allows easy model analysis:\n",
        "\n",
        "```bash\n",
        "python calcgpt_train.py --analyze models/calcgpt_emb128_lay6_head8_ep20_bs8_lr1e3_dsm100\n",
        "# Shows complete training configuration and equivalent command\n",
        "```\n",
        "\n",
        "Let's demonstrate the interactive capabilities!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Demonstrate various CalcGPT usage modes\n",
        "print(\"🎮 CalcGPT Usage Demonstrations\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# 1. Programmatic batch processing\n",
        "print(\"\\n1️⃣ Programmatic Batch Processing\")\n",
        "batch_problems = [\"25+25=\", \"100-33=\", \"67+12=\", \"88-44=\", \"75+20=\"]\n",
        "\n",
        "print(f\"Input problems: {[p.replace('=', '') for p in batch_problems]}\")\n",
        "print(\"Results using CalcGPT library:\")\n",
        "\n",
        "batch_inference_config = InferenceConfig(temperature=0.0, verbose=False)\n",
        "batch_calc_model = CalcGPT(\n",
        "    config=batch_inference_config,\n",
        "    model_path=production_model_path,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "correct_count = 0\n",
        "for problem in batch_problems:\n",
        "    try:\n",
        "        result = batch_calc_model.generate(problem)\n",
        "        predicted = result['completion'].strip()\n",
        "        \n",
        "        # Calculate expected\n",
        "        expr = problem.replace('=', '')\n",
        "        if '+' in expr:\n",
        "            operands = expr.split('+')\n",
        "            expected = int(operands[0]) + int(operands[1])\n",
        "        elif '-' in expr:\n",
        "            operands = expr.split('-')\n",
        "            expected = int(operands[0]) - int(operands[1])\n",
        "        \n",
        "        is_correct = str(predicted) == str(expected)\n",
        "        status = \"✅\" if is_correct else \"❌\"\n",
        "        if is_correct:\n",
        "            correct_count += 1\n",
        "        \n",
        "        print(f\"  {expr} → {predicted} {status}\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"  {expr} → ERROR ❌\")\n",
        "\n",
        "print(f\"Accuracy: {correct_count}/{len(batch_problems)} ({correct_count/len(batch_problems)*100:.1f}%)\")\n",
        "\n",
        "# 2. CLI batch processing with JSON output (demonstrating the CLI tool)\n",
        "print(\"\\n2️⃣ CLI Batch Processing with JSON Output\")\n",
        "result = subprocess.run([\n",
        "    'python', 'calcgpt.py',\n",
        "    '-b', '25+25', '100-33', '67+12', '88-44', '75+20',\n",
        "    '--format', 'json',\n",
        "    '--no-banner'\n",
        "], capture_output=True, text=True)\n",
        "\n",
        "if result.stdout:\n",
        "    try:\n",
        "        output_data = json.loads(result.stdout)\n",
        "        print(f\"CLI Results - {output_data['metadata']['correct_answers']}/{output_data['metadata']['total_problems']} correct\")\n",
        "        for res in output_data['results']:\n",
        "            status = \"✅\" if not res.get('error') else \"❌\"\n",
        "            print(f\"  {res['problem']} → {res.get('answer', 'ERROR')} {status}\")\n",
        "    except:\n",
        "        print(\"Raw output:\", result.stdout)\n",
        "\n",
        "# 3. Performance comparison: Tiny vs Production (programmatic)\n",
        "print(\"\\n3️⃣ Performance Comparison: Tiny vs Production\")\n",
        "\n",
        "comparison_problems = [\"1+1=\", \"10+5=\", \"25+25=\", \"50-20=\", \"99+1=\"]\n",
        "\n",
        "# Initialize tiny model for comparison\n",
        "tiny_calc_model = CalcGPT(\n",
        "    config=InferenceConfig(temperature=0.0, verbose=False),\n",
        "    model_path=tiny_model_path,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "print(\"Problem   | Tiny Model  | Production Model | Better?\")\n",
        "print(\"-\" * 55)\n",
        "\n",
        "for problem in comparison_problems:\n",
        "    expr = problem.replace('=', '')\n",
        "    \n",
        "    # Get expected answer\n",
        "    if '+' in expr:\n",
        "        operands = expr.split('+')\n",
        "        expected = int(operands[0]) + int(operands[1])\n",
        "    elif '-' in expr:\n",
        "        operands = expr.split('-')\n",
        "        expected = int(operands[0]) - int(operands[1])\n",
        "    \n",
        "    # Test tiny model\n",
        "    try:\n",
        "        tiny_result = tiny_calc_model.generate(problem)\n",
        "        tiny_answer = tiny_result['completion'].strip()\n",
        "        tiny_correct = str(tiny_answer) == str(expected)\n",
        "    except:\n",
        "        tiny_answer = \"ERROR\"\n",
        "        tiny_correct = False\n",
        "    \n",
        "    # Test production model\n",
        "    try:\n",
        "        prod_result = production_calc_model.generate(problem)\n",
        "        prod_answer = prod_result['completion'].strip()\n",
        "        prod_correct = str(prod_answer) == str(expected)\n",
        "    except:\n",
        "        prod_answer = \"ERROR\"\n",
        "        prod_correct = False\n",
        "    \n",
        "    # Determine which is better\n",
        "    if prod_correct and not tiny_correct:\n",
        "        better = \"🚀 YES\"\n",
        "    elif prod_correct and tiny_correct:\n",
        "        better = \"✅ BOTH\"\n",
        "    elif not prod_correct and tiny_correct:\n",
        "        better = \"🤔 TINY\"\n",
        "    else:\n",
        "        better = \"❌ NONE\"\n",
        "    \n",
        "    tiny_status = \"✅\" if tiny_correct else \"❌\"\n",
        "    prod_status = \"✅\" if prod_correct else \"❌\"\n",
        "    \n",
        "    print(f\"{expr:8s}  | {tiny_answer:6s} {tiny_status:2s} | {prod_answer:10s} {prod_status:2s}     | {better}\")\n",
        "\n",
        "# 4. CLI advanced features demonstration\n",
        "print(\"\\n4️⃣ CLI Advanced Features - Temperature Control\")\n",
        "\n",
        "print(\"🎯 Temperature Control (CLI demonstration):\")\n",
        "test_problem = \"50+50\"\n",
        "\n",
        "for temp in [0.0, 0.5, 1.0]:\n",
        "    result = subprocess.run([\n",
        "        'python', 'calcgpt.py',\n",
        "        '-b', test_problem,\n",
        "        '--temperature', str(temp),\n",
        "        '--no-banner'\n",
        "    ], capture_output=True, text=True)\n",
        "    \n",
        "    # Extract answer\n",
        "    answer = \"ERROR\"\n",
        "    for line in result.stdout.split('\\n'):\n",
        "        if \"50+50\" in line:\n",
        "            parts = line.split()\n",
        "            if len(parts) >= 2:\n",
        "                answer = parts[1]\n",
        "                break\n",
        "    \n",
        "    randomness = \"deterministic\" if temp == 0.0 else f\"randomness={temp}\"\n",
        "    print(f\"  Temperature {temp}: {test_problem} → {answer} ({randomness})\")\n",
        "\n",
        "print(f\"\\n🎉 CalcGPT Library & CLI Tools Demonstrated!\")\n",
        "print(f\"   ✅ Programmatic access via lib/ package\")\n",
        "print(f\"   ✅ CLI tools for interactive usage\")  \n",
        "print(f\"   ✅ Multiple input/output formats\")\n",
        "print(f\"   ✅ Model comparison capabilities\")\n",
        "print(f\"   ✅ Professional evaluation tools\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🎓 Part 7: Lessons Learned & Advanced Concepts\n",
        "\n",
        "### 🧠 Key Insights from Building CalcGPT\n",
        "\n",
        "Through this journey, we've learned fundamental principles that apply to all transformer-based language models:\n",
        "\n",
        "#### 1. **Architecture Scaling Laws**\n",
        "- **Parameters matter**: 30x more parameters → dramatically better performance\n",
        "- **Depth vs Width**: More layers often better than wider layers\n",
        "- **Attention heads**: Multiple heads capture different relationships\n",
        "- **Context length**: Longer sequences enable more complex reasoning\n",
        "\n",
        "#### 2. **Data Engineering Principles**  \n",
        "- **Quality over quantity**: Clean, systematic data beats noisy large datasets\n",
        "- **Data augmentation**: Simple transformations (like commutativity) boost performance\n",
        "- **Distribution coverage**: Ensure training data covers the inference domain\n",
        "- **Intelligent naming**: Systematic dataset organization enables reproducibility\n",
        "\n",
        "#### 3. **Training Dynamics**\n",
        "- **Learning rate scheduling**: Cosine annealing provides smooth convergence\n",
        "- **Validation monitoring**: Early stopping prevents overfitting\n",
        "- **Batch size trade-offs**: Larger batches for stability, smaller for regularization\n",
        "- **Mixed precision**: Significant speedups with minimal accuracy loss\n",
        "\n",
        "#### 4. **Evaluation Methodologies**\n",
        "- **Multiple test types**: Different completion scenarios reveal different capabilities\n",
        "- **Comprehensive metrics**: Format, correctness, and performance matter\n",
        "- **Generalization testing**: Test beyond training distribution\n",
        "- **Error analysis**: Understanding failures guides improvements\n",
        "\n",
        "### 🔬 What Makes CalcGPT Special?\n",
        "\n",
        "Unlike general language models that struggle with arithmetic, CalcGPT demonstrates:\n",
        "\n",
        "- **Precise computation**: Exact arithmetic rather than approximate pattern matching\n",
        "- **Systematic reasoning**: Step-by-step problem solving\n",
        "- **Format consistency**: Reliable output structure\n",
        "- **Scalable performance**: Handles increasing complexity gracefully\n",
        "\n",
        "### 🚀 Advanced Concepts & Extensions\n",
        "\n",
        "Ready to take CalcGPT further? Here are some advanced directions:\n",
        "\n",
        "#### 🧮 Extended Arithmetic\n",
        "- **Multiplication & Division**: More complex operations\n",
        "- **Multi-step problems**: (a+b)×c, nested operations\n",
        "- **Decimal numbers**: Floating-point arithmetic\n",
        "- **Negative numbers**: Full integer arithmetic\n",
        "\n",
        "#### 🏗️ Architectural Improvements  \n",
        "- **Positional encodings**: Learned vs sinusoidal\n",
        "- **Attention mechanisms**: Sparse attention, local attention\n",
        "- **Normalization strategies**: LayerNorm vs RMSNorm\n",
        "- **Activation functions**: ReLU vs GELU vs SwiGLU\n",
        "\n",
        "#### 📊 Training Enhancements\n",
        "- **Curriculum learning**: Start simple, gradually increase complexity\n",
        "- **Data mixing**: Combine arithmetic with natural language\n",
        "- **Multi-task learning**: Multiple mathematical operations simultaneously\n",
        "- **Reinforcement learning**: Self-improvement through interaction\n",
        "\n",
        "#### 🔧 Production Optimizations\n",
        "- **Model quantization**: 8-bit or 4-bit inference\n",
        "- **Knowledge distillation**: Smaller models from larger ones\n",
        "- **Caching strategies**: KV-cache optimization\n",
        "- **Batch processing**: Efficient multi-query handling\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## 🌟 Summary & Next Steps\n",
        "\n",
        "### 🎯 What We Accomplished\n",
        "\n",
        "In this comprehensive tutorial, we built a complete machine learning system from scratch:\n",
        "\n",
        "#### 🛠️ **Tools Created**\n",
        "- **CalcGPT DataGen**: Intelligent dataset generation with parameter encoding\n",
        "- **CalcGPT Trainer**: Professional training system with auto-naming\n",
        "- **CalcGPT Eval**: Comprehensive evaluation and analysis\n",
        "- **CalcGPT CLI**: Production-ready inference interface\n",
        "\n",
        "#### 📊 **Models Trained**\n",
        "- **Tiny Model**: 38K parameters, proof of concept (0-5 arithmetic)\n",
        "- **Production Model**: 1.2M parameters, real-world capable (0-100 arithmetic)\n",
        "\n",
        "#### 🧠 **Core Concepts Mastered**\n",
        "- Transformer architecture and attention mechanisms\n",
        "- Character-level language modeling for arithmetic\n",
        "- Dataset engineering and augmentation strategies  \n",
        "- Training dynamics and optimization techniques\n",
        "- Comprehensive evaluation methodologies\n",
        "- Production deployment and model management\n",
        "\n",
        "### 🚀 Your Learning Journey Continues\n",
        "\n",
        "#### **Immediate Next Steps**\n",
        "1. **Experiment**: Try different model architectures and training settings\n",
        "2. **Extend**: Add multiplication, division, or decimal arithmetic\n",
        "3. **Scale**: Train on larger datasets with higher number ranges\n",
        "4. **Deploy**: Use CalcGPT in real applications or integrate via API\n",
        "\n",
        "#### **Advanced Projects**\n",
        "- **Multi-modal**: Combine text and visual arithmetic problems\n",
        "- **Interactive Tutoring**: Build an AI math tutor\n",
        "- **Scientific Computing**: Extend to algebraic expressions\n",
        "- **Model Optimization**: Quantization and efficient inference\n",
        "\n",
        "### 📚 Additional Resources\n",
        "\n",
        "#### **HuggingFace & Transformers**\n",
        "- [Transformers Documentation](https://huggingface.co/docs/transformers)\n",
        "- [Course: NLP with Transformers](https://huggingface.co/course)\n",
        "- [Model Hub](https://huggingface.co/models)\n",
        "\n",
        "#### **PyTorch Deep Learning**\n",
        "- [PyTorch Tutorials](https://pytorch.org/tutorials)\n",
        "- [Deep Learning with PyTorch](https://pytorch.org/deep-learning-with-pytorch)\n",
        "\n",
        "#### **Research Papers**\n",
        "- [Attention Is All You Need](https://arxiv.org/abs/1706.03762) (Original Transformer)\n",
        "- [Language Models are Few-Shot Learners](https://arxiv.org/abs/2005.14165) (GPT-3)\n",
        "- [Training Compute-Optimal Large Language Models](https://arxiv.org/abs/2203.15556) (Scaling Laws)\n",
        "\n",
        "### 🎉 Congratulations!\n",
        "\n",
        "You've successfully built a complete transformer-based language model system! You now understand:\n",
        "\n",
        "- ✅ How transformers work under the hood\n",
        "- ✅ Professional ML engineering practices  \n",
        "- ✅ Dataset design and evaluation strategies\n",
        "- ✅ Production deployment considerations\n",
        "- ✅ The full ML lifecycle from data to deployment\n",
        "\n",
        "**Keep experimenting, keep learning, and keep building amazing AI systems!** 🚀\n",
        "\n",
        "---\n",
        "\n",
        "*Built with ❤️ using CalcGPT - A comprehensive transformer tutorial by Mihai NADAS*\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
